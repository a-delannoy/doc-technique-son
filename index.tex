% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table des matières}
\else
  \newcommand\contentsname{Table des matières}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Liste des Figures}
\else
  \newcommand\listfigurename{Liste des Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Liste des Tables}
\else
  \newcommand\listtablename{Liste des Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{Liste des Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{french}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Guide pratique des techniques du son},
  pdfauthor={Jean-Loup Pecquais},
  pdflang={fr},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Guide pratique des techniques du son}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Enregistrement, mixage et spatialisation, appliqués à la
musique}
\author{Jean-Loup Pecquais}
\date{}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[frame hidden, sharp corners, interior hidden, borderline west={3pt}{0pt}{shadecolor}, breakable, enhanced, boxrule=0pt]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table des matières}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{avant-propos}{%
\chapter*{Avant-propos}\label{avant-propos}}
\addcontentsline{toc}{chapter}{Avant-propos}

\markboth{Avant-propos}{Avant-propos}

Ce livre est né de la nécessité d'un support de cours pour la formation
professionnelle ``Technique de Prise de Son'', dispensée par l'auteur.
Il intègre donc l'ensemble des notions abordées, expliquées en détail,
ainsi que des exemples sonores.

Ce livre est écrit dans la philosophie de l'Open Source. L'intégralité
de son contenu est donc disponible gratuitement. Son code source est
accessible dans un dépôt GitHub. Ainsi, il est possible à tout à chacun
de reporter les éventuelles erreurs ou de proposer des modifications. La
grande majorité des outils utilisés pour sa rédaction et la création du
contenu sont open source : R \& Rmarkdown, Python, FAUST et draw.io.

\hypertarget{a-qui-sadresse-cet-ouvrage}{%
\section*{A qui s'adresse cet
ouvrage}\label{a-qui-sadresse-cet-ouvrage}}
\addcontentsline{toc}{section}{A qui s'adresse cet ouvrage}

\markright{A qui s'adresse cet ouvrage}

Ce livre s'adresse à toutes personnes désireuses d'en apprendre plus sur
le son ainsi que sur les métiers de preneur de son et de mixeur. Ainsi,
il fait état des principes physiques nécessaires à la bonne appréhension
des techniques de travail des métiers susnommés, avec le souci de les
rendre accessibles à toutes et tous.

Il pourra donc servir aux musiciens, aux étudiants, et pourquoi pas, à
certains professionnels des métiers du son et du divertissement en
général.

\hypertarget{mise-uxe0-jour}{%
\section*{Mise à jour}\label{mise-uxe0-jour}}
\addcontentsline{toc}{section}{Mise à jour}

\markright{Mise à jour}

La distribution numérique de ce livre permet une mise à jour régulière
de son contenu. Cela implique deux choses :

\begin{itemize}
\tightlist
\item
  Certaines sections peuvent être incomplètes, et seront complétées plus
  tard
\item
  C'est une bonne idée de revenir consulter ce site régulièrement
\end{itemize}

\begin{quote}
Pour l'instant, ce livre n'inclut pas encore d'exemples sonores, cela
est en cours de création.
\end{quote}

\hypertarget{structures}{%
\section*{Structures}\label{structures}}
\addcontentsline{toc}{section}{Structures}

\markright{Structures}

Dans un premier temps, le livre aborde des principes généraux, aussi
bien sur la physique que sur l'environnement de production de la musique
enregistrée. Est ensuite abordé l'ensemble de la chaîne audio, en y
explicitant le rôle et le fonctionnement de chacun de ses composants.
L'objectif est de fournir une base technique objective au preneur de
son.

Dans un second temps, le livre détaille un ensemble de techniques de
prise de son et de mixage, insistant particulièrement sur les mécanismes
généraux de la prise et sur l'écoute critique.

\begin{quote}
La partie dédiée à la pratique du mixage son n'est pas encore disponible
en ligne.
\end{quote}

\hypertarget{uxe0-propos-de-lauteur}{%
\section*{À propos de l'auteur}\label{uxe0-propos-de-lauteur}}
\addcontentsline{toc}{section}{À propos de l'auteur}

\markright{À propos de l'auteur}

Jean-Loup Pecquais est formateur et consultant dans le monde de l'audio
professionnel (FLUX:: Immersive, Whiti Audio, Arkalya). Il est plus
particulièrement spécialisé dans les techniques de mixage sonore
immersives. Il est diplômé de l'ENS Louis-Lumière en 2019.

\part{Généralités}

\hypertarget{oreille-et-audition}{%
\chapter{Oreille et audition}\label{oreille-et-audition}}

L'oreille est l'organe qui, chez l'Homme, permet d'entendre les sons
environnants. Comme nous le détaillerons dans le chapitre suivant, le
son est une vibration de l'air. Afin que celle-ci puisse être audible,
l'oreille doit d'abord transformer cette vibration de l'air
(caractérisée par une variation de pression) en signal électrique
finalement transmis à notre cerveau.

On distingue ainsi entendre, perception passive du son, et écouter, qui
suppose une participation active de l'auditeur.

Le sens lié à cette faculté de perception du son se nomme
\textbf{l'ouïe}.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Nous ne discuterons pas ici du rôle de l'oreille dans l'équilibre.

\end{tcolorbox}

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{generalites/../_resources/bitmap/anatomie/anatomie-oreille.jpeg}

}

\caption{\label{fig-oreille}Schéma de l'oreille}

\end{figure}

Cet organe se décompose classiquement en trois parties, l'oreille
externe, l'oreille moyenne et l'oreille interne.

\hypertarget{loreille-externe}{%
\section{L'oreille externe}\label{loreille-externe}}

Comme son nom l'indique, l'oreille externe est la partie visible de
notre organe de l'audition. Elle est caractérisée par ce pavillon à la
forme si particulière. Le rôle de ce \textbf{pavillon auriculaire}
permet de ``collecter'' le son. Sa forme applique une emprunte
fréquentielle sur le son, donnant une information principalement d'ordre
spatial. Ce pavillon joue donc un rôle important dans notre capacité à
localiser les sons, avec une précision maximale lorsque l'évènement
sonore se trouve devant nous.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Comme nous le verrons plus tard, la forme de notre tête et même de notre
torse a également un rôle important dans notre capacité à localiser des
évènements sonores dans l'espace.

\end{tcolorbox}

L'oreille externe comporte aussi le canal auditif, avec à son terme le
tympan. Ce dernier est une simple membrane, vibrant de façon homologue à
l'onde sonore lui provenant. L'ensemble de ce système de ``captation''
possède un rendement maximal sur les fréquences autour de 3 kHz
(fréquences aiguës).

\hypertarget{loreille-moyenne}{%
\section{L'oreille moyenne}\label{loreille-moyenne}}

Derrière le tympan se trouve l'oreille moyenne, et plus particulièrement
une collection de trois os, nommés ``marteau'', ``enclume'' et
``étrier''. Le \textbf{marteau} est directement relié au tympan et
transmet les vibrations du tympan à l'``\textbf{enclume}'' puis à
l'``\textbf{étrier}''. Ce dernier permet la transmission du son à
l'oreille interne par la fenêtre ovale.

Nous y trouvons aussi la trompe d'eustache, reliée à la gorge, réalisant
ainsi un équilibrage de la pression entre celle de l'oreille interne et
celle nous environnant.

Le rôle principal de cette oreille moyenne est de réaliser une
adaptation d'impédance acoustique entre l'air et le milieu liquide, dans
lequel baigne notre oreille interne. En d'autres termes, elle permet un
transfert efficace de l'énergie sonore vers l'oreille interne. Sans
cette étape, notre sens de l'audition serait grandement amoindri.

Évoquons également le \textbf{muscle stapédien}. Il permet, lorsqu'il
est contracté, de limiter l'amplitude de mouvement des trois os évoqués
précédemment. Il agit alors comme une protection lorsque nous sommes
confrontés à de forts niveaux sonores. Si cette rigidification n'avait
pas lieu, notre tympan serait beaucoup plus facilement arraché par des
stimulus sonores importants.

Cependant, ce muscle stapédien échappe à notre contrôle cognitif et est
donc mis en action par réflexe. Son temps de mise en action est d'au
moins 40 millisecondes (ms) après l'émission d'un son supérieur à 90-100
décibel (dB). Pire, la protection maximale n'est atteinte que 150 ms
plus tard. Cela signifie que, si nous sommes exposés à des déflagrations
sonores très importantes (armes à feu, explosions, etc.), notre
\textbf{réflexe stapédien} n'aura pas le temps de s'activer, et notre
système auditif sera sévèrement endommagé.

\hypertarget{loreille-interne}{%
\section{L'oreille interne}\label{loreille-interne}}

Nous avons précédemment évoqué l'attachement de l'étrier à la fenêtre
ovale. Cette dernière fait elle-même partie de la cochlée, où commence
l'oreille interne. Cette cochlée prend une forme de coquille d'escargot
et renferme la membrane basilaire et l'organe de Corti, récepteur de
l'audition. Son ensemble est immergé dans différentes lymphes (milieu
liquide).

La membrane basilaire court le long de la cochlée et près de 30 000
récepteurs ressemblant à de petits cheveux la parcourent. Cette membrane
vibre lorsque la lymphe change de pression. Sur l'ensemble de sa
longueur est répartie notre sensibilité aux différentes fréquences. La
partie proche de l'oreille moyenne est plus sensible aux aiguës, alors
que la zone en bout de son enroulement est plus sensible aux graves. On
a donc une correspondance entre fréquence et emplacement sur la membrane
basilaire. Lorsque les récepteurs vibrent suffisamment fortement, un
signal électrique est émis par l'organe de Cortie dans le système
nerveux.

La diminution de sensibilité, voire la perte de certaines fréquences
audible dans l'audition, est associée à la mort de ces récepteurs
peuplant la membrane basilaire. Ce phénomène est irréversible et peut
aboutir à l'apparition d'acouphènes.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-warning-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Avertissement}]

L'oreille est un organe fragile, dont l'endommagement est irréversible.
Il convient donc d'en prendre soin en limitant :

\begin{itemize}
\tightlist
\item
  son exposition à de forts niveaux sonores
\item
  son exposition au bruit
\end{itemize}

Dans les cas où l'exposition est contrainte (voire souhaité en concert
par exemple), il est vivement conseillé de porter des protections
auditives (bouchons d'oreilles).

Il est également bon de rappeler que, dans la législation française, les
niveaux sonores de diffusions dans des lieux de spectacles sont normés
et ne doivent pas dépasser certains seuils. L'ingénieur du son affecté
au mixage est donc \textbf{responsable} du respect de ces normes.

En studio, il n'existe pas de norme de niveau de diffusions dans les
casques ou les écoutes, mais l'ingénieur du son reste tout de même
responsable de ce que les musiciens entendent, et donc de toute perte
d'audition de l'un d'eux lors d'une session de travail.

\end{tcolorbox}

\hypertarget{sec-son}{%
\chapter{Quantifier et qualifier le son}\label{sec-son}}

Le son peut s'appréhender de plusieurs façons différentes.
Particulièrement, sa description physique et psychoacoustique est très
précieuse pour tous les praticiens du son. Il convient donc, afin de
pouvoir proposer un dispositif cohérent de prise de son, de comprendre
la physique élémentaire du son ainsi que d'être capable de le décrire
efficacement.

\hypertarget{phuxe9nomuxe8ne-physique}{%
\section{Phénomène physique}\label{phuxe9nomuxe8ne-physique}}

\hypertarget{quelques-duxe9finitions}{%
\subsection{Quelques définitions}\label{quelques-duxe9finitions}}

Le son est une vibration mécanique d'un fluide. Dans le cadre de ce
cours, nous ne considérerons que l'air comme médium de propagation.
Cette onde cause une variation de la pression dans l'espace. Nous, les
êtres humains, le percevons grâce à notre ouïe. Il s'agit donc, par
définition, d'un phénomène ondulatoire et peut être caractérisé par un
nombre d'oscillations par seconde, aussi appelé fréquence. On estime que
notre espèce est sensible aux fréquences allant de 20 Hz (très grave)
jusqu'à 20 000 Hz (très aigu).

On parlera d'\textbf{évènement sonore} pour parler généralement de
phénomènes physiques produisant une onde sonore.

Les sons composés d'une seule fréquence se nomment \textbf{sons purs}.
Cependant, de tels signaux n'existent pas dans la nature, et sont
souvent utilisés afin de réaliser des mesures ou des tests
psychoacoustiques.

\begin{figure}

{\centering \includegraphics{generalites/qualifier_le_son_files/figure-pdf/fig-sine-output-1.pdf}

}

\caption{\label{fig-sine}Onde sinusoïdale et visualisation de son
spectre}

\end{figure}

Dans notre environnement, les sons sont donc composés de plusieurs
fréquences. La fréquence la plus grave d'un son est sa \textbf{fréquence
fondamentale}. Les autres sont alors appelées \textbf{partiels}. Si ces
partielles ont pour fréquence un multiple de la fréquence fondamentale,
alors on les nomme \textbf{harmoniques}.

\begin{quote}
Plus généralement, on admettra que la composition fréquentielle, ou
spectrale, de tout son peut être décomposée par une somme de sinusoïde.
L'outil permettant de passer de la représentation temporelle d'un signal
à sa représentation fréquentiel s'appelle la \textbf{transformée de
Fourrier.}
\end{quote}

\begin{figure}

{\centering \includegraphics{generalites/qualifier_le_son_files/figure-pdf/fig-square-output-1.pdf}

}

\caption{\label{fig-square}Signal carré et visualisation de son spectre}

\end{figure}

La fréquence fondamentale donne la \textbf{hauteur} du son (sa note en
musique par exemple). Les partiels enrichissent cette fréquence
fondamentale et créés le \textbf{timbre} d'un son. C'est en partie grâce
au timbre que l'on peut reconnaître différents instruments de musiques
jouant la même note.

Un son se caractérise également par l'évolution de son amplitude au
cours du temps. On parle alors de son \textbf{enveloppe}. Un modèle
courant d'enveloppe est l'ADSR : \emph{Attack}, \emph{Decay},
\emph{Sustain}, \emph{Release}, soit \emph{Attaque},
\emph{Décroissance}, \emph{Maintient} et \emph{Relâchement}.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/generalites/../_resources/drawings/adsr.pdf}

}

\caption{\label{fig-adsr}Exemple d'enveloppe ADSR}

\end{figure}

Lorsque son temps et très bref, l'ensemble \emph{attaque} et
\emph{décroissance} forme les \textbf{transitoires}. Cette partie du
signal est responsable de la sensation percussive du son.

\hypertarget{relation-entre-temps-distance-et-fruxe9quence}{%
\subsection{Relation entre temps, distance et
fréquence}\label{relation-entre-temps-distance-et-fruxe9quence}}

Il est important de garder à l'esprit que les notions de temps, de
fréquence et de distance sont étroitement liées. Nous avons vu ci-dessus
que tous les sons peuvent être décrits par une somme de sinusoïde. Leur
fréquence la plus grave, dite fondamentale, permet de définir la
\textbf{période}. La période est le temps que met un signal à répéter
son motif oscillatoire (voir schémas 3.1 et 3.2). Le lien mathématique
entre fréquence et période est très simple, car l'un est l'inverse de
l'autre :

\[ f = \frac 1 T \]

Si nous étudions les fréquences extrêmes, audibles par notre ouïe, nous
trouvons que pour \(f_{min} = 20 \,Hz\), sa période
\(T_{f_{min}} = 50 \,ms\). Pour \(f_{max} = 20\,000 \,Hz\),
\(T_{f_{max}} = 0.5 \,ms\).

Une onde sonore est également caractérisée par sa \textbf{célérité}.
Celle-ci est constante dans un milieu donné. Dans l'air, à une
température de \(15 \,°C\) et au niveau de la mer, sa célérité \(c\) est
de \(340\,m.s^{-1}\). On admettra cette valeur pour réaliser l'ensemble
de nos différents calculs.

Comme son unité l'indique, la célérité du son est homogène à une
distance divisée par un temps, soit :

\[ c =\frac d t \]

Suivant cette formule, nous pouvons alors calculer la \textbf{longueur
d'onde} correspondant à une fréquence. La longueur d'onde se note
\(\lambda\).

\[ \lambda = cT \; \iff \; \lambda = \frac c f\]

Si nous étudions à nouveau les bornes minimale et maximale de notre
audition, nous trouvons que \(\lambda_{f_{min}} = 17 \,m\) et
\(\lambda_{f_{max}} = 17 \,mm\).

Nous pouvons également calculer le temps de propagation du son. En
pratique, nous serons souvent intéressés par le temps de propagation
séparant deux points dans l'espace (par exemple, le temps séparant deux
microphones par rapport à un instrument).

\begin{figure}

{\centering \includegraphics{index_files/mediabag/generalites/../_resources/drawings/mic_dist.pdf}

}

\caption{\label{fig-dist_mic}Distance entre deux microphones.}

\end{figure}

\[ t = \frac {d_2-d_1}{c}\]

\hypertarget{perception-du-son}{%
\section{Perception du son}\label{perception-du-son}}

Nous avons abordé quelques notions de physique permettant de mieux
caractériser le phénomène sonore. Comme indiqué au début de ce chapitre,
le son peut également être discuté sous l'angle de notre ouïe, et donc,
de notre perception. Cette branche de la science se nomme la
psychoacoustique et cherche à étudier la façon dont nous percevons le
son.

Notre corps, et a fortiori notre cerveau, sont des machines extrêmement
complexes. Nous sommes équipés d'une multitude de capteurs permettant de
sentir le contact d'une matière, des odeurs, d'entendre, de goûter, de
voir, de positionner nos membres dans l'espace, de ressentir la douleur,
etc. Pris indépendamment, chacun de ces sens est déjà un phénomène
complexe à décrire, mais il existe en plus une grande interdépendance
entre ceux-ci. Par exemple, l'interdépendance entre la vision et
l'audition est à l'origine d'un certain nombre de mécanismes biaisant
notre écoute.

Nous nous bornerons au fil de ce cours à quelques notions liées à l'ouïe
et à son interdépendance à d'autre sens quand cela sera pertinent.

\hypertarget{spectre-timbre-et-vocabulaire}{%
\subsection{Spectre, timbre et
vocabulaire}\label{spectre-timbre-et-vocabulaire}}

D'un point de vue perceptif, le spectre d'un évènement sonore est
facilement remarquable. Il est, par contre, beaucoup plus difficile à
qualifier. Il n'est pas rare de rencontrer les adjectifs ``chaud'',
``brillant'', ``rond'', ``aéré'', ``ouvert'', ``sombre'', voir d'autres
encore plus ésotérique, pour tenter de communiquer la sensation
ressentie à l'écoute de tel ou tel son.

Cette difficulté liée à l'absence de vocabulaire commun quant à la
qualification le son emmène systématiquement la redéfinition de ce
vocable en fonction de son interlocuteur. En effet, le mot ``rond'' ne
signifiera pas forcément la même chose selon à qui on s'adresse. Une
stratégie possible consiste à questionner son interlocuteur sur
l'utilisation de ses adjectifs tout en cherchant à y associer des
exemples sonores.

Nous pouvons tout de même nous essayer à cet exercice pour nous
permettre d'avoir un vocabulaire commun au fil de ce cours. Vous aurez
sans doute compris qu'il n'y aura, dans les termes employés, aucun
critère absolu.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/generalites/../_resources/drawings/spectre.pdf}

}

\caption{\label{fig-spectre}Proposition de découpage du spectre}

\end{figure}

\textbf{Proposition d'association entre bandes de fréquences et
sensation}.

\begin{itemize}
\tightlist
\item
  \textbf{20~Hz --- 80~Hz} : Subharmonique, sensation tripale
\item
  \textbf{80~Hz --- 160~Hz} : Grave, sensation d'assise
\item
  \textbf{160~Hz --- 380~Hz} : bas-médium, sensation de «~chaleur~»,
  voir «~boueux~»
\item
  \textbf{380~Hz --- 1400~Hz} : Medium, sensation de «~boîte~» quand
  trop présent, sonne «~creux~» quand trop absent
\item
  \textbf{1400~Hz --- 3200~Hz} : Haut-medium : zone de sensibilité
  maximale de l'oreille.
\item
  \textbf{3200~Hz --- 8000~Hz} : Aigu, apporte de la précision voir de
  l'agressivité
\item
  \textbf{8000~Hz --- 20~000~Hz} : Air, apporte une sensation
  d'ouverture voir de finesse
\end{itemize}

Il est intéressant de former son oreille à reconnaître une plage de
fréquence, ainsi que d'y associer son propre vocabulaire et une
sensation. Les appellations proposées ci-dessus ne sont à prendre que
comme guides et n'ont pas valeur de référence. Cela favorise une écoute
critique et analytique.

\begin{quote}
Aussi, les fréquences graves ont un effet masquant sur les fréquences
plus aiguës. Ce phénomène est dû au fonctionnement de notre oreille, et
plus particulièrement de la cochlée.
\end{quote}

\hypertarget{pression-acoustique-niveau-sonore}{%
\subsection{Pression acoustique \& niveau
sonore}\label{pression-acoustique-niveau-sonore}}

Nous l'avons abordé plus haut, lorsqu'une onde sonore se déplace dans
l'air, on constate la variation de la pression atmosphérique en ce
point. Dès lors, il est facile de corréler l'amplitude de la variation
de la pression avec le niveau sonore entendu (ou mesuré).

L'unité du système international de la pression est le \textbf{pascal}
(\textbf{Pa}). Or, il est très rare de parler de la pression acoustique
en pascal, car la variation de cette pression exprimée en pascal ne
correspond pas à ce que nous percevons. En d'autres termes, si la
pression acoustique exprimée en pascal double, nous ne percevons pas un
son deux fois plus fort.

Notre oreille fonctionne de façon logarithmique, et non linéairement,
face à une variation de pression acoustique. C'est pour cela que l'on
parle généralement de \textbf{niveau de pression acoustique}, où
\textbf{SPL} (pour Sound Pressure Level en anglais), qui s'exprimera en
\textbf{décibel}. La relation entre la variation de pression et le
niveau de pression acoustique se fait grâce à la relation :

\[L_p = 20\,\log_{10}\Big(\frac{p_{eff}}{p_{ref}}\Big) \qquad p_{ref} = 20\mu Pa\]

\begin{quote}
Si la pression acoustique double, on observe une augmentation du niveau
sonore de 6 dB SPL. Lorsqu'on ressent un doublement du niveau sonore, on
observe une augmentation de 20 dB.

La pression acoustique est divisée par deux à chaque doublement de
distance.
\end{quote}

La question se complexifie lorsque l'on rajoute la dimension
fréquentielle à la question de la perception du niveau sonore. En effet,
nous percevons des niveaux sonores différents pour différentes
fréquences pourtant émises au même niveau de pression acoustique. Pour
inclure cette dépendance fréquentielle, nous avons mis en place une
unité de mesure : la \textbf{sonie} ou \textbf{bruyance}
(\textbf{loudness} en anglais). Il est donc possible ensuite de définir
des courbes d'\textbf{isosonie}, c'est-à-dire des courbes indiquant un
niveau sonore de perception égale en fonction de la fréquence et du
niveau de pression acoustique.

\begin{figure}

{\centering \includegraphics{generalites/../_resources/diagrams/Courbes_isosonie.png}

}

\caption{\label{fig-isosonie}Courbes d'isosonie, aussi dites de
Fletcher-Munson}

\end{figure}

Que conclure de cet abaque ?

\begin{itemize}
\tightlist
\item
  Notre oreille ne perçoit pas les fréquences de manière égale.
\item
  Notre zone de sensibilité maximale se situe dans l'aigu (3k-4k Hz).
\item
  Notre perception d'un matériau sonore en fonction du niveau auquel
  nous l'écoutons !
\end{itemize}

\hypertarget{positionnement-dans-lespace}{%
\subsection{Positionnement dans
l'espace}\label{positionnement-dans-lespace}}

Notre système auditif nous permet de situer l'émission d'un son dans
l'espace. Cette capacité de localisation repose sur un ensemble de
facteurs étroitement liés entre eux.

On qualifie notre écoute de \textbf{binaurale}, littéralement, écouter
avec deux oreilles. La présence de deux ``capteurs de pression''
(oserait-on parler de microphones ?) sur les faces latérales de notre
crâne et un premier élément expliquant notre capacité de localisation du
son.

En effet, l'espacement de nos oreilles (en moyenne 15 cm), créer un
décalage temporel entre nos deux canaux d'écoutes. Ce léger retard
entendu d'un côté ou de l'autre nous permettra de placer un son plutôt à
gauche ou plutôt à notre droite. On appelle cet écart de temps
\textbf{différence de temps interaural}, ou \textbf{ITD} (interaural
time difference en anglais) et se note \(\Delta t\).

On pourrait d'ailleurs, grâce aux formules de ce début de chapitre,
calculer le retard maximal moyen entre nos deux oreilles.

\[\Delta t_{max} = \frac d c = \frac {0,15}{340} = 0.4 \> ms\]

\begin{figure}

{\centering \includegraphics{index_files/mediabag/generalites/../_resources/drawings/delta_t.pdf}

}

\caption{\label{fig-delta_t}Illustration de l'ITD}

\end{figure}

Si nos oreilles sont espacées de quelques centimètres, notre tête les
séparant représente un obstacle acoustique non négligeable. De plus, les
pavillons des oreilles imposent également une certaine directivité à
notre écoute. En première approximation, on pourra donc considérer que
l'ensemble formé par la tête et les pavillons implique une atténuation
linéaire des ondes sonores, elle-même fonction de l'angle d'incidence.
On appelle cette différence de niveau \textbf{différence d'intensité
interaural}, ou \textbf{ILD} (interaural level difference) et se note
\(\Delta i\). On considère que si la différence de niveau de pression
acoustique entre les deux oreilles est supérieure à 20 dB, on entendra
l'évènement sonore complètement latéralisé.

\begin{quote}
L'ombre acoustique que représentent la tête et le pavillon n'est en
réalité pas du tout linéaire en fréquence. La modification du timbre
induite par ce système n'est pas perçue par notre cerveau comme une
information de couleur, mais bien comme une information de
spatialisation. Ainsi, selon l'angle d'incidence de l'évènement sonore,
son spectre sera filtré d'une certaine manière qui permettra à notre
cerveau de le positionner dans l'espace. La réponse en fréquence d'une
tête se nomme \textbf{HRTF} (\textbf{Head Related Transfer Function}).
\end{quote}

Enfin, nous sommes également capables de déterminer la distance d'un
évènement sonore. La plupart des paramètres permettant d'évaluer cette
distance sont relatifs. Cela signifie que l'évènement doit être comparé
à un autre pour pouvoir le repositionner dans l'espace. On pourra alors
comparer :

\begin{itemize}
\tightlist
\item
  Leurs niveaux sonores : un évènement sonore plus fort paraît plus
  proche
\item
  Leurs timbres : l'absorption de l'air aura pour effet de diminuer les
  fréquences aiguës
\item
  La sensation de réverbération associée : plus le signal de l'évènement
  sonore semblera solliciter la réponse acoustique du lieu, plus
  celui-ci semblera fort.
\item
  Le temps d'arrivée des premières réflexions : le son direct d'un
  évènement sonore lointain arrivera quasi simultanément avec ses
  premières réflexions. Le son direct d'un évènement sonore proche
  arrivera avant ses premières réflexions.
\end{itemize}

Le chapitre suivant traitera des notions d'acoustique élémentaire ainsi
que de la réverbération.

\hypertarget{acoustique-des-salles}{%
\chapter{Acoustique des salles}\label{acoustique-des-salles}}

Tout environnement, sollicité par un évènement sonore, produit une
réponse acoustique. Cette réponse acoustique est appelée réverbération.
Elle est caractéristique d'un lieu et peut, dans certains cas, être une
alliée précieuse dans notre travail. Dans d'autres, elle est source de
problèmes et complexifie grandement notre travail d'écoute analytique.

\hypertarget{guxe9nuxe9ralituxe9s-1}{%
\section{Généralités}\label{guxe9nuxe9ralituxe9s-1}}

\hypertarget{la-ruxe9verbuxe9ration}{%
\subsection{La réverbération}\label{la-ruxe9verbuxe9ration}}

Afin d'étudier l'acoustique d'une salle, on procède à la mesure de sa
réponse impulsionnelle. Pour se faire, on émet dans le lieu à mesurer un
signal audio impulsionnel (clappement de main, explosion d'un ballon,
émission d'une impulsion de Dirac grâce à un haut-parleur), et l'on
enregistre le résultat à l'aide d'un microphone de mesure.

La réponse impulsionnelle d'une salle est généralement décrite en deux
temps : le temps des premières réflexions et le temps du champ diffus.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/generalites/../_resources/drawings/reverb.pdf}

}

\caption{\label{fig-impulse}Schéma d'une réponse impulsionnelle de
réverbération.}

\end{figure}

Les premières réflexions sont les premiers rebonds d'une onde sonore sur
les parois d'une salle et sont caractéristiques de la signature
acoustique du lieu. Ces rebonds reviennent à l'auditeur avec un certain
temps. Ce retard se nomme souvent «~pré-délai~» dans les moteurs de
réverbération artificiels. Ce prédélai est fonction de deux paramètres~:

\begin{itemize}
\tightlist
\item
  la taille de la pièce~; plus la pièce est petite, plus les premières
  réflexions reviendront à l'auditeur rapidement.
\item
  les positions de la source sonore et de l'auditeur~; plus l'auditeur
  est proche de la source, plus les premières réflexions arriveront
  après le son direct, plus l'auditeur est loin de la source, plus les
  premières réflexions arriveront en même temps que le son direct.
\end{itemize}

Lorsque les premières réflexions elles-mêmes auront rebondi plusieurs
fois sur les parois du lieu, le phénomène d'écho des premières
réflexions va se muer en champs diffus, par nature plus dense. La
longueur du champ diffus se mesure grâce au RT60. Cette méthode de
mesure propose de regarder le temps que met la réverbération à perdre
60~dB. Ce temps permettra ensuite de donner une longueur de
réverbération.

\hypertarget{calcul-du-temps-de-ruxe9verbuxe9ration}{%
\subsection{Calcul du temps de
réverbération}\label{calcul-du-temps-de-ruxe9verbuxe9ration}}

L'équation de Sabine permet de calculer le temps de réverbération d'une
salle à partir de son volume et du coefficient d'absorption de ses
matériaux.

\[RT_{60} = 0.1611 \times \frac{V}{\sum_{i=0}^{k} S_i.\alpha_i}\]

\(V\) s'exprime en \(m^3\) et \(S\) en \(m^2\). \(\alpha\) est le
coefficient d'absorption du matériau, en sabins. Ce coefficient est
compris entre 0 et 1, plus il est important plus le matériau est
absorbant.

En guise d'exemple sur l'utilisation de la formule ci-dessus, prenons le
cas d'une pièce de \(25\,m^2\) (\(5\,m\) par \(5\,m\)) et de \(2.40\,m\)
de hauteur. Nous considérons que le sol est en parquet et les murs en
plâtre. Nous avons donc \(25\,m^2\) de parquet et
\(4\times(5\times2.4)=48\,m^2\). On trouve sur les sites de fabricant de
matériaux que le plâtre peint a un coefficient d'absorption de 0.05
sabins et le bois un coefficient de 0.15 sabins. Notre calcul final.

\[RT_{60} = 0.1611 \times \frac{25 \times 2.4}{25\times0.15+48\times0.05} \approx 1.57\,s\]

On peut dès lors calculer la \textbf{distance critique}, distance à
partir de laquelle on entendra autant un évènement sonore que la réponse
acoustique de la salle à son stimulus.

\[d_c \approx 0.057 \times \sqrt{\frac{V}{RT60}}\]

Dans notre exemple \(d_c \approx 0.35\,m\).

Il est souvent considéré que la taille de la pièce joue un rôle
déterminant sur la longueur de réverbération. L'équation de Sabine
indique bien que le coefficient d'absorption des matériaux y joue un
rôle beaucoup plus important. Le modèle de réverbération de l'IRCAM va
jusqu'à complètement décorréler la taille de la pièce simulée du temps
de réverbération. Au final, la taille de l'espace joue davantage sur la
structure temporelle des échos, et donc, principalement sur les
premières réflexions.

\hypertarget{limite-de-luxe9quation-de-sabine}{%
\subsection{Limite de l'équation de
Sabine}\label{limite-de-luxe9quation-de-sabine}}

Il convient d'observer plusieurs réserves quant à l'utilisation de
l'équation de Sabine. Premièrement, elle ne tient pas compte de l'aspect
fréquentiel lié à l'absorption des matériaux. En effet, le temps de
réverbération des graves est presque toujours plus long que celui des
aigus. Afin de contourner ce problème, on pourra chercher des
coefficients d'absorption tenant compte de la fréquence et ainsi
résoudre l'équation de Sabine pour certaines plages fréquentielles.

L'équation de Sabine pose également problème pour de petits espaces
(régie d'écoute par exemple) en prédisant un temps de réverbération trop
long. Dans ce cas, l'équation d'Eyring est plus adaptée.

\[RT_{60} = -0.1611 \times \frac{V}{\sum_{i=0}^{k} S_i.\ln(1-\alpha_i)}\]

\begin{quote}
:warning: L'équation d'Eyring n'améliore pas non plus la problématique
fréquentielle.
\end{quote}

\hypertarget{lindice-de-speech-clarity-c50}{%
\subsection{L'indice de ``Speech Clarity''
C50}\label{lindice-de-speech-clarity-c50}}

L'indice d'intelligibilité (noté \(C_{50}\)), ou ``Speech Clarity'' en
anglais, indique la faculté d'une pièce à permettre une bonne
compréhension d'une voix parlée. Son principe repose sur la mesure de
l'énergie de la réponse impulsionnelle de la pièce avant 50 ms et après
50 ms. On en fait ensuite un rapport logarithmique pour obtenir une
valeur en décibel.

\[ C_{50} = 10 \times \log \frac{Energie(<50ms)}{Energie(>50ms)} \, dB \]

Plus la valeur du \(C_{50}\) est grande, plus la salle concentre la
majorité de son énergie avant les 50 ms de propagation de la
réverbération. À l'inverse, plus le \(C_{50}\) est faible, plus la salle
a une énergie prédominante après 50 ms de temps de propagation. Dans ce
cas une voix parlée paraîtra moins intelligible, car la réponse
acoustique de la pièce engendrera un effet de fusion et de masquage.

\hypertarget{le-phuxe9nomuxe8ne-donde-stationnaire}{%
\subsection{Le phénomène d'onde
stationnaire}\label{le-phuxe9nomuxe8ne-donde-stationnaire}}

La plupart des pièces de vie sont des salles rectangulaires. Dans ce
cas, les surfaces sont toutes parallèles. Ce type de salle est
particulièrement propice à l'apparition d'ondes stationnaires. Une onde
stationnaire est un phénomène acoustique provoquant l'augmentation de
volume de certaines fréquences (ventre) et la disparition d'autres
(nœuds).

Nous aborderons ici ce phénomène sous l'angle de l'acoustique des
salles, mais il est applicable dans d'autres situations, comme la
vibration d'une corde par exemple.

\begin{figure}

{\centering \includegraphics{generalites/../_resources/gif/Standing_wave_2.png}

}

\caption{\label{fig-onde_stat}Les points rouges représente les noeuds,
les amplitudes maximales sont les ventres. Infographie par Lucas Vieira}

\end{figure}

Il est possible de calculer les fréquences d'un mode grâce aux formules
vues au chapitre précédent :

\[f(n) = \frac{c}{2L}.n\] où \(c=340\,m.s^{-1}\), \(L\) est la longueur
considérée de la pièce. Pour \(n=1\) on trouve le \textbf{mode propre}.
Pour \(n>1\) on trouvera tous les \textbf{modes harmoniques}.

Étudions la fréquence du mode propre pour deux cas théoriques : une
salle de 16 m² (4x4) et une autre de 49 m² (7x7). On trouvera donc :

\[f(1)_{L=4m} = 42.5 \,Hz \>\>\>\> f(1)_{L=7m} = 24 \,Hz\]

On en déduit donc que, plus la pièce est grande, plus la fréquence des
modes propres sera grave. Il convient également de considérer la
distance de chaque surface parallèle, car les pièces sont rarement
cubiques. Cela implique donc la présence de trois modes propres, plus
leurs modes harmoniques, pour une seule et même salle.

\hypertarget{premiuxe8res-ruxe9flexions-et-filtre-en-peigne}{%
\section{Premières réflexions et filtre en
peigne}\label{premiuxe8res-ruxe9flexions-et-filtre-en-peigne}}

Nous avons vu que la réponse acoustique, ou réverbération, d'une salle
se décompose généralement en deux parties, la première étant les
premières réflexions. Ces premières réflexions sont donc, comme leur nom
l'indique, les premiers rebonds que nous entendons suite à un évènement
sonore.

Dans de petites pièces, les premières réflexions peuvent être entendues
si proche du son direct que cela génère un type de filtrage bien
particulier appelé \textbf{filtre en peigne}.

\begin{figure}

{\centering \includegraphics{generalites/l_acoustique_des_salles_files/figure-pdf/fig-peigne-output-1.pdf}

}

\caption{\label{fig-peigne}Filtre en peigne correspondant à un retard
d'une milliseconde}

\end{figure}

Toujours en utilisant les formules définies au premier chapitre, on
établit la relation suivante :

\[ fc = \frac 1{2t} = \frac c{2d} \]

Où \(fc\) correspond à la fréquence d'annulation la plus grave du filtre
en peigne. Les autres fréquences se calculent grâce à la relation
\(f(n) = fc*n\). Le phénomène de filtre en peigne est donc également
harmonique.

Ainsi, on peut calculer les filtres en peignes présents au point
d'écoute d'une régie de mixage ou de prise de son grâce à la mesure du
chemin des premières réflexions.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/generalites/../_resources/drawings/roomPr.pdf}

}

\caption{\label{fig-pr}Ensemble des premières reflexions entendues par
une oreille pour une enceinte (hors plafond et plancher/bureau).}

\end{figure}

\begin{quote}
La réflexion du son sur une paroi est tout à fait comparable à de
l'optique géométrique. Une onde sonore arrivant avec un angle
d'incidence \(\alpha\) sur une surface sera réfléchie avec le même
angle. Ainsi, il est souvent conseillé d'utiliser un miroir lorsque l'on
positionne des traitements acoustiques. Lorsque la personne assise au
point d'écoute voit une enceinte dans un miroir placé sur un mur, on
sait alors qu'il faudra placer le panneau à la place du miroir.
\end{quote}

On se rend donc compte que l'influence des filtres en peigne générés par
les premières réflexions est très importante. Ce phénomène à lui seul
explique l'intérêt d'une grande régie d'écoute. En effet, plus une pièce
est grande, plus l'écart de temps entre le son direct et les premières
réflexions est important. Cela implique deux choses :

\begin{itemize}
\tightlist
\item
  Notre cerveau favorisera le son direct plus facilement (effet de
  précédence)
\item
  À partir d'une certaine taille, l'effet du filtre en peigne se mue en
  information d'acoustique pour notre cerveau. Au-delà de 40 ms (trajet
  d'une première réflexion d'environ 14 m), l'écart entre le son direct
  et les premières réflexions est tel que nous entendons un écho (effet
  Haas).
\end{itemize}

Afin de réduire au maximum les effets des filtres en peignes, il est
recommandé de placer des traitements aux points de réflexion critique
par rapport à la position d'écoute (voir schéma ci-dessus).

\begin{figure}

{\centering \includegraphics{generalites/l_acoustique_des_salles_files/figure-pdf/fig-peigne_att-output-1.pdf}

}

\caption{\label{fig-peigne_att}Même filtre en peigne, avec une
atténuation de 20 dB sur la reflexion}

\end{figure}

\hypertarget{traitement-acoustique}{%
\section{Traitement acoustique}\label{traitement-acoustique}}

Grâce aux différents points abordés ci-dessus, nous avons maintenant
bien l'idée que l'acoustique d'un lieu est un des facteurs les plus
déterminants sur le rendu sonore. Mais c'est aussi celui sur lequel il
est plus difficile et technique d'intervenir.

On favorisera au maximum une architecture optimisée pour l'acoustique.
Dans ce but, il convient de n'avoir aucune surface parallèle, cela
permettant de grandement limiter l'apparition d'ondes stationnaires. On
choisira également des matériaux avec des propriétés acoustiques
intéressantes (plâtre et carrelage sont à proscrire, au profit du bois
par exemple).

On se posera ensuite la question des endroits de la pièce les plus
propices pour y positionner un évènement sonore (enceinte, musicien,
etc.). On cherchera donc un point où la contribution des différents
modes semble équilibrée. Pour cela, il suffit de se munir d'une enceinte
et d'y diffuser une musique ou un signal test qui nous est familier. En
déplaçant l'enceinte, on pourra évaluer la contribution acoustique de la
pièce en différents points.

Une fois ces considérations prises en compte, on pourra alors aborder le
traitement de l'acoustique.

\begin{quote}
Il ne faut pas confondre isolation acoustique et traitement acoustique.
Dans le premier cas, on chercher a limiter la contribution sonore d'un
lieu sur son environnement, dans l'autre on cherche à améliorer la
propagation du son dans un espace donné. Une isolation acoustique
satisfaisante nécessite de lourds travaux, voire l'aménagement d'une
``boîte dans une boîte''. Ces notions d'acoustiques dépassent le cadre
de ce cours.
\end{quote}

\hypertarget{les-types-de-traitements}{%
\subsection{Les types de traitements}\label{les-types-de-traitements}}

On trouve, en général, deux types de traitements~:

\begin{itemize}
\tightlist
\item
  Les absorbeurs, qui réduisent l'énergie d'une onde sonore à son
  impact.
\item
  Les diffuseurs, qui répartissent l'énergie d'une onde sonore dans
  l'espace.
\end{itemize}

Dans un lieu où la quantité de réverbération est jugée trop importante,
on utilisera des absorbeurs. À l'inverse, dans un lieu où l'on souhaite
préserver la quantité de réverbération, mais en évitant les phénomènes
de modes ou de filtre en peignes, on utilisera des diffuseurs.

Dans de petits lieux, l'usage de diffuseur semble contre-productif, la
priorité étant d'absorber au maximum les premières réflexions, celle-ci
arrivant très rapidement après l'émission du son direct.

\hypertarget{considuxe9ration-dacoustique-pour-le-travail-de-son}{%
\subsection{Considération d'acoustique pour le travail de
son}\label{considuxe9ration-dacoustique-pour-le-travail-de-son}}

Il est vivement recommandé d'installer un studio, de prise de son ou de
monitoring, dans un lieu plutôt grand. En effet, plus le lieu est grand,
plus il sera facile de positionner un point de prise de son ou d'écoute
suffisamment éloigné des parois afin de minimiser l'influence des
premières réflexions. Aussi, plus le lieu est grand, plus l'espace y
sera suffisant pour installer des traitements acoustiques. Certains
types de traitements, comme les basstraps, peuvent prendre une place
bien trop importante pour être installée dans des pièces de dimension
habituelle (chambres, bureau, etc.). On se rappellera aussi de choisir
une pièce de travail avec le minimum de surface parallèle, afin de
limiter les ondes stationnaires.

En ce qui concerne les traitements en eux-mêmes, il est vivement
recommandé de traiter en priorité le bas du spectre. L'ajout de basstrap
est donc prioritaire sur le reste des traitements. Plus la longueur
d'onde à traiter est grande (donc la fréquence grave), plus la taille
des matériaux devra être importante. On retrouve donc le point abordé
précédemment~: traiter une pièce correctement, demande un certain
espace. Par ailleurs, il est important que les traitements appliqués à
un lieu soient linéaires en fréquence, c'est-à-dire qu'il ne se
concentre pas sur une seule zone du spectre. Cela arrive souvent avec
les kits de mousses peu onéreux, mais n'ayant une réelle efficacité que
dans les médiums et hautes fréquences.

Pour une régie d'écoute, on sera tenté de privilégier des traitements
d'absorption. En effet, une réverbération trop longue dans une régie de
monitoring risque fort de fausser certaines prises de décisions
(distance des microphones à la source, quantité de réverbération, etc.).
À l'inverse, une pièce avec un temps de réverbération trop court pourra
créer un sentiment d'inconfort, voire de malaise.

Pour une salle de prise de son, l'idéal est de disposer d'un grand
espace avec un traitement acoustique principalement basé sur de la
diffusion, pour ensuite disposer de traitements absorbants amovibles
permettant de sculpter le rendu acoustique en fonction de la prise de
son à réaliser. Pour des petits lieux (- de 25 m²), on cherchera à
absorber au maximum afin de limiter les effets de filtre en peigne.

\hypertarget{notions-uxe9luxe9mentaires-duxe9lectronique}{%
\chapter{Notions élémentaires
d'électronique}\label{notions-uxe9luxe9mentaires-duxe9lectronique}}

Les chapitres précédents nous ont permis d'aborder un certain nombre de
notions fondamentales sur le son ainsi que sur l'acoustique des salles.
Nous allons maintenant aborder quelques notions d'électricité et
d'électronique. Le but n'est pas de savoir lire un schéma électronique,
ou de comprendre comment réaliser tel ou tel circuit, mais bien
d'aborder les quelques notions indispensables pour le travail du son.

Durant tout son trajet dans le milieu analogique, le signal sonore est
représenté par un courant électrique. Il est donc régi par les mêmes
règles que n'importe quel autre courant, même s'il possède une certaine
spécificité, comme son oscillation. Un courant électrique se caractérise
par le déplacement d'électrons dans un matériau conducteur (le métal par
exemple). Un matériau, comme le plastique, qui ne permet pas aux
électrons de se déplacer, est qualifié d'\textbf{isolant}.

\begin{quote}
Les électrons font partie des composants de l'atome. Ils sont chargés
négativement et se déplacent donc dans le sens inverse du courant.
\end{quote}

\hypertarget{les-grandeurs-physiques}{%
\section{Les grandeurs physiques}\label{les-grandeurs-physiques}}

Commençons par aborder les grandeurs physiques liées à l'électricité.

\hypertarget{lintensituxe9}{%
\subsection{L'intensité}\label{lintensituxe9}}

L'intensité électrique, notée \textbf{I} et exprimée en \textbf{Ampère
(A)}, est une grandeur permettant de mesurer le débit du courant
électrique. Ceci est parfaitement analogue à un débit d'eau. Si un
robinet est faiblement ouvert, l'écoulement de l'eau sera faible, s'il
est complètement ouvert, le débit sera fort.

\hypertarget{la-tension}{%
\subsection{La tension}\label{la-tension}}

La tension, généralement notée \textbf{U} et exprimée en \textbf{Volt
(V)}, désigne une différence de potentiel entre deux points d'un
circuit. Imaginons deux réservoirs d'eau, remplis d'un volume différent
et connectés par une valve. Dans ce cas, la différence de potentiel
serait la différence du volume d'eau entre les deux réservoirs. En
d'autres termes, s'il n'y a pas de tension, il n'y a pas de débit.

\begin{quote}
On choisit, en général, la masse, valant zéro volt, comme point de
référence.
\end{quote}

Dans le cas de l'audio, la tension électrique du signal sonore est
homologue à la variation de pression.

Tout comme la pression acoustique, il est possible de rendre compte
d'une variation de tension électrique à un niveau sonore en décibel. Le
relation liant la tension et le niveau est :

\[ L_{dB} = 20 \, log (\frac{U}{U_{ref}}) \]

Il existe plusieurs valeurs pour U\_\{ref\}, donnant lieu à différentes
unités de mesures :

\begin{itemize}
\tightlist
\item
  \textbf{dBm}, définie à l'apparition du téléphone, propose
  \(U_{ref} = 0.775 V\) pour une impédance de \(600 \omega\). Cette
  impédance correspond à celle des lignes téléphoniques.
\item
  \textbf{dBu} / \textbf{dBv}, qui ne tient plus compte de la charge
  d'impédance, \(U_{ref} = 0.775 V\).
\item
  \textbf{dBV}, où \(U_{ref} = 1 V\)
\end{itemize}

\begin{quote}
Lorsque la tension double, le niveau augmente de six décibels. Lorsque
la tension est multiplié par dix, le niveau augmente de vingt décibels.
\end{quote}

On peut également définir l'augmentation du niveau sonore par rapport à
la puissance du signal. On admet que :

\[ P = \frac{U^2}{Z} \, U = \sqrt{P \times Z} \]

Où \(P\) est la puissance. En remplaçant dans l'équation précédente, on
trouve :

\[ L_{dB} = 20 \, log (\frac{\sqrt{P}}{\sqrt{P_{ref}}}) \> = 10 \, log (\frac{P}{P_{ref}}) \]

\begin{quote}
Lorsque la puissance double, le niveau augmente de trois décibels.
Lorsque la puissance est multiplié par dix, le niveau augmente de dix
décibels.
\end{quote}

On utilisant la loi d'ohm (voir ci-dessous) et la relation entre la
puissance, la tension et l'impédance, on trouve également que :

\[ P = U \times I \]

\hypertarget{limpuxe9dance}{%
\subsection{L'impédance}\label{limpuxe9dance}}

Nous connaissons, en général, la \textbf{loi d'Ohm}. Celle-ci permet de
donner une relation entre l'intensité du courant et sa tension, aux
bornes d'un composant d'un circuit (aussi appelé dipôle).

\[ U = R \times I \]

Où \(R\) est la résistance du dipôle. Elle traduit la facilité d'un
courant à se déplacer dans le dipôle. Pour reprendre les analogies
ci-dessus, la résistance correspondrait à une valve. À tension
constante, si la résistance tend vers zéro, le débit est très important.
Si la résistance tend vers l'infini, le débit sera très faible. Si elle
est nulle, alors nous sommes dans le cas d'un court-circuit
(interrupteur fermé). Si elle est infinie, cela traduit une absence de
connexion entre deux points d'un circuit (interrupteur ouvert). L'unité
de cette résistance est l'\textbf{ohm}.

L'impédance traduit elle aussi l'opposition d'un circuit au passage d'un
courant électrique, mais dans le cas d'une \textbf{tension oscillante}.
Dès lors, l'impédance englobe les effets de résistance, de capacitance
et d'inductance (voir ci-dessus).

\hypertarget{les-composants-uxe9lectroniques}{%
\section{Les composants
électroniques}\label{les-composants-uxe9lectroniques}}

\hypertarget{les-composants-passifs}{%
\subsection{Les composants passifs}\label{les-composants-passifs}}

\begin{figure}

\begin{minipage}[b]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[b]{0.40\linewidth}

{\centering 

\includegraphics{index_files/mediabag/generalites/../_resources/diagrams/resistor.pdf}

}

\end{minipage}%
%
\begin{minipage}[b]{0.40\linewidth}

{\centering 

\includegraphics{index_files/mediabag/generalites/../_resources/diagrams/resistor_sym.pdf}

}

\end{minipage}%
%
\begin{minipage}[b]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%

\caption{\label{fig-resistances}Représentation d'une résistance et de
son symbole}

\end{figure}

Étudions maintenant les composants électroniques les plus communs. Nous
avons en premier les \textbf{résistances}. Ce sont des dipôles purement
résistifs. Leur valeur s'exprime en \textbf{ohm}. Une résistance
s'oppose donc au passage du courant. Pour rappel, la tension a ses
bornes est \(U = R \times i\).

\begin{figure}

\begin{minipage}[b]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[b]{0.40\linewidth}

{\centering 

\includegraphics{index_files/mediabag/generalites/../_resources/diagrams/capa.pdf}

}

\end{minipage}%
%
\begin{minipage}[b]{0.40\linewidth}

{\centering 

\includegraphics{index_files/mediabag/generalites/../_resources/diagrams/capa_sym.pdf}

}

\end{minipage}%
%
\begin{minipage}[b]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%

\caption{\label{fig-capa}Représentation d'un condensateur et de son
symbole}

\end{figure}

Viennent ensuite les \textbf{condensateurs}. Ils sont constitués de
matériaux conducteurs séparés par une couche isolante. La relation entre
tension et intensité à ses bornes en régime oscillant est :

\[ U = Z_c \times I \]

Où \(Z_c\) est l'impédance d'un condensateur idéal. Nous pouvons ici la
même analyse que plus haut, quand \(Z_c\) tend vers l'infini le courant
ne passe plus, quand \(Z_c\) tend vers 0, le débit est important.
L'impédance d'un condensateur est fonction de sa \textbf{capacité} (noté
\textbf{C}, et s'exprime en \textbf{farads}).

\[ Z_c = \frac{1}{jC\omega} \> = 2 \pi \, f\]

Si la fréquence \(f\) tend vers l'infini, \(Z_c\) tend vers zéro, si la
fréquence tend vers zéro, \(Z_c\) tend vers l'infini. On constate donc
que l'impédance d'un condensateur varie en fonction de sa fréquence. On
peut assimiler un condensateur à un interrupteur ouvert en basse
fréquence et à un interrupteur fermé en haute fréquence.

\begin{figure}

{\centering \includegraphics[width=0.25\textwidth,height=\textheight]{index_files/mediabag/generalites/../_resources/diagrams/inductor_sym.pdf}

}

\caption{Symbole d'une bobine}

\end{figure}

Terminons sur les bobines. Ces composants sont constitués d'un
enroulement de câble en cuivre et possède une \textbf{inductance} notée
\textbf{L} et s'exprimant en \textbf{henrys}. Étudions à nouveau la
relation entre tension et intensité, aux bornes d'une bobine :

\[ U = Z_L \times I \]

Où \(Z_L\) est l'impédance d'une bobine idéale. Cette impédance se
calcule grâce à la relation suivante :

\[ Z_L = j\omega L = 2 \pi \, f \]

Si la fréquence \(f\) tend vers l'infini, \(Z_L\) tend vers l'infini. Si
\(f\) tend vers zéro, alors \(Z_L\) tend vers zéro. On observe donc le
comportement inverse du condensateur. Une bobine se comporte comme un
court-circuit en basse fréquence et comme un interrupteur ouvert en haut
fréquence.

\begin{quote}
On admet j comme un outil mathématique permettant de simplifier
certaines écritures et certains calculs. On l'appelle le nombre
complexe, tel que \(j^2 = -1\). Dans nos applications, sa présence dans
les relations des impédances de condensateur et de bobine implique un
déphasage de \(-\frac{\pi}{2}\) pour un condensateur, et, de
\(\frac{\pi}{2}\) pour une bobine.
\end{quote}

L'association de résistances, de condensateurs et de bobines donne des
circuits RL, RC où RLC, permettant de réaliser des \textbf{opérations de
filtrage} sur le signal.

\hypertarget{tubes-semi-conducteurs}{%
\subsection{Tubes \& semi-conducteurs}\label{tubes-semi-conducteurs}}

\begin{figure}

\begin{minipage}[t]{0.11\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.26\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{generalites/../_resources/bitmap/elec/tube.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.26\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{generalites/../_resources/bitmap/elec/transistor.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.26\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{generalites/../_resources/bitmap/elec/ic.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.11\linewidth}

{\centering 

~

}

\end{minipage}%

\caption{\label{fig-composants}Tubes, transistor et circuits intégrés}

\end{figure}

Les \textbf{tubes}, tubes à vide, ou parfois, lampes, sont
historiquement les premiers composants permettant d'amplifier le signal,
contre une certaine tension d'alimentation. On les retrouve donc dans
les préamplificateurs, égaliseurs, compresseurs, et autres
amplificateurs jusque dans les années soixante. Ils sont alors
progressivement remplacés par les \textbf{transistors}, composants
appelés \textbf{semi-conducteurs}. Ces transistors permettent de
réaliser la même amplification du signal qu'une lampe, mais sont
beaucoup plus petits et demandent aussi moins de puissance électrique
pour réaliser le même facteur d'amplification (aussi appelé
\textbf{gain}). Peu de temps après la mise au point des transistors, les
\textbf{circuits intégrés} sont inventés. Ces petites boîtes renferment
plusieurs transistors, et peuvent également servir à l'amplification de
signaux.

Il est très important de savoir que l'invention du transistor et des
circuits intégrés est sans doute l'avancée technologique la plus
importante du siècle dernier. Elle a permis le développement exponentiel
de l'industrie informatique grâce à la miniaturisation des composants.

L'utilisation de tubes, de transistors ou de circuits intégrés au sein
des machines audio, est souvent associée à une certaine «~couleur~». Il
y aurait donc un son des tubes, un son des transistors et un son des
circuits intégrés. Les différences entre ces dipôles apparaissent
principalement dans les zones de \textbf{non-linéarité} des composants,
typiquement dans leur zone de saturation. La saturation apparaît lorsque
la tension du signal amplifiée dépasse la tension d'alimentation du
composant responsable de cette amplification. On observe alors
l'apparition de certaines harmoniques. La distribution des harmoniques
générés est différente en fonction du dipôle utilisé.

Il est compliqué d'attribuer une couleur sonore particulière à un
composant. En effet, le comportement d'un composant est fondamentalement
conditionné par la topologie du circuit dans lequel il est utilisé ainsi
que par les autres composants qui l'entourent. Il convient donc, à
l'humble avis de l'auteur, d'être relativement prudent sur des
expressions telles que «~son des tubes~» ou «~son des transistors~»,
particulièrement quand il s'agit de dire que l'une des technologies
«~sonnerait mieux~» que l'autre. L'histoire de l'électronique musicale
regorge d'exemples et de contre-exemples pour chacune de ces
affirmations.

\hypertarget{linfluence-de-limpuxe9dance-entre-diffuxe9rents-appareils.}{%
\section{L'influence de l'impédance entre différents
appareils.}\label{linfluence-de-limpuxe9dance-entre-diffuxe9rents-appareils.}}

Sur la fiche technique des appareils, on trouve des valeurs pour son
impédance d'entrée et son impédance de sortie. Imaginons que nous
connections un appareil A dans un appareil B. En pratique, nous faisons
en sorte que l'impédance de sortie de l'appareil A soit dix fois
inférieure à l'impédance d'entrée de l'appareil B. À partir du moment où
ces impédances sont proches, voire que l'impédance de sortie de A soit
plus grande que celle d'entrer de B, nous allons atténuer le signal
transitant entre les deux appareils. Étudions de plus près ce phénomène.

Soit le schéma électronique ci-dessous. On appelle \(U_{out}\) la
tension de sortie de l'appareil A et \(Z_{out}\) son impédance de
sortie. De façon similaire, on appelle \(U_{in}\) la tension d'entré de
l'appareil B et \(Z_{in}\) son impédance d'entré.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/generalites/../_resources/diagrams/impedance.pdf}

}

\end{figure}

Dans ce circuit, \(Z_{eq} = Z_{in} + Z_{out}\) et
\(U_{out} = Z_{eq} \times i\). Alors,
\(i = \frac{U_{out}}{Z_{eq}} = \frac{U_{out}}{Z_{in} + Z_{out}}\).
Toujours grâce au circuit ci-dessus, on peut dire que
\(U_{in} = Z_{in} \times I\). En remplaçant dans l'expression précédente
on trouve : \(\frac{U_{in}}{Z_{in}} = \frac{U_{out}}{Z_{in} + Z_{out}}\)

\[ \frac{U_{in}}{U_{out}} = \frac{Z_{in}}{Z_{in} + Z_{out}} = \frac{1}{1+\frac{Z_{out}}{Z_{in}}} \]

Dès lors, si \(Z_{in}\) est très grand devant \(Z_{out}\), alors
\(U_{in}\) tend vers \(U_{out}\). Si \(Z_{out}\) est très grand devant
\(Z_{in}\), alors \(U_{in}\) tend vers \(0\).

Cela nous amène à démontrer l'affirmation ci-dessus. Maintenant, nous
savons que dans un circuit, l'impédance varie en fonction de la
fréquence. Dès lors, une mauvaise adaptation d'impédance ne fera pas que
diminuer l'amplitude du signal, mais filtrera aussi une partie de
spectre, généralement les hautes fréquences.

\begin{quote}
On considère aussi l'adaptation d'\textbf{impédance en tension}. Lorsque
que nous considérons la \textbf{puissance} les relations sont
différentes (cf section sur les hautparleurs).
\end{quote}

\hypertarget{description-dune-production-musicale-type}{%
\chapter{Description d'une production musicale
type}\label{description-dune-production-musicale-type}}

Afin de comprendre quels vont être les enjeux du preneur de son, il
convient de comprendre dans quel contexte il intervient. Certes, il est
le premier métier du son à rentrer en scène, mais l'œuvre à enregistrer
a déjà très probablement eu une longue vie. Elle a été composée,
arrangée, peut-être même déjà interprétée au cours de concerts.

À ce stade, le preneur de son aura un regard neuf sur la matière. Il
aura donc le potentiel de permettre aux créateurs de prendre du recul
sur leur travail. Il convient d'ailleurs de rappeler qu'un preneur de
son, aussi talentueux et créatif soit il, est un \textbf{assistant de
création}. Cela signifie qu'il met à disposition une compétence
technique à un d'artiste pour lui permettre d'avancer sur son projet.
Cela implique également que celui ou celle qui a le mot final sur le
choix des orientations esthétiques est l'artiste en question. Il
convient donc, en tant que preneur de son, d'être force de proposition,
tout en sachant respecter le choix (qu'ils soient bons ou mauvais) des
artistes.

D'un point de vue sonore, le travail de prise de son est absolument
critique. Ce sera à ce moment que va se jouer la majorité des choix
esthétiques. Il convient donc de réunir les conditions optimales pour~:

\begin{itemize}
\tightlist
\item
  offrir aux musiciens et musiciennes la chance de donner leur meilleure
  interprétation possible
\item
  réaliser une prise de son en adéquation avec l'orientation esthétique
  du projet
\end{itemize}

La plupart des choix faits à la prise de son ne pourront pas être
renégociés a posteriori. Il convient donc de mettre d'accord les
artistes, le directeur artistique et le preneur de son sur les moyens à
mettre en œuvre.

\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{index_files/mediabag/generalites/../_resources/diagrams/productionSonore.pdf}

}

\caption{\label{fig-prod-mus}Entonnoir de la production musicale}

\end{figure}

\hypertarget{les-acteurs-de-la-ruxe9alisation-dune-ux153uvre-enregistruxe9e}{%
\section{les acteurs de la réalisation d'une œuvre
enregistrée}\label{les-acteurs-de-la-ruxe9alisation-dune-ux153uvre-enregistruxe9e}}

Nous allons ici rapidement discuter des différents rôles apparaissant
dans la production d'une œuvre musicale enregistrée. Ceux-ci sont
volontairement très séparés, bien que dans les cas pratiques, une
personne puisse en incarner plusieurs.

\textbf{Le compositeur} est la personne qui a composé la mélodie et
l'harmonie de l'œuvre.

\textbf{L'arrangeur} est chargé de l'orchestration (choix des
instruments) et l'écriture des différentes partitions.

\textbf{L'interprète} a la responsabilité de retranscrire une partition
le plus justement possible, à la fois dans sa dimension technique et
sensible.

\textbf{Le directeur artistique} (ou DA) supervise l'ensemble de
l'enregistrement. Il aura, par exemple, à choisir le preneur de son, le
mixeur ou dans quel studio enregistrer. Lors de la session
d'enregistrement, il aura à diriger les musiciens (comme un réalisateur
dirige ses acteurs au cinéma) afin de leur faire jouer la meilleure
interprétation possible pour l'œuvre. Lors du mixage, il sera le
principal interlocuteur du mixeur. Pour faire court~: il est le garant
de l'orientation esthétique du projet.

\textbf{Le producteur} finance l'ensemble de projets. C'est donc un
investisseur qui attend un retour sur investissement.

\begin{quote}
L'appellation abusive de «~producteur~» pour parler du directeur
artistique vient d'un anglicisme du mot «~producer~». Le producteur est
donc bien l'équivalent du directeur artistique dans les pays
anglo-saxons. Si le DA a besoin d'un certain talent, le producteur a
surtout besoin d'argent.
\end{quote}

\textbf{Le preneur de son} est chargé d'enregistrer les musiciens et
musiciennes. Il a donc un rôle premier très technique~: il doit inscrire
sur un support les ondes sonores produites par ces musiciens. Il a
également un rôle esthétique très important, d'un point de vue sonore,
car le choix du dispositif de prise de son aura un fort effet sur la
suite de la vie de l'œuvre.

\textbf{Le mixeur} intervient après la prise de son et doit réaliser une
sommation de l'ensemble des points de captations (microphone) vers un
format écoutable par le grand public (mono, stéréo, 5.1, Ambisonique,
Dolby Atmos, etc.). Son rôle esthétique est fortement contraint par le
travail de prise de son. Si celle-ci est réussie, il pourra amplifier et
bonifier les choix de production. Dans le cas contraire, il devra lutter
pour essayer de faire sortir le meilleur d'une matière imparfaite.

\textbf{Le technicien de mastering} est le dernier maillon de la chaîne.
Son rôle premier sera de préparer le travail de mixage à aux supports de
diffusion. Il se devra également d'offrir une oreille nouvelle sur le
travail réalisé au mixage.

\hypertarget{la-pruxe9production}{%
\section{La préproduction}\label{la-pruxe9production}}

La préproduction concerne toutes les étapes d'une œuvre enregistrée qui
ont lieu avant ledit enregistrement. On parlera donc en premier lieu de
la composition et particulièrement de l'arrangement.

La qualité d'un arrangement aura une influence énorme sur la facilité à
mixer une œuvre. Si les instruments sont astucieusement répartis sur
l'ensemble du spectre sonore, cela sera une difficulté de moins à gérer
au mixage par exemple.

Il est aussi courant pour des artistes de réaliser des «~démos~».
Celles-ci sont souvent des enregistrements réalisés en home studio afin
de définir un cap esthétique pour la suite de la production sonore.
C'est un atout extrêmement précieux pour un preneur de son, cela permet
de rapidement identifier quel est le projet esthétique de l'œuvre.

\hypertarget{la-production}{%
\section{La production}\label{la-production}}

C'est ici que le travail du preneur de son commence. L'étape de
production consiste à fixer les interprétations définitives. Le premier
objectif est donc de s'assurer du bon enregistrement de tous les canaux
prévus. Bien sûr, l'enjeu n'est pas seulement technique, mais aussi
esthétique. Et il n'est pas moindre, les choix pris lors de la prise de
son seront des carcans impossibles à outrepasser lors de la phase de
mixage. Enfin, l'élément le plus déterminant de cette étape est
d'obtenir des musiciens leurs meilleures interprétations. La présence
d'un directeur artistique est d'une aide précieuse afin de diriger et
d'orienter les musiciens. Il permet aussi de faire le lien entre les
artistes et l'équipe technique, en exprimant les besoins des uns aux
autres.

Sur les projets les plus modestes, le poste de directeur artistique est
souvent sacrifié. Il en va donc à l'ingénieur du son de, parfois,
remplir ce rôle.

\hypertarget{la-postproduction}{%
\section{La postproduction}\label{la-postproduction}}

Arrivé à ce stade, la majorité du travail est déjà accompli, il ne reste
que le mixage et le mastering. Classiquement, chacune de ces tâches
incombe à un technicien différent. Le travail du mixeur consistera à
réaliser la sommation, généralement en stéréo, de l'ensemble des canaux
enregistrés lors de la prise de son. Afin de faire cohabiter tous ces
signaux, il est commun d'utiliser des traitements pour les répartir sur
l'ensemble du spectre et de gérer leur dynamique. Parfois, ces
traitements remplissent un rôle esthétique, en déformant le signal
d'origine pour aboutir à une nouvelle matière.

Une fois le travail du mixeur terminé, le mastering commence. Le but et
d'homogénéiser l'ensemble des titres d'un disque, en volume, en
dynamique et en couleur. Ensuite, il convient aussi de définir le niveau
de sortie général du disque. La dernière étape consistera à monter
l'ordre des morceaux pour le disque, d'y inscrire les métadonnées (nom
de l'artiste, des titres, genre musical, etc.) et de générer le fichier
final, dédier à l'exploitation.

\part{Outils et équipements}

\hypertarget{le-chemin-du-signal}{%
\chapter{Le chemin du signal}\label{le-chemin-du-signal}}

La première mission d'un preneur de son est d'assurer l'arrivée à bon
port des signaux dans l'enregistreur. En effet, toute notion de mise en
scène sonore et d'esthétique devient très secondaire si le contenu n'a
pas été enregistré.

Le diagramme ci-dessous reprend les principaux étages rencontrés par un
signal audio dans un contexte de production numérique. Il est essentiel
d'être le plus familier possible avec ces différents composants.

\begin{figure}

{\centering \includegraphics[width=1\textwidth,height=\textheight]{index_files/mediabag/outils_equipements/../_resources/diagrams/cheminSignal.pdf}

}

\caption{\label{fig-chemin_sig}Le chemin du signal. Elle peut-être
agrandie en ouvrant l'image dans un nouvel onglet.}

\end{figure}

Nous pourrions catégoriser à partir de ce schéma différents «~milieux~».
Tout d'abord, nous avons le \textbf{milieu acoustique}, où nous
trouverons toutes sortes d'instruments de musique, les différents lieux
dans lesquels ils pourront s'y trouver. C'est donc le domaine de l'onde
sonore mécanique.

On trouve ensuite le \textbf{milieu analogique}, où l'onde sonore est
représentée, de façon analogue, par des grandeurs électriques. Celles
d'un signal sonore dans un circuit analogique sont fonction, par
exemple, de la variation de la pression atmosphérique provoquée en un
point par une onde sonore. Les éléments clefs du milieu analogique sont
les préamplificateurs et les amplificateurs, mais on trouve aussi
certains traitements, comme les égaliseurs et les compresseurs. On
définira «~analogique~» comme une représentation dans laquelle les
grandeurs (tension, courant, etc.) qui entrent dans les calculs sont
représentées par des grandeurs analogues et qui varient de manière
identique (définition du
\href{https://www.cnrtl.fr/definition/analogique}{CNRTL}).

Pour passer du milieu acoustique au milieu analogique, et vice-versa, on
utilise des microphones et des haut-parleurs. Tous deux sont des
\textbf{transducteurs}, permettant de transformer une énergie en une
autre. Le microphone transforme une énergie mécanique en énergie
électrique. Le haut-parleur réalise l'opération inverse.

On en vient ensuite au \textbf{milieu numérique}. Fondamentalement, le
signal est toujours de nature électrique, mais il a subi une opération
très importante nommée \textbf{échantillonnage}. On a donc mesuré à
intervalle régulier la tension électrique générée par l'onde sonore. Le
passage par le numérique permet une myriade de traitements sur le
signal, beaucoup plus complexes que ceux permis par l'électronique
analogique. L'audio numérique permet aussi un stockage de l'information
à moindre coût et l'acheminement d'un grand nombre de voies (canaux)
grâce à un faible nombre de modulations (câble).

L'appareil permettant de passer du milieu analogique au milieu numérique
est le \textbf{convertisseur analogique/numérique}. Il ne s'agit pas
d'un transducteur, car les signaux d'entrées et de sorties sont de même
nature électrique. Pour opérer l'opération inverse, on utilise un
\textbf{convertisseur numérique/analogique.}

Le \textbf{milieu informatique} nous permet d'utiliser des applications
relatives aux traitements du son par le biais d'ordinateurs. Il s'agit
aujourd'hui indubitablement de notre outil de travail principal. Nous y
réalisons la grande majorité des traitements audio, ainsi que
l'enregistrement et le routage des sources.

Le lien entre un ordinateur et un convertisseur A/N/A se fait grâce à un
\textbf{bus de sérialisation} associé à un \textbf{pilote} (ou
\textbf{driver}). L'ensemble des deux permet de mettre en forme la
donnée numérique et de la rendre compréhensible à l'ordinateur.

Chaque élément évoqué ci-dessus sera abordé dans des sections dédiées
dans la suite de ce livre.

\hypertarget{les-microphones}{%
\chapter{Les microphones}\label{les-microphones}}

Un microphone est un \textbf{transducteur} permettant de transformer une
onde acoustique en signal électrique. Cette opération est réalisée par
une membrane. Selon la nature du microphone, cette membrane pourra être
constituée d'une feuille métallique d'un condensateur ou encore être
rattachée à une bobine.

Le microphone est l'outil principal du preneur de son. Le choix du
modèle et sa position dans l'espace est déterminants sur le rendu sonore
d'une captation. Ces deux paramètres ont par ailleurs une certaine
interdépendance~: une position souhaitée du microphone pouvant
influencer le choix du modèle et vice-versa.

\hypertarget{petit-historique-des-microphones}{%
\section{Petit historique des
microphones}\label{petit-historique-des-microphones}}

Sans vouloir rentrer dans un récit exhaustif sur l'invention et
l'évolution des microphones, relater les moments clefs de cette
technologie permet d'avoir une vision globale du marché d'aujourd'hui.

La nécessité de capter un évènement sonore grâce à un microphone
provient de trois besoins~:

\begin{itemize}
\tightlist
\item
  le transmettre (télécommunication)
\item
  l'amplifier (concert, spectacle vivant)
\item
  l'enregistrer (industrie du disque)
\end{itemize}

En 1876, Alexandre Graham Bell propose un système à base liquide,
permettant de transformer une onde sonore en tension électrique. Le
système ne fut jamais réellement exploité, car le rendu sonore était
jugé trop peu satisfaisant.

Le premier type de microphone utilisé industriellement est le
\textbf{microphone à charbon} (au UK, par David Edward Hugues, aux US
par Emile Berliner et Thomas Edison. Le brevet sera d'ailleurs disputé,
avec un gain de cause pour Edison malgré des démonstrations publiques de
Hugues antérieur aux publications d'Edison). En raison de sa faible
bande passante et de son niveau de bruit élevé, il se révèle de piètres
qualités pour l'enregistrement et la transmission de la musique. Il
aura, par contre, une place de choix dans les téléphones durant de
longues décennies.

Un premier brevet, peut-être même le premier, pour un \textbf{microphone
dynamique} à bobine mobile est attribué à l'ingénieur et industriel
allemand Ernst Werner von Siemens en 1877. La technologie de la bobine
mobile a été mise en pratique dans les années 1920 lorsque la
Marconi-Sykes Company a créé le magnétophone pour la radio britannique.
Ils s'imposent d'abord dans le monde du concert, dès les années 40, pour
leur grande résistance mécanique.

Viennent ensuite les \textbf{microphones à condensateur}, dont les
premiers modèles remontent à 1916, par le chercheur Edward Wente. Ces
microphones sont tout d'abord réputés assez capricieux, leurs réponses
en fréquences pouvant varier significativement en fonction de l'humidité
de l'air et de la température.

À cause de ces variations sonores présentes dans les premiers
microphones à condensateur, on leur préférera un temps les
\textbf{microphones à ruban}. Ils sont inventés en 1923 par Harry Olson.
Ils sont par contre d'une grande fragilité mécanique.

George Neumann est un des noms à connaître dans cette histoire des
microphones. On lui doit, entre autres, la stabilisation des microphones
statiques. Il sera aussi le premier à produire un microphone (U87)
utilisant un transistor en lieu et place des traditionnels tubes.

À partir des années 1970, les microphones dynamiques sont adoptés en
studio d'enregistrement, notamment portés par la marque Shure. Ces
microphones ont la grande qualité d'être très robustes, et remplaceront
leurs homologues à ruban dans bien des cas.

Depuis, les principales améliorations ont concerné la robustesse d'une
part, et la miniaturisation des dispositifs d'autre part, menant ainsi
au développement des capsules MEMS.

\hypertarget{les-types-et-technologies-de-microphones}{%
\section{Les types et technologies de
microphones}\label{les-types-et-technologies-de-microphones}}

Avant d'aborder en détail certaines constructions de microphones, il
convient de faire attention à certains raccourcis associant des méthodes
de fabrications à un niveau présumé de qualité. Par exemple, il est
commun d'associer les microphones à électret à une construction «~bas de
gamme~». Or, c'est oublier que la série 4000 de chez DPA, considérée par
beaucoup comme une référence indétrônable de la prise de son, ne
contient que des microphones à électret. Les MEMS souffrent du même
biais, ceux-ci se retrouvent pourtant de plus en plus souvent sur des
microphones ambisoniques, comme le Zyla ou le SPC mic.

Nous allons maintenant aborder les types de microphones suivants~:

\begin{itemize}
\tightlist
\item
  Les microphones électrostatiques/à condensateur
\item
  Les microphones à ruban
\item
  Les microphones dynamiques
\end{itemize}

\hypertarget{les-microphones-uxe9lectrostatiquesuxe0-condensateur}{%
\subsection{Les microphones électrostatiques/à
condensateur}\label{les-microphones-uxe9lectrostatiquesuxe0-condensateur}}

\begin{figure}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/u87.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/cmc64.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/cm4.jpg}

}

}

\end{minipage}%

\caption{\label{fig-mic_stat}Neumann U87, Schoeps CMC64, Line Audio CM4}

\end{figure}

Ce sont, historiquement, les premiers microphones à permettre une
captation du spectre audible satisfaisante. Ils sont cependant très
sensibles aux conditions de température et d'humidité et il fallut
attendre les années trente pour que ce problème cesse. Ils nécessitent
une alimentation externe, appelée alimentation fantôme, normalisée à
+48V. Il existe deux familles de microphones électrostatiques, les
\textbf{condensateurs à hautes fréquences} et \textbf{condensateur
polarisés en courant continu}.

Les microphones à condensateur polarisés en courant continu ont le
fonctionnement le plus commun. Un courant continu vient polariser la
capsule/condensateur. Lorsqu'une onde sonore rencontre la capsule, une
de ses armatures se déforme et génère une variation de tension analogue
à la variation de pression.

Les microphones à condensateur à haute fréquence proposent une approche
différente. Un oscillateur est intégré dans le microphone et la
variation de pression enregistrée par le condensateur vient moduler la
fréquence de cet oscillateur. Le signal est ensuite démodulé dans la
plage audible. Cette méthode de construction offre une impédance de
sortie plus faible et une plus grande résistance aux variations de
conditions climatiques.

Concernant leurs caractéristiques, ces microphones possèdent des
réponses en fréquence souvent très linéaire et une excellente réponse en
transitoire. Leur niveau de sortie (sensibilité) est élevé. Leur
impédance de sortie est basse.

Exemples~: Neumann~U87/AKG C414/Shoeps CMC4/Série 4000 DPA/Série MKH
Sennheiser

\hypertarget{les-microphones-uxe0-ruban}{%
\subsection{Les microphones à ruban}\label{les-microphones-uxe0-ruban}}

\begin{figure}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/r121.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/vinjet.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/coles.jpg}

}

}

\end{minipage}%

\caption{\label{fig-mic_rub}Royer R121, Cascade Vinjet, Coles 4038}

\end{figure}

Les microphones à ruban souvent préférés à leurs homologues statiques
dans les débuts de la musique enregistrée. Leur fonctionnement repose
sur l'utilisation d'une feuille métallique placée entre deux aimants.
Lorsqu'une onde sonore rencontre cette feuille (le ruban), celle-ci
vibre et perturbe le champ électromagnétique créé par les aimants et
génère une tension analogue à la variation de pression.

D'un point de vue sonore, les microphones à ruban ont souvent un bas du
spectre assez généreux et une réponse plutôt douce pour les hautes
fréquences. Ils sont aussi connus pour avoir une impédance de sortie
assez élevée et un niveau de sortie faible. Attention à l'alimentation
fantôme (+48V), elle peut endommager le microphone.

Exemples~: Royer R121/Cohles/Beyerdynamic M160

\hypertarget{les-microphones-dynamiques}{%
\subsection{Les microphones
dynamiques}\label{les-microphones-dynamiques}}

\begin{figure}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/sm57.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/re20.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/mic/md441.jpg}

}

}

\end{minipage}%

\caption{\label{fig-mic_dyn}Shure SM57, Electro-Voice RE20, Sennheiser
MD441}

\end{figure}

Les microphones dynamiques sont conçus pour des conditions d'utilisation
rudes, où les niveaux sonores sont élevés et où le risque de chute est
important. Ils sont donc monnaie courante en sonorisation. Leur membrane
est attachée à une bobine entourant un aimant. Lorsqu'une onde sonore la
met en vibration, la bobine se déplace autour de l'aimant, et, par
perturbation du champ électromagnétique, génère une tension de sortie
analogue à la variation de pression.

Leur réponse en fréquence est souvent accidentée, particulièrement dans
le haut du spectre. Cela peut être vu comme un inconvénient ou comme un
outil de «~coloration~» du son. Comme leurs homologues à ruban, ils
possèdent un niveau de sortie faible et une impédance de sortie élevée.

Exemples~: Shure~SM57/Electrovoice~RE20/Sennheiser~MD441

\hypertarget{la-taille-des-membranes}{%
\subsection{La taille des membranes}\label{la-taille-des-membranes}}

La taille des membranes influe sur la captation du son. Plus la capsule
est grande, plus les fréquences aiguës seront diffractées et donc
atténuées dans la prise de son. Un microphone à petite membrane est donc
techniquement un microphone plus «~juste~». Cependant, l'emploi de large
membrane permet aussi d'adoucir un surplus d'énergie dans le haut du
spectre.

\hypertarget{microphones-uxe0-tubes-ou-transistors}{%
\subsection{Microphones à tubes ou
transistors?}\label{microphones-uxe0-tubes-ou-transistors}}

Historiquement, les tubes ont été les premiers composants électroniques
à permettre l'amplification du signal. Le transistor est apparu à la fin
des années 40 et a permis de remplir les mêmes fonctions qu'un tube, par
une consommation moindre et avec un encombrement beaucoup plus faible.

Certains microphones continuent à être fabriqués avec des tubes,
préférant leur comportement vis-à-vis du son. Une écrasante majorité est
cependant fabriquée avec des transistors.

Le choix entre un microphone à tube et un microphone à transistor semble
cependant anecdotique par rapport à son type, à son placement et à sa
directivité.

\hypertarget{timbre-et-directivituxe9}{%
\section{Timbre et directivité}\label{timbre-et-directivituxe9}}

La directivité d'un microphone permet de décrire sa capacité à réaliser
une «~écoute~» sélective de son environnement. On rencontre les
directivités suivantes~:

\begin{itemize}
\tightlist
\item
  Omnidirectionnel~: capte l'ensemble du champ sonore de façon
  indifférenciée.
\item
  Hypercardioïde~: compromis entre Omnidirectionnel et cardioïde.
\item
  Cardioïde~: capte à l'avant, mais rejette à l'arrière du microphone.
\item
  Supercardioïde~: ressers la zone d'écoute avant au prix de
  l'apparition d'une résurgence arrière.
\item
  Hypercardioïde~: ressers davantage la zone d'écoute et augmente
  d'autant plus la résurgence arrière.
\item
  Bidirectionnel : capte à l'avant et à l'arrière, mais selon un lobe
  plus resserré qu'en cardioïde.
\end{itemize}

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\begin{figure}

{\centering 

\begin{verbatim}
Unable to display output for mime type(s): text/html
\end{verbatim}

}

\caption{\textbf{?(caption)}}

\end{figure}

\begin{figure}

{\centering 

\begin{verbatim}
Unable to display output for mime type(s): text/html
\end{verbatim}

}

\caption{\textbf{?(caption)}}

\end{figure}

}

\caption{\label{fig-dir}\textbf{?(caption)}}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\begin{verbatim}
Unable to display output for mime type(s): text/html
\end{verbatim}

}

\caption{\label{fig-dir2}\textbf{?(caption)}}

}

\end{minipage}%

\end{figure}

Plus la directivité d'un microphone est large, plus la contribution de
l'acoustique est apparente. Le timbre est également aussi linéaire que
possible. À l'inverse, plus la directivité tant à être étroite, plus le
microphone aura une capacité à échantillonner seulement une zone de
l'espace. Le timbre est, par contre, amoindri dans le bas du spectre.
Les microphones omnidirectionnels sont donc les plus larges et les plus
«~neutres~», tandis que les microphones bidirectionnels sont les plus
focalisés et ont la plus importante perte dans le bas du spectre.

Le preneur de son choisit donc une directivité en fonction de la tâche à
accomplir. Les microphones directifs ont l'avantage de limiter la
contribution d'évènements sonores que l'on ne souhaite pas capter. Les
microphones omnidirectionnels ont la faculté d'être un dispositif de
prise de son plus transparent, mais seront beaucoup plus sensibles à une
acoustique moins optimale, ainsi qu'au bruit environnant.

Nous allons par la suite nous intéresser au cœur du microphone : sa
capsule. Il existe deux familles de capsules, celles dites «~à
pression~», et celles dites à «~gradient de pression~».

\hypertarget{capsules-uxe0-pression}{%
\subsection{Capsules à pression}\label{capsules-uxe0-pression}}

Une capsule sensible à la pression est omnidirectionnelle : elle capte
les fluctuations de pressions en un point. Mathématiquement, cette
relation s'exprime, en coordonnées polaires, par :

\[ \theta = 1 \]

L'angle d'incidence de l'onde sonore par rapport au microphone importe
donc peu.

Pour réaliser une capsule à pression, on enferme une partie de la
membrane dans un milieu acoustique à pression constante.

\hypertarget{capsules-uxe0-gradient-de-pression}{%
\subsection{Capsules à gradient de
pression}\label{capsules-uxe0-gradient-de-pression}}

Une capsule à gradient de pression est sensible à la \textbf{variation}
du champ de pression. Ces capsules ne sont plus omnidirectionnelles,
mais bidirectionnelles : elles captent devant et derrière elles.
Mathématiquement, une telle directivité s'exprime par la relation (en
coordonnées polaires) :

\[ \theta = cos(\alpha) \]

Où \(\alpha\) est l'angle d'incidence d'un son par rapport à la capsule.

Pour réaliser une capsule à gradient de pression, il suffit de laisser
exposer les deux faces de la membrane aux variations de pressions.

\hypertarget{et-les-autres-directivituxe9s}{%
\subsection{Et les autres
directivités~?}\label{et-les-autres-directivituxe9s}}

Il est possible, à partir des deux équations ci-dessus, de retrouver
toutes les autres directivités. Par exemple, un microphone cardioïde a
une équation de directivité polaire tel que :

\[ \theta(\alpha) = \frac{1}{2}(1 + cos[\alpha]) \]

Elles découlent donc des deux directivités primaires :
omnidirectionnelle et bidirectionnelle. Pour obtenir une directivité
particulière, il suffit de «~doser~» l'influence de ces deux
directivités. Par exemple, un microphone cardioïde possède une
contribution égale de chacune d'elles. Plus on augmente la proportion de
la directive bidirectionnelle, plus on tend vers un microphone
supercardioïde, voire hypercardioïde. À l'inverse, augmenter la
proportion de la directivité omnidirectionnelle fait tendre le
microphone vers une directivité hypocardioïde.

Il existe deux solutions pour agir sur la contribution des directivités
primaires. La première consiste à utiliser un labyrinthe acoustique pour
changer le milieu acoustique d'une des faces de la membrane. L'autre
consiste à avoir une capsule omnidirectionnelle et une seconde
bidirectionnelle et de sommer leur tension de sortie.

Les microphones à multidirectivité permettent à l'utilisateur d'influer,
soit sur le labyrinthe acoustique, soit sur la sommation des deux
capsules. Il n'est pas rare que ces microphones soient moins performants
qu'un microphone spécifiquement dédié à une seule directivité.

On retiendra donc :

\[ \theta(\alpha) = A + B \cos (\alpha) \> où \> A + B = 1\]

\begin{figure}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/outils_equipements/../_resources/diagrams/Polar-pattern-U-87-Ai-omni.pdf}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/outils_equipements/../_resources/diagrams/Polar-pattern-U-87-Ai-cardioid.pdf}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/outils_equipements/../_resources/diagrams/Polar-pattern-U-87-Ai-figure8.pdf}

}

}

\end{minipage}%

\caption{\label{fig-u87dir}Directivités réelles du microphone (U 87)}

\end{figure}

\hypertarget{directivituxe9s-ruxe9elles-duxe9timbrage}{%
\subsection{Directivités réelles \&
détimbrage}\label{directivituxe9s-ruxe9elles-duxe9timbrage}}

Nous avons jusque là considéré que la directivité d'un microphone était
un phénomène indépendant de la fréquence. Or, cela n'est pas vrai. En
d'autres termes, la directivité d'un microphone n'est pas la même en
fonction de la fréquence de l'onde sonore lui arrivant. Typiquement, un
microphone tendra vers une directivité plus resserrée dans le haut du
spectre, et vers une directivité plus large dans le bas du spectre.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/outils_equipements/../_resources/diagrams/Frequency-diagram-U-87-Ai-omni.pdf}

}

\caption{\label{fig-u87omni}Réponse en fréquence du microphone Neumann
U87 (omnidirectionnel)}

\end{figure}

\begin{figure}

{\centering \includegraphics{index_files/mediabag/outils_equipements/../_resources/diagrams/Frequency-diagram-U-87-Ai-cardioid.pdf}

}

\caption{\label{fig-u87card}Réponse en fréquence du microphone Neumann
U87 (cardioïde)}

\end{figure}

\begin{figure}

{\centering \includegraphics{index_files/mediabag/outils_equipements/../_resources/diagrams/Frequency-diagram-U-87-Ai-figure8.pdf}

}

\caption{\label{fig-u87bidir}Réponse en fréquence du microphone Neumann
U87 (figure en huit)}

\end{figure}

Cela signifie donc que positionner un microphone hors axe face à un
évènement sonore n'aura pas seulement un effet sur le niveau du signal
en sortie du microphone, mais également sur le timbre. On appelle alors
«~\textbf{timbré}~», un évènement sonore capté plein axe par un
microphone, et \textbf{détimbré} un évènement sonore capté hors axe.

Ce phénomène est un outil précieux pour les preneurs de son. Par
exemple, lorsqu'on enregistre une voix, certains sons sont exagérés par
le microphone, particulièrement les «~s~». En tournant légèrement le
microphone pour placer la voix hors axe, on peut déjà grandement
améliorer les problèmes de sifflante avant même de penser à un éventuel
traitement ultérieur.

\hypertarget{transport-de-signaux-analogiques}{%
\chapter{Transport de signaux
analogiques}\label{transport-de-signaux-analogiques}}

Les câbles assurent le transport de signaux électriques. Ces signaux
peuvent représenter une onde sonore (précédemment captée par un
microphone), une valeur de contrôle pour piloter un appareil (pédale
d'expression) ou encore une information numérique (câble USB, ethernet,
etc.). Nous aborderons ici les câbles dédiés aux modulations
analogiques, et tout particulièrement à l'audio.

Le principe de transport d'un signal analogique est assez simple. Pour
une modulation, il faudra au moins un conducteur pour véhiculer le
signal, et un conducteur pour la référence de tension, la masse. Pour
transporter un signal supplémentaire, on conservera le même conducteur
pour la référence et l'on en ajoutera un pour véhiculer le signal
supplémentaire, faisant ainsi un total de trois conducteurs.

\hypertarget{anatomie-dun-cuxe2ble}{%
\section{Anatomie d'un câble}\label{anatomie-dun-cuxe2ble}}

Les câbles véhiculant un seul signal sont généralement constitués de
quatre à cinq composants~:

\begin{itemize}
\tightlist
\item
  d'un cœur composé d'un filament (souvent multibrin) en un métal
  conducteur, véhiculant le signal électrique.
\item
  d'une gaine isolante (plastique) protégeant le cœur
\item
  d'une tresse en cuivre connectée à la masse
\item
  Parfois, d'une feuille de cuivre, enrobant la tresse, permettant de
  réaliser une cage de faraday et de protéger le cœur des ondes
  électromagnétiques.
\item
  Enfin, d'une dernière gaine isolante, permettant de protéger
  l'ensemble du câble.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.6\textwidth,height=\textheight]{index_files/mediabag/outils_equipements/../_resources/drawings/cable.pdf}

}

\caption{\label{fig-cable}Coupe d'un câble}

\end{figure}

Ceux permettant de transporter plus de signaux rajouteront des cœurs
multibrins entourés de leur gaine isolante. La plupart du temps, les
câbles véhiculent un ou deux signaux à la fois, mais certains permettent
d'en acheminer beaucoup plus (multipaire, Sub-D). On appelle un câble en
fonction de ses connecteurs (ou fiches).

\hypertarget{longueur-du-cuxe2ble-son-et-impuxe9dance}{%
\subsection{Longueur du câble, son et
impédance}\label{longueur-du-cuxe2ble-son-et-impuxe9dance}}

Étudions la section d'un câble à modulation unique. Nous pouvons faire
plusieurs observations. Le fil conducteur du signal, généralement en
cuivre, est d'une longueur non négligeable. Plus cette longueur est
importante, plus ce fil aura une \textbf{résistance} importante. De
plus, ce fil est séparé de la tresse de masse (élément également
conducteur) par un isolant. Il existe donc un effet de
\textbf{capacitance} entre le point chaud et la masse. Enfin, la tresse
de masse peut être comparée à une bobine, et possède donc une
\textbf{inductance}. Nous pouvons donc assimiler un câble à un circuit
\textbf{RLC} filtrant le haut du spectre audio.

Physiquement, notre description précédente est valide, mais elle est à
corréler à \textbf{l'impédance de sortie} de la source. Typiquement,
lors de l'utilisation d'un microphone statique, son impédance est
suffisamment faible pour que la longueur du câble soit totalement
transparente. Certains microphones dynamiques ou à ruban, possédant une
impédance plus élevée, peuvent très légèrement souffrir de la longueur
du câble.

Ce phénomène d'altération du timbre à cause de la longueur d'un câble a
surtout lieu avec les instruments électriques \textbf{passifs} (guitares
et basses). L'impédance de sorte de ces instruments est tellement grande
que l'on peut aisément entendre la différence de son entre deux câbles.

\begin{quote}
Il est amusant de constater que certains musiciens utilisent ce
phénomène, et jouent avec des câbles volontairement trop longs, pour
atténuer le haut du spectre. Brian May et Eric Johnson en sont deux
exemples.
\end{quote}

\hypertarget{les-connexions-asymuxe9triques}{%
\subsection{Les connexions
asymétriques}\label{les-connexions-asymuxe9triques}}

Les connexions asymétriques permettent de transporter un signal entre
une source et un récepteur. Il s'agit de la façon la plus simple de
connecter deux appareils devant échanger des signaux. Cependant, sur de
longue distance, le câble peut se comporter comme une antenne et induire
sur le signal certaines ondes électromagnétiques (comme la radio). Ces
connexions ne nécessitent qu'un fil conducteur par modulation.

\hypertarget{les-connexions-symuxe9triques}{%
\subsection{Les connexions
symétriques}\label{les-connexions-symuxe9triques}}

Le but de ces connexions est de palier au problème des connexions
asymétrique. Dans l'appareil émetteur, le signal à transporter est
dupliqué, et ce duplicata est inversé en phase. Cette étape s'appelle la
\textbf{symétrisation}.

C'est deux signaux qui sont appelés point chaud (signal d'origine) et
point froid (signal opposé en phase). Sur le trajet du câble, lorsqu'une
perturbation électromagnétique est induite sur le signal, celle-ci
s'inscrit en phase sur les deux conducteurs (point chaud et point
froid). À l'arrivée, l'appareil récepteur inverse la phase du point
froid et le somme avec le point chaud. Cette étape se nomme la
\textbf{dé-symétrisation}. Ainsi le signal d'origine est sommé en phase,
tandis que les interférences sont sommées hors phase et s'annulent.

Les connexions symétriques nécessitent deux fils conducteurs pour chaque
modulation.

\hypertarget{les-fiches-connecteurs}{%
\section{Les fiches \& connecteurs}\label{les-fiches-connecteurs}}

\begin{figure}

\begin{minipage}[t]{0.20\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/plug/jackTs.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.20\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/plug/jackTrs.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.20\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/plug/jackBantam.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.20\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/plug/xlr.jpg}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.20\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/plug/subd25.jpg}

}

}

\end{minipage}%

\caption{\label{fig-fiches}Jack TS, Jack TRS, Jack Bantam, XLR, Sub-D
25}

\end{figure}

On appelle «~fiche~» les éléments mécaniques situés aux extrémités d'un
câble et permettant sa connexion à un équipement. Celle-ci nous permet
de facilement identifier le type de câble que nous avons entre les
mains.

\begin{quote}
Contrairement aux dires de certains mythes, majoritairement reliée à
l'audiophilie, la différence de matériau utilisé pour le contact de la
fiche n'a pas d'incidence sur le son.
\end{quote}

On rencontre principalement les connectiques jack TS, jack TRS, jack
bantam, XLR et Sub-D. Les fiches jack TS ont deux points de connexion.
Les fiches jack TRS, XLR et bantam en ont deux. Les Sub-D~25 en
possèdent vingt-cinq.

Les fiches jack TS sont souvent utilisées sur les instruments
électriques et électroniques (guitare, basse, synthétiseurs, etc.). Ces
connexions sont nécessairement symétriques. Les jack TRS sont un peu
plus rare et se trouvent généralement sur des instruments avec des
sorties stéréophoniques, ou sur des équipements audio possédant des
entrés/sorties symétriques. La connectique XLR remplit fondamentalement
le même usage qu'un jack TRS, mais offre un verrouillage mécanique,
permettant de sécuriser la connexion. On la trouve principalement sur
les microphones et sur préamplificateurs. L'avantage du jack TRS est son
plus faible encombrement mécanique. On le préfère donc sur les appareils
possédant un grand nombre d'entrées/sorties. Le jack bantam se trouve
sur les boîtiers de patch. Leur petite taille permet une grande densité
de point de connexion. Les patchbay prennent ainsi moins de place. On
trouve aussi les connectiques Sub-D~25, principalement pour remplacer
des connexions XLR. En effet, une seule connectique Sub-D~25 permet de
remplacer huit câbles XLR.

\hypertarget{exemples-pratiques}{%
\section{Exemples pratiques}\label{exemples-pratiques}}

\hypertarget{cuxe2ble-jack-mono}{%
\subsection{Câble jack «~mono~»}\label{cuxe2ble-jack-mono}}

Ce type de câble est souvent utilisé sur les instruments électriques. On
l'appelle «~mono~» car il ne véhicule qu'un seul signal.

\hypertarget{cuxe2ble-jack-stuxe9ruxe9o}{%
\subsection{Câble jack «~stéréo~»}\label{cuxe2ble-jack-stuxe9ruxe9o}}

L'appellation de ce câble est ambiguë. Le terme stéréo fait référence à
ses deux voies de connexion, cependant, le nom «~stéréo~» impliquerait
qu'une des voies est destinée à alimenter l'enceinte gauche, et l'autre,
le canal droit. Or, ce type de câble peut également convenir pour des
connexions symétriques.

\begin{quote}
On notera qu'il est possible de brancher un câble jack TS dans une fiche
TRS. Un seul des canaux sera alors acheminé.
\end{quote}

\hypertarget{cuxe2ble-y}{%
\subsection{Câble «~Y~»}\label{cuxe2ble-y}}

Ces câbles possèdent trois connecteurs, et sont le plus souvent équipés
de jack TS. Ils permettent de récupérer un signal pour le transmettre
sur deux appareils. Attention, la duplication du signal étant passive,
on risque un problème d'impédance si l'impédance d'entrée des deux
appareils est trop différente. Le cas d'école est souvent rencontré
lorsqu'on branche deux casques sur le même amplificateur. Si l'impédance
des deux casques est trop différente, un des deux aura presque
l'intégralité du niveau du signal alors que l'autre sous-modulera.

\hypertarget{les-connexions-dinsert}{%
\subsection{Les connexions d'insert}\label{les-connexions-dinsert}}

Ces câbles ont la particularité d'avoir une fiche jack TRS et deux
fiches jack TS. En studio, on les rencontre très souvent pour insérer un
périphérique de traitement dans la chaîne audio. Le «~tip~» du jack TRS
est connecté au «~tip~» d'un des jack TS qui est connectés sur l'entré
du périphérique. Le deuxième jack TS est raccordé à la sortie de
l'appareil et son «~tip~» est connecté au «~ring~» du jack TRS.

Ces câbles sont aussi utilisés pour séparer une sortie dite «~stéréo~»
en deux voies «~mono~».

\hypertarget{routage-des-signaux}{%
\section{Routage des signaux}\label{routage-des-signaux}}

En studio d'enregistrement, il n'est pas rare de rencontrer plusieurs
cabines de prise de son, chacune équipée de boîtier de patch. Ces
boîtiers sont constitués d'un certain nombre d'entrées XLR. On achemine
ensuite les sorties de ces boîtiers via des multipaires jusqu'à une
«~patchbay~». Le rôle de la «~patchbay~» est de permettre de connecter
n'importe quelle entrée (signal provenant d'un microphone) vers
n'importe quel préamplificateur.

On trouve évidemment beaucoup d'usage à ces «~patchbay~». Elles sont à
considérer comme la matrice de routage d'un studio d'enregistrement.

\hypertarget{les-pruxe9amplificateurs}{%
\chapter{Les préamplificateurs}\label{les-pruxe9amplificateurs}}

Le rôle d'un préampli est de réaliser une amplification en tension du
signal ainsi que de diminuer son impédance. Cette opération est
indispensable pour permettre à notre signal de traverser le reste de la
chaîne du traitement audio.

Dans les débuts de l'enregistrement audio, les préamplificateurs de
microphone étaient des appareils passifs rudimentaires utilisant
généralement un couplage par transformateur pour assurer l'isolation et
adapter l'impédance du microphone au reste du système audio.

Au fur et à mesure que les techniques d'enregistrement progressaient,
les préamplis sont devenus de plus en plus sophistiqués et ont commencé
à intégrer des composants électroniques actifs (tube à vide,
transistors, circuits intégrés). Ces préamplis actifs offrent une plus
grande flexibilité et de meilleures performances.

L'une des principales évolutions de la technologie des préamplis a été
l'avènement de l'électronique à semi-conducteurs, remplaçant ainsi la
technologie des tubes à vide. Ces préamplis à transistors sont plus
petits, plus légers et plus fiables que leurs homologues à tubes, et ils
offrent généralement un bruit plus faible et une gamme dynamique plus
étendue.

Il n'est pas rare que les préamplificateurs soient choisis pour leur
«~couleur~» sur le signal. Nous commencerons par aborder ces outils d'un
point de vue pratique pour enfin déboucher sur cette question.

\hypertarget{informations-techniques-des-pruxe9amplificateurs}{%
\section{Informations techniques des
préamplificateurs}\label{informations-techniques-des-pruxe9amplificateurs}}

Le \textbf{gain} (quantité d'amplification) : Les préamplificateurs pour
microphones fournissent généralement un gain compris entre 20 et 60 dB,
qui est nécessaire pour amplifier les signaux de faible niveau provenant
d'un microphone pour atteindre un niveau utilisable. Le gain d'un
préampli est généralement réglable, ce qui permet à l'utilisateur de
définir le niveau optimal pour un microphone et une application donnés.

L'\textbf{impédance} d'entrée d'un préamplificateur de microphone est un
paramètre critique, car elle détermine la charge imposée par le
préamplificateur au microphone. Une mauvaise adaptation d'impédance peut
provoquer des interactions indésirables entre le microphone et le
préampli, entraînant, entre autre, des modifications de la réponse en
fréquence.

La \textbf{réponse en fréquence} d'un préamplificateur est une
considération importante, car elle détermine la manière dont le
préamplificateur va affecter le son du microphone. Une réponse en
fréquence plate est généralement souhaitable.

Le \textbf{plancher de bruit} d'un préamplificateur est une mesure du
bruit résiduel ajouté au signal par le préamplificateur lui-même. Un
plancher de bruit faible est nécessaire pour maintenir un bon rapport
signal/bruit dans le système audio. Cette donnée est évidemment d'autant
plus critique que le niveau du signal d'entré est faible. Par extension,
on désigne la plage dynamique d'un préamplificateur de microphone comme
la gamme comprise entre le niveau maximal du signal que le
préamplificateur peut accepter et le plancher de bruit.

La distorsion est une mesure des modifications indésirables du signal
audio qui sont introduites par le préampli. De faibles niveaux de
distorsion sont souhaitables, car ils garantissent que le son du
microphone est capturé et amplifié avec précision. On évoquera alors la
\textbf{distortion harmonique}, qui, comme son nom l'indique, augmente
le signal d'entré d'harmoniques supplémentaires. On rencontre aussi
\textbf{la distortion d'intermodulation}. Admettons que nous envoyons en
entrée d'un équipement audio deux sons purs de fréquences F1 et F2. La
distortion d'intermodulation engendre deux nouvelles fréquences F1+F2 et
F1-F2. On cherche donc a maintenir la contribution de ces deux
résurgences le plus bas possible.

Ci-dessous, en guise d'exemple, on trouve le tableau des spécifications
du préampli Rupert Neve Design 511 :

Measured at Main Output, un-weighted, 22 Hz - 22 kHz, source impedance
150 Ohm balanced. Noise performance can vary depending on the 500 series
and / or interference from stray magnetic fields. \textbf{NOISE} Unity
Gain: Better than -103 dBV Gain @ +66 dB: Better than -60 dBV Equivalent
Input Noise: -125 dB

\textbf{FREQUENCY RESPONSE} Main output, no load. +/- 0.1 dBu from 10 Hz
to 31.5 kHz -2.6 dB @ 120 kHz

\textbf{MAXIMUM OUTPUT LEVEL} +23 dBu

\textbf{TOTAL HARMONIC DISTORTION AND NOISE, NO SILK} @ 1 kHz, +20 dBu
output level, no load: Better than 0.0025\% @ 20 Hz, +20 dBu output
level, no load: 0.025\% Typical (2nd and 3rd harmonic)

\textbf{TOTAL HARMONIC DISTORTION AND NOISE WITH SILK ENGAGED} @ 100 Hz,
+20 dBu input level, no load. TEXTURE @ min: 0.015\%, mostly 3rd
harmonic typical TEXTURE @ max: 2\%, mostly 2rd harmonic typical

\textbf{GAIN} Unity up to +66 dB in 6 dB steps. Trim continuously
adjustable from -6 dB to +6 dB.

\textbf{PHANTOM POWER} Supplied by the 500 series rack power supply.
Switch selectable on faceplate.

\textbf{HIGH PASS FILTER} Continuously variable swept frequency from 20
Hz to 250 Hz. Slope: 12 dB/Octave

\textbf{POWER REQUIREMENTS} @ +/-16VDC, 100mA

\hypertarget{crituxe8res-de-choix-dun-pruxe9amplificateur}{%
\section{Critères de choix d'un
préamplificateur}\label{crituxe8res-de-choix-dun-pruxe9amplificateur}}

Le critère de première importance dans le choix d'un préamplificateur
est son gain maximal. Plus l'amplification disponible est grande, plus
le préampli sera capable de répondre à des situations exigeantes, telles
que l'enregistrement d'un évènement sonore à faible niveau, ou l'emploi
d'un microphone à faible sensibilité.

Le second critère important dans le choix d'un préampli est sa réponse
en fréquence. Théoriquement, celle-ci doit être la plus neutre possible.
Une certaine coloration peut être acceptée (voire souhaitée), mais
celle-ci doit rester raisonnable pour répondre à des critères
d'utilisations professionnelles.

La réponse en transitoire est un autre élément important. Certains
préamplis auront tendance à adoucir la sensation d'attaque des sources.
Cet effet n'est pas souhaitable.

Enfin le rapport signal sur bruit doit être le plus grand possible. Nous
cherchons toujours à rajouter le moins de bruit possible sur le chemin
de notre signal.

\hypertarget{les-technologies-de-pruxe9ampli}{%
\section{Les technologies de
préampli}\label{les-technologies-de-pruxe9ampli}}

Nous avons vu dans le chapitre trois qu'il existe trois familles de
composants électroniques permettant d'amplifier le signal : les tubes,
les transistors et les circuits intégrés. On retrouve donc des
topologies de circuit de préamplificateurs utilisant chacun de ces
composants.

Chacune de ces topologies offre de très légère variation de son lorsque
les préamplis sont poussés dans leur retranchement (seuil de
saturation). Comme pour les microphones, il est délicat de parler de son
«~à tube~» ou «~à transistor~». De plus, l'influence sur le son d'un
préamplificateur apparaît en pratique comme très marginale par rapport
au positionnement du microphone.

\hypertarget{les-ruxe9glages-dun-pruxe9ampli}{%
\section{Les réglages d'un
préampli}\label{les-ruxe9glages-dun-pruxe9ampli}}

Un préampli propose souvent les réglages suivants~:

\begin{itemize}
\tightlist
\item
  Un potentiomètre de gain (qui est souvent remplacé par un sélecteur
  cranté, plus précis, pour les modèles haut de gamme).
\item
  Un bouton activant l'alimentation fantôme. En effet, c'est bien le
  préampli qui génère cette tension d'alimentation pour les microphones
  statiques.
\item
  Un bouton d'inversion de phase.
\item
  Un coupe-bas.
\end{itemize}

\hypertarget{la-conversion-analogique-numuxe9rique}{%
\chapter{La conversion analogique
numérique}\label{la-conversion-analogique-numuxe9rique}}

\hypertarget{la-nuxe9cessituxe9-de-la-conversion-analogique-numuxe9rique}{%
\section{La nécessité de la conversion analogique
numérique}\label{la-nuxe9cessituxe9-de-la-conversion-analogique-numuxe9rique}}

Durant toute la période de l'audio analogique, le support de stockage de
prédilection fut la bande magnétique. Cependant, celle-ci n'offre pas un
rapport signal sur bruit très satisfaisant, limitant alors la dynamique
musicale enregistrable. De plus, la bande a également un coût non
négligeable. On a donc cherché à remplacer ce support afin de résoudre
ces deux problèmes. Le stockage numérique offre, sous certaines
conditions, une dynamique bien supérieure à celle des supports
analogiques.

Une représentation numérique de l'audio permet aussi la réalisation de
traitement délicat, voire impossible, en analogique. On pense, par
exemple, aux algorithmes de réverbération, d'écho et de «~pitch
shifting~» (modification de la hauteur d'un son).

Enfin, nos principaux outils de manipulation du son sont aujourd'hui
informatiques. Dès lors, une représentation numérique des signaux est
toute indiquée pour les manipuler grâce à nos ordinateurs. Il en découle
donc une nécessité de bien maîtriser les principes entourant la
numérisation des signaux.

\begin{quote}
En français, le «~digital~» est un anglicisme. Le mot correct est donc
bien «~numérique~», et non «~digital~», qui qualifie ce qui a rapport au
doigt.
\end{quote}

\hypertarget{thuxe9orie-de-luxe9chantillonnage}{%
\section{Théorie de
l'échantillonnage}\label{thuxe9orie-de-luxe9chantillonnage}}

\hypertarget{dun-signal-continu-vers-un-signal-uxe9chantillonnuxe9}{%
\subsection{D'un signal continu vers un signal
échantillonné}\label{dun-signal-continu-vers-un-signal-uxe9chantillonnuxe9}}

Une des caractéristiques principales d'un signal analogique est qu'il
est continu. Une fonction, en mathématique, est dite continue si elle
est définie en n'importe quel instant. Afin d'être numérisé, un signal
doit donc être dénombré. En effet, la notion d'infini imposé par la
continuité du signal n'a pas d'existence en numérique.

La numérisation du signal est comparable à l'utilisation d'un multimètre
pour mesurer une tension. Un convertisseur va prélever la valeur du
signal, de façon régulière, au cours du temps.

Afin de correctement numériser un signal, il convient de définir deux
paramètres~:

\begin{itemize}
\tightlist
\item
  la vitesse de prélèvement, ou \textbf{fréquence d'échantillonnage}
\item
  la plage de valeur permise pour le signal, ou \textbf{résolution de
  quantification}
\end{itemize}

\hypertarget{la-fruxe9quence-duxe9chantillonnage}{%
\subsection{La fréquence
d'échantillonnage}\label{la-fruxe9quence-duxe9chantillonnage}}

Cette fréquence définit le nombre de prélèvements par seconde. Par
exemple, un morceau édité sur un CD audio a une fréquence
d'échantillonnage de 44~100~Hz (44,1~kHz), cela signifie que le signal
est mesuré 44~100~fois par seconde.

La fréquence de travail la plus courante est 48~kHz, mais l'on rencontre
parfois des valeurs supérieures, multiple de celle-ci~: 96~kHz, 192~kHz,
etc. Cette augmentation proportionnelle de la fréquence
d'échantillonnage s'appelle \textbf{suréchantillonnage}. Certains
techniciens espèrent ainsi améliorer la qualité de l'enregistrement. Ce
suréchantillonnage à un coût en ressource CPU et en espace de stockage.
Un flux audio échantillonné à 96~kHz demande deux fois plus de ressource
et d'espace qu'un flux échantillonné à 48~kHz. Cette valeur initiale de
44~100~Hz (ou 48~kHz) n'a pas été choisie au hasard. Pour la comprendre,
il faut revenir au phénomène physique que nous cherchons à numériser.

Rappelons que le son est une onde mécanique, et nous l'entendons
lorsqu'elle oscille dans une plage de fréquence comprise entre 20~Hz
(très grave) et 20~000~Hz (très aigu). Il faut donc que notre système de
numérisation soit capable de reproduire une fréquence maximale allant
jusqu'à 20~000~Hz. Pour cela, nous utilisons les résultats des travaux
des chercheurs Harry Nyquist et Claude Shannon (tous deux ayant
travaillé aux laboratoires Bell).

Le \textbf{théorème de Shannon-Nyquist} stipule que, pour être capable
d'échantillonner un signal de fréquence \(f\), la fréquence
d'échantillonnage doit au moins être de \(2f\). Ainsi, un ensemble de
points généré par une fréquence inférieure à \(f\) ne peut correspondre
qu'à cette seule et unique fréquence. Notre plage d'écoute étant limitée
à 20~kHz, la fréquence d'échantillonnage minimale dont nous avons besoin
est de 40~kHz.

Que se passe-t-il si la fréquence du signal dépasse la moitié de la
fréquence d'échantillonnage~? Dans ce cas, la vitesse de prélèvement
n'est plus suffisante et nous observons l'apparition de nouvelles
fréquences ne provenant pas du signal original. Ce phénomène se nomme
\textbf{repliement spectral}.

\hypertarget{la-ruxe9solution-de-quantification}{%
\subsection{La résolution de
quantification}\label{la-ruxe9solution-de-quantification}}

La résolution de quantification permet de définir la plage de valeur
dynamique permise dans le système numérique. Celle-ci s'exprime en bit.
Par exemple, si nous prenons un convertisseur travaillant en 8~bit. Le
nombre de valeurs que peut prendre un signal numérisé par un tel
convertisseur est de \(2^8-1 = 255\) en base 10. Admettons que ce
convertisseur accepte des signaux ayant une tension en entrée variant
entre +15V et -15~V, celles-ci seront \textbf{échelonnées} sur
255~valeurs. Si maintenant, ce convertisseur travaille en 16~bit, il y
aura 65~535~échelons. La précision de mesure de la dynamique du signal
n'est donc pas du tout la même.

En pratique, augmenter la résolution de quantification permet
principalement de définir le niveau de bruit du convertisseur. Plus la
résolution est élevée, plus le bruit se retrouvera faible. En 8~bit,
l'écart entre le niveau maximal d'un signal et le bruit est de 48~dB, en
16~bit cet écart est de 96~dB, en 24~bit, 144~dB. On peut
approximativement calculer cette dynamique par la relation suivante :

\[ \Delta_L \approx 6 \times N_{bits} \]

La résolution de quantification standard en enregistrement est 24~bit.
La plage dynamique est telle qu'elle rend le travail d'enregistrement
beaucoup plus souple sur les niveaux d'acquisition des différentes
sources.

\hypertarget{quelle-influence-sur-le-signal}{%
\section{Quelle influence sur le signal
?}\label{quelle-influence-sur-le-signal}}

Le son numérique a longtemps eu la réputation d'être «~dur~»,
particulièrement dans le haut du spectre. Cela s'explique assez
facilement par le fonctionnement des premiers convertisseurs.

En effet, toute la difficulté de fabrication d'un convertisseur réside
dans la réalisation d'un filtre anti-repliement, pour prévenir le
repliement spectral. Ce filtre doit enlever toutes les fréquences
au-dessus de la moitié de la fréquence d'échantillonnage, sans pour
autant affecter le spectre audible. Ce type de filtre est extrêmement
délicat à réaliser en analogique. Cependant, ce problème est résolu
grâce à une méthode d'échantillonnage appelée «~sigma-delta~» (voir
ci-dessous).

Le repliement spectral n'apparaît pas seulement lors de la conversion.
Il peut également survenir lors de l'utilisation de certains traitements
(saturation, simulation analogique, compresseurs). Lorsqu'il devient
audible, le repliement spectral se caractérise par l'apparition de
fréquences \textbf{non harmoniques} souvent qualifiées de «~dures~» et
désagréables. Il est cependant bon de rappeler que ce phénomène, certes
bien réel, apparaît dans des conditions de saturation du signal
importante et sur des sources sonores riches en hautes fréquences.

Malgré la dure vie que mène parfois la réputation du son numérique, il
est important de rappeler qu'il a apporté un grand nombre d'avantages
sur le son analogique, \textbf{y compris sur des questions de rendus
sonores}. Par exemple, la dynamique est bien plus importante, la
distorsion involontaire du signal infime et l'ajout de bruit inexistant.

\hypertarget{la-conversion-sigma-delta}{%
\section{La conversion sigma-delta}\label{la-conversion-sigma-delta}}

Aujourd'hui, les convertisseurs ne travaillent pas directement à
44,1~kHz/16~bit ou 48~kHz/24~bit. Ils utilisent à la place un procédé
appelé échantillonnage sigma-delta. Le principe est d'utiliser une
fréquence d'échantillonnage très rapide (384~kHz) et de coder la
dynamique du signal, en relatif, sur un seul bit (ce bit prend une
valeur de 1 si le nouvel échantillon est plus fort que l'ancien, 0 pour
le cas inverse). Les formats de travail que nous utilisons sont générés
après cette première étape.

L'intérêt de cette méthode est double~:

\begin{itemize}
\tightlist
\item
  Le signal est suréchantillonné dès l'enregistrement
\item
  Les filtres permettant d'éviter le repliement spectral sont donc très
  simples à réaliser
\end{itemize}

\hypertarget{transports-de-signaux-numuxe9riques}{%
\chapter{Transports de signaux
numériques}\label{transports-de-signaux-numuxe9riques}}

Après être passé au travers d'un convertisseur, l'audio est représenté
par un ensemble d'échantillons. En raison de cette représentation
particulière, on trouve un certain nombre de protocoles de communication
de signaux numériques entre appareils. Il ne s'agit plus ici de faire
transiter une tension analogue à celle de la variation de pression d'une
onde sonore, mais plutôt une tension représentant des mots binaires
(bits).

La variation de tension de ces signaux s'apparente à une onde carrée.
Ces signaux périodiques possèdent un état «~haut~» et un état «~bas~»,
très pratique pour communiquer des nombres binaires.

\begin{figure}

{\centering \includegraphics{outils_equipements/transport_signaux_numeriques_files/figure-pdf/fig-num_sig-output-1.pdf}

}

\caption{\label{fig-num_sig}Exemples de signal numérique (Non Return to
Zero)}

\end{figure}

\hypertarget{les-liaisons-point-uxe0-point}{%
\section{Les liaisons point à
point}\label{les-liaisons-point-uxe0-point}}

Les protocoles ci-dessous permettent de transmettre un ou plusieurs
signaux numériques entre deux appareils.

\hypertarget{aes3-aesebu}{%
\subsection{AES3~; AES/EBU}\label{aes3-aesebu}}

L'AES3 est un protocole défini par l'\emph{Audio Engineering Society} et
par l'\emph{European Union Broadcast}. Il est principalement destiné aux
appareils audio dits «~professionnels~». Il permet de véhiculer deux
canaux audio, à une fréquence d'échantillonnage maximal de 48~kHz, via
une fiche XLR ou BNC (coaxial).

La S/PDIF est relativement proche de l'AES3, plutôt utilisé dans les
équipements grand public, utilisant des câbles coaxiaux (sur fiches RCA)
ou optiques (fiche toslink).

\hypertarget{adat}{%
\subsection{ADAT}\label{adat}}

L'\emph{ADAT lightpipe}, souvent abrégé ADAT, est un autre protocole de
transmission de signaux numériques. Il a été développé par Alesis pour
fonctionner avec les magnétophones à bandes numériques de la même
marque. ADAT signifie enfaîte «~Alesis Digital Audio Tape~». On retrouve
ce protocole sur un grand nombre d'appareils, notamment les interfaces
audio, afin d'augmenter le nombre d'entrées/sorties accessibles.

L'ADAT peut transporter jusqu'à huit canaux à 44.1/48~kHz, quatre canaux
à 88.2/96~kHz et deux canaux à 176.4/192~kHz. Le débit d'information est
donc constant, doubler la fréquence d'échantillonnage divise par deux le
nombre de canaux.

La connectique la plus courante pour l'ADAT est la fibre optique avec
fiches toslink.

\begin{figure}

{\centering \includegraphics[width=0.3\textwidth,height=\textheight]{outils_equipements/../_resources/bitmap/plug/toslink.jpg}

}

\caption{\label{fig-toslink}Câble Toslink}

\end{figure}

\hypertarget{madi}{%
\subsection{MADI}\label{madi}}

Le MADI, ou AES10, est un protocole permettant d'acheminer un grand
nombre de canaux. On peut donc récupérer soixante-quatre canaux audio à
une fréquence de 44.1/48~kHz. Comme pour l'ADAT, le nombre de canaux est
divisé par deux à chaque doublement de la fréquence d'échantillonnage.

Ce protocole se retrouve fréquemment dans le monde de l'audio
professionnel. Les connexions entre appareils supportant le MADI peuvent
se faire soit avec des fibres optiques, soit sur câble coaxial (fiches
BNC). Certains constructeurs, comme DIGICO, ont choisi les câbles~RJ45
comme support d'acheminement.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/plug/fibre.jpg}

}

\caption{\label{fig-fibre}\textbf{?(caption)}}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/plug/bnc.jpg}

}

\caption{\label{fig-bnc}\textbf{?(caption)}}

}

\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

Fibre optique et câble BNC

}

\end{minipage}%

\end{figure}

\hypertarget{les-ruxe9seaux-audio-numuxe9riques}{%
\section{Les réseaux audio
numériques}\label{les-ruxe9seaux-audio-numuxe9riques}}

Aujourd'hui, dans le monde du spectacle vivant, la plupart des salles de
spectacle sont équipées avec des solutions de transmission des signaux
audio sur réseau. Ces solutions se retrouvent aussi de plus en plus dans
les studios d'enregistrement et de production audiovisuelle.

Il existe plusieurs protocoles permettant le déploiement de tels
dispositifs, mais leur logique fondamentale reste identique. Chaque
appareil capable de se connecter au réseau audio peut recevoir et
envoyer un flux audio a n'importe quels autres appareils appartenant au
même réseau.

Les réseaux audio sont régis par les mêmes règles que les réseaux
informatiques. Chaque appareil pouvant être connecté à un réseau est
identifiable par une adresse matérielle unique, appelée \textbf{adresse
MAC}. Lorsqu'un appareil est connecté sur un réseau, il faut lui
attribuer une adresse logique appelée \textbf{adresse IP}. Il y a ici
deux façons de faire. Soit l'utilisateur attribue manuellement une
adresse différente à chaque machine (solution préférée en audio, mais
fastidieuse lorsque le réseau comprend un grand nombre d'appareils),
soit le réseau possède un \textbf{serveur DHCP} qui se chargera
d'attribuer une adresse IP unique à chacun des appareils connectés. Cet
outil est généralement intégré dans un appareil nommé \textbf{routeur},
permettant d'interconnecter plusieurs appareils ainsi que de gérer le
routage des flux d'information. Une fois les appareils interconnectés,
chaque constructeur de solutions audio sur IP fournit un logiciel de
routage de l'audio entre les appareils.

Les principaux acteurs industriels des réseaux audionumériques sont
Audinet avec DANTE, ALC NetworX (appartenant à Lawo) avec Ravenna, et
les protocoles open source~AES67 et AVB.

\hypertarget{introduction-uxe0-linformatique-musicale}{%
\chapter{Introduction à l'informatique
musicale}\label{introduction-uxe0-linformatique-musicale}}

(En cours d'écriture)

\hypertarget{fonctionnement-dun-ordinateur}{%
\section{Fonctionnement d'un
ordinateur}\label{fonctionnement-dun-ordinateur}}

\hypertarget{les-systuxe8mes-dexploitation}{%
\section{Les systèmes
d'exploitation}\label{les-systuxe8mes-dexploitation}}

\hypertarget{linux}{%
\subsection{Linux}\label{linux}}

\hypertarget{apple-macos}{%
\subsection{Apple MacOS}\label{apple-macos}}

\hypertarget{microsoft-windows}{%
\subsection{Microsoft Windows}\label{microsoft-windows}}

\hypertarget{les-pilotes-audio}{%
\section{Les pilotes audio}\label{les-pilotes-audio}}

\hypertarget{asio}{%
\subsection{ASIO}\label{asio}}

\hypertarget{coreaudio}{%
\subsection{CoreAudio}\label{coreaudio}}

\hypertarget{alsa}{%
\subsection{ALSA}\label{alsa}}

\hypertarget{jack-audio}{%
\subsection{Jack Audio}\label{jack-audio}}

\hypertarget{les-stations-de-travail-audio-numuxe9rique-daw}{%
\section{Les Stations de Travail Audio-Numérique
(DAW)}\label{les-stations-de-travail-audio-numuxe9rique-daw}}

\hypertarget{le-moteur-audio}{%
\subsection{Le moteur audio}\label{le-moteur-audio}}

\hypertarget{les-fonctionnalituxe9s}{%
\subsection{Les fonctionnalités}\label{les-fonctionnalituxe9s}}

\hypertarget{les-protocoles-de-transmission-dinformations}{%
\section{Les protocoles de transmission
d'informations}\label{les-protocoles-de-transmission-dinformations}}

\hypertarget{midi}{%
\subsection{MIDI}\label{midi}}

\hypertarget{osc}{%
\subsection{OSC}\label{osc}}

\hypertarget{enceintes-et-amplificateurs}{%
\chapter{Enceintes et
amplificateurs}\label{enceintes-et-amplificateurs}}

Un haut-parleur est un appareil permettant de transformer une énergie
électrique en énergie mécanique. On l'appelle, plus spécifiquement, un
transducteur électroacoustique. Fondamentalement, il s'agit d'un
appareil extrêmement proche d'un microphone. D'ailleurs, il est possible
d'utiliser un haut-parleur comme microphone, et vice-versa. Les
haut-parleurs ont de faibles rendements, il est donc nécessaire
d'amplifier les signaux grâce à des amplificateurs de puissance en
amont.

De tous les équipements audio nécessaires pour réaliser une prise de
son, les enceintes (et les casques) sont certainement les plus
importants. En effet, c'est à travers leur prisme que nous pourrons
écouter et contrôler notre travail. Il est donc crucial d'utiliser des
écoutes regroupant un certain nombre de critères et, surtout, de les
connaître sur le bout des doigts.

\hypertarget{anatomie-dun-haut-parleur}{%
\section{Anatomie d'un haut-parleur}\label{anatomie-dun-haut-parleur}}

\begin{figure}

\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/speaker/woofer.png}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/speaker/midrange.png}

}

}

\end{minipage}%
%
\begin{minipage}[t]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{outils_equipements/../_resources/bitmap/speaker/tweeter.png}

}

}

\end{minipage}%

\caption{\label{fig-hp}Coupe de hautparleur (dans l'ordre, woofer,
mid-range, tweeter). Infographie par Svjo, CC BY-SA 3.0}

\end{figure}

Sur les schémas ci-dessus, nous trouvons les éléments suivants~:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  L'aimant
\item
  La bobine
\item
  La suspension
\item
  La membrane
\end{enumerate}

La plupart des haut-parleurs sont qualifiés de \textbf{dynamiques}. La
membrane du haut-parleur est reliée à une bobine, elle-même entourée par
un système d'aimants. Lorsqu'un courant est appliqué aux bornes de cette
bobine, sa position change dût à la modification du champ
électromagnétique. Si le courant oscille, la bobine oscille de façon
analogue, entraînant la membrane et permet donc la reproduction du son.

On appelle généralement «~subwoofer~» les haut-parleurs conçus pour
retranscrire les fréquences très graves (20-200~Hz), «~woofer~» les
haut-parleurs dédiés aux fréquences graves (50~Hz à 1000~kHz),
«~mid-range~» les haut-parleurs du médium (1~kHz à 6~kHz), et
«~tweeter~», ceux de l'aigu (au-delà de 5~kHz).

Le haut-parleur est sans doute l'appareil audio le plus imparfait qui
soit. Il est sujet à de nombreuses sources de distorsion du signal.

Nous ne savons pas fabriquer des haut-parleurs capables de reproduire
uniformément toutes les fréquences. Ces derniers sont souvent
spécialisés dans une certaine plage de fréquence. La plupart des
enceintes de monitoring utilisent 3~voies~: deux actives (utilisant des
haut-parleurs) pour l'aigu et le médium, et une passive (évent avant ou
arrière) pour le grave. L'utilisation du plusieurs voies imposent donc
l'utilisation de filtres induisant un déphasage de certaines fréquences.

Également, un haut-parleur peut être approché par un modèle
«~masse-ressort~». Cela signifie qu'il y a une certaine inertie à sa
mise en action et une certaine inertie à sa mise en arrêt. L'enceinte
idéale devrait posséder une inertie nulle. Cette inertie est
potentiellement responsable d'un adoucissement des transitoires et d'une
sensation de flou.

\hypertarget{amplification-et-impuxe9dance}{%
\section{Amplification et
impédance}\label{amplification-et-impuxe9dance}}

Nous avons précédemment abordé le préamplificateur, qui permet
d'amplifier la tension d'un signal audio analogique et d'en baisser son
impédance. On appelle alors «~amplificateur~» un amplificateur de
\textbf{puissance}. On rappel que la puissance d'un signal s'exprime par
la relation ci-dessous. On cherche donc à augmenter la tension
\textbf{et} l'intensité du signal.

\[ P = U \times I \]

Nous pouvons rapidement aborder la notion de classe d'amplification. En
audio, nous n'utilisons que les classes A, AB et D. La classe A utilise
un transistor (ou tube) pour amplifier l'ensemble du signal. Elle
possède un très mauvais rendement. Cela signifie qu'il faut fournir
beaucoup d'énergie au transistor pour un faible gain sur la puissance du
signal. La classe AB utilise deux transistors, un pour les alternances
négatives et un pour les alternances positives. Le rendement est
meilleur que pour la classe A. Cependant, le point de raccordement entre
les deux transistors est assez sensible et peu généré de la distorsion
sur le signal (distorsion de croisement). La classe D, aussi appelée à
tort «~numérique~», utilise un transistor afin d'indiquer l'état du
signal. On retrouve donc la même idée que dans l'échantillonnage du
signal. Ces amplificateurs offrent un \textbf{excellent rendement}.

Nous avons également abordé précédemment la notion d'adaptation
d'impédance en tension, sans aborder l'adaptation d'impédance en
puissance. Pour rappel, afin de préserver la tension entre deux
appareils A et B, nous faisons en sorte d'avoir une faible impédance à
la sortie de l'appareil A et une grande impédance à l'entré de
l'appareil B. Pour préserver la puissance du signal, ce paradigme ne
fonctionne plus. On cherche alors à avoir la même impédance entre la
sortie d'un appareil et l'entrée d'un autre. En pratique, on raccordera,
sur la sortie «~8~ohms~» d'un amplificateur, un haut-parleur ayant une
impédance de «~8~ohms~».

\begin{quote}
On remarque qu'ici, les impédances sont extrêmement faibles. Les
impédances typiques des haut-parleurs (et donc des sorties
d'amplificateurs en puissance) sont 4, 8 et 16~ohms.
\end{quote}

La plupart des enceintes de monitoring ont aujourd'hui une amplification
de classe D directement intégré.

\hypertarget{puissance-et-sensibilituxe9}{%
\section{Puissance et sensibilité}\label{puissance-et-sensibilituxe9}}

On trouve généralement deux mesures de la puissance pour les enceintes.
La puissance \textbf{crête à crête} (peak) et la \textbf{puissance
moyenne} (\textbf{RMS}, ou \textbf{Root Mean Square}). La puissance se
calcule grâce à la formule suivante~:

\[ P =\frac {U^2}{Z} \]

\(P\) est la puissance, \(U\) la tension et \(Z\) l'impédance. Pour
réaliser la mesure de puissance d'un haut-parleur, on le soumet à un
signal test, en général un bruit rose, pendant plusieurs heures. La
puissance crête à crête se calcul grâce à la tension crête à crête
(aussi dite maximale). Par exemple, pour une tension maximale de 100~V,
sous une impédance de 8~ohms, on trouve une \textbf{puissance crête à
crête} d'environ 1200~watts (abbrégé W). On considère généralement que
la tension moyenne d'un signal est six décibels plus petite que sa
tension maximale. En reprenant notre exemple, pour une tension maximale
de 100~V, on a une tension moyenne de 50~V, sous une impédance de
8~ohms, on trouve une \textbf{puissance moyenne} d'environ 300~W.

Alors, il faut donc faire très attention sur les spécifications données
par les constructeurs, parfois volontairement floues. À défaut, si on
lit que la puissance admissible d'un haut-parleur est de 1000~W, on
supposera par défaut qu'il s'agit d'une puissance crête à crête. On ne
dépassera donc pas une puissance moyenne d'amplification de 250 W.

La \textbf{sensibilité} est une mesure du niveau sonore à un mètre de
l'enceinte pour une puissance RMS d'entrée d'un watt. Grâce à cette
valeur, on peut calculer le niveau sonore produit par le haut-parleur à
diverses distances et en fonction de différentes puissances d'entrées.
On comprend aussi que la puissance électrique admissible dans l'enceinte
ne donne que peu d'information sur son niveau sonore de sortie.

\hypertarget{conseils-pratiques}{%
\section{Conseils pratiques}\label{conseils-pratiques}}

\hypertarget{choisir-une-paire-duxe9coutes}{%
\subsection{Choisir une paire
d'écoutes}\label{choisir-une-paire-duxe9coutes}}

Choisir une paire d'enceintes peut sembler être un exercice difficile.
Il existe énormément de modèles, coûtant de quelques dizaines d'euros à
plusieurs dizaines de milliers.

Il y a cependant plusieurs critères assez objectifs pour évaluer la
qualité d'une enceinte~:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La réponse en fréquence~: l'enceinte flatte-t-elle particulièrement
  une zone du spectre~? En délaisse-t-elle une autre~?
\item
  La réponse en transitoires~: les attaques sont-elles respectées~?
  Retrouve-t-on l'énergie initiale du signal~?
\item
  La linéarité en fonction du volume~: a-t-on une sensation de
  compression du signal lorsque l'on augmente le niveau envoyé dans
  l'enceinte~?
\item
  Le centre fantôme~: le centre du système stéréophonique paraît-il
  stable~? Paraît-il précis~?
\item
  La couleur sonore de l'enceinte~: a-t-on plaisir à écouter du son et
  de la musique sur ce système~?
\end{enumerate}

\hypertarget{placer-correctement-son-uxe9coute}{%
\subsection{Placer correctement son
écoute}\label{placer-correctement-son-uxe9coute}}

Afin de satisfaire les critères de la stéréophonie, il convient de
respecter les règles suivantes~:

\begin{itemize}
\tightlist
\item
  Les deux enceintes doivent être de même marque, de même modèle et
  appairée. Si une des membranes a dû être changée sur l'une d'elle,
  l'autre aurait dû recevoir la même opération.
\item
  Les deux enceintes doivent être séparées par un angle de 60°
\item
  L'auditeur doit être placé à équidistance des deux haut-parleurs, et
  regarder vers le milieu du segment formé par les deux enceintes.
\end{itemize}

Une fois ces critères respectés, voici quelques conseils sur le
placement des enceintes dans une pièce~:

On préférera des pièces de grandes tailles, afin de repousser au maximum
le temps d'arrivée des premières réflexions. Le système stéréophonique
devrait être positionné dans un souci de symétrie~: l'enceinte de gauche
ne devrait pas être plus proche d'un mur que l'enceinte de droite, par
exemple. Dans le cas de petit espace, on préféra coller les enceintes
contre un mur. Cela permettra de supprimer l'influence d'une des
premières réflexions au prix de l'augmentation du niveau de grave. Il
est vivement recommandé de procédé au traitement, même minimal,
acoustique de la pièce de travail, à commencer par les zones de
réflexions premières et par les angles (ou le grave va s'accumuler). Si
le traitement acoustique n'est pas envisageable, il convient de
privilégier une écoute à faible niveau et une proximité maximale avec
les enceintes.

\hypertarget{luxe9coute-au-casque}{%
\section{L'écoute au casque}\label{luxe9coute-au-casque}}

Le casque est un outil permettant d'écouter un signal tout en
s'extrayant de son environnement (acoustique et/ou bruit). Cependant, de
par son mode de fonctionnement, à savoir deux haut-parleurs placés dans
une enceinte en contact direct avec les oreilles, il génère un certain
nombre de déformations.

Premièrement, la stéréophonie écoutée au casque est hypertrophiée. En
effet, dans ces conditions d'écoutes, l'oreille gauche n'entend que le
haut-parleur gauche et l'oreille droite n'entend que le haut-parleur
droit.

Deuxièmement, il est très difficile de trouver des casques avec une
réponse en transitoire satisfaisante. Il convient donc d'être
excessivement prudent lorsque l'on mix du contenu percussif sur un
casque.

Troisièmement, les casques sont encore moins linéaires en fréquence que
les haut-parleurs, il convient là aussi d'être très prudent lors de la
réalisation d'un mixage.

Ces défauts peuvent être compensés par l'habitude et la connaissance du
système d'écoute, mais la transportabilité d'un mixage (à savoir, sa
compatibilité avec d'autres systèmes d'écoute) réalisé au casque est
souvent discutable.

\hypertarget{casque-fermuxe9-ou-casque-ouvert}{%
\subsection{Casque fermé ou casque
ouvert~?}\label{casque-fermuxe9-ou-casque-ouvert}}

Le casque fermé, comme son nom l'indique, propose une fabrication
enfermant le haut-parleur dans une enceinte close. Cette méthode de
fabrication offre l'avantage d'isoler celui qui écoute de
l'environnement, mais aussi d'isoler l'environnement de ce qui est
diffusé dans le casque. Par contre, ces casques ont souvent une réponse
en fréquence très accidentée, et ne sont pas recommandés pour le mixage.
Il est par contre vivement recommandé pour les musiciens en session de
prise de son.

Le casque ouvert, à l'inverse de son homologue fermé, n'offre aucune
isolation acoustique, au prix d'une meilleure réponse en fréquence du
casque. Ces casques sont tout indiqués pour le mixage, mais beaucoup
moins pour des situations de prise de son.

\part{Méthodologie de prise de son}

\hypertarget{ecoute-critique-premiuxe8re-partie}{%
\chapter{Ecoute critique : première
partie}\label{ecoute-critique-premiuxe8re-partie}}

\hypertarget{mono-et-multi-microphonie}{%
\chapter{Mono et multi-microphonie}\label{mono-et-multi-microphonie}}

(En cours d'écriture)

\hypertarget{la-prise-de-son-au-couple}{%
\chapter{La prise de son au couple}\label{la-prise-de-son-au-couple}}

La prise de son au couple stéréophonique regroupe l'ensemble des
techniques de prise de son dédié au système d'écoute stéréophonique
(deux enceintes séparées de 60° et orientées vers un auditeur placé à
équidistance des deux transducteurs).

Ces techniques permettent une bien meilleure représentation des espaces
des prises de son ainsi qu'une localisation des différents éléments
enregistrés dans cet espace.

\hypertarget{guxe9nuxe9ralituxe9s-sur-les-muxe9canismes-de-la-localisation-du-son-par-loreille-humaine}{%
\section{Généralités sur les mécanismes de la localisation du son par
l'oreille
humaine}\label{guxe9nuxe9ralituxe9s-sur-les-muxe9canismes-de-la-localisation-du-son-par-loreille-humaine}}

Afin de mieux comprendre comment fonctionne un couple de prise de son,
il convient d'étudier rapidement les principes fondamentaux de notre
écoute.

Notre capacité à localiser les sons dans l'espace repose principalement
sur deux mécanismes~: + La différence de temps + La différence de niveau

\hypertarget{la-localisation-par-diffuxe9rence-de-temps}{%
\subsection{La localisation par différence de
temps}\label{la-localisation-par-diffuxe9rence-de-temps}}

Nos oreilles sont espacées, d'environ 15 à 25 cm. Cette distance
implique qu'un son émis plus proche de l'oreille droite arrivera
également plus tôt qu'à l'oreille gauche. Cet écart de temps, de
quelques millisecondes, est suffisant pour donner à notre cerveau un
indice sur la localisation du son.

Afin de sentir l'ordre de grandeur en jeu, calculons la différence de
temps (\(\Delta t\)) maximale pour un individu possédant un écart
d'oreille de 20 cm.

On sait que la célérité du son dans l'air vaut \(c = 340 m.s^{-1}\), et
est invariant en fonction de la fréquence. On sait également que
\(c = \frac{d}{t}\).

Dès lors, si on pose \(d = 20 cm\) soit \(d = 0.2 m\), on peut en
déduire que~:

\(t = \frac{d}{c} \iff t= \frac{0.2}{340} \approx 0.0006 s \approx 0.6 ms\)

Afin de mettre en relief ce résultat, il est communément admis que
l'oreille humaine commence à faire la différence entre deux répétitions
d'un même son à partir de \(20 ms\).

\hypertarget{la-localisation-par-diffuxe9rence-dintensituxe9}{%
\subsection{La localisation par différence
d'intensité}\label{la-localisation-par-diffuxe9rence-dintensituxe9}}

A priori, l'espace entre nos deux oreilles n'est pas creux. La densité
de notre crâne et de son contenu va réfléchir et absorber une partie des
fréquences rencontrées.

Également, la partie externe de nos oreilles, appelées pavillon, permet,
grâce à sa forme, de donner une directivité à notre écoute.

En d'autres termes, notre tête et le pavillon de nos oreilles se
comportent comme un filtre, variant en fonction de l'angle d'incidence
de la source. Cette altération du timbre n'est pas perçue comme une
coloration, mais bien comme une information de localisation. La
modélisation mathématique de ces filtres se retrouve dans la littérature
scientifique sous le nom \textbf{HRTF}.

Cette atténuation séquentiellement dépendante est décisive dans notre
capacité à localiser les sons. On la retrouve communément sous le nom
\(\Delta i\).

\hypertarget{pruxe9valence-fruxe9quentielle-de-ces-deux-phuxe9nomuxe8nes}{%
\subsection{Prévalence fréquentielle de ces deux
phénomènes}\label{pruxe9valence-fruxe9quentielle-de-ces-deux-phuxe9nomuxe8nes}}

Il est communément admis que le \(\Delta t\) aura une efficacité
maximale dans les basses fréquences, et le \(\Delta i\) dans les hautes
fréquences.

\hypertarget{principes-de-la-prise-de-son-au-couple}{%
\section{Principes de la prise de son au
couple}\label{principes-de-la-prise-de-son-au-couple}}

Pour créer son effet stéréophonique, les couples de prise de son
utilisent les mêmes mécanismes que notre écoute naturelle~:

\begin{itemize}
\tightlist
\item
  La différence de temps
\item
  La différence d'intensité
\end{itemize}

Il va de soi que, pour fonctionner de façon optimale, les microphones
utilisés pour réaliser une prise de son stéréophonique doivent être de
même marque, de même modèle et appairée.

\begin{quote}
L'appairage garantit que les microphones aient des caractéristiques
techniques suffisamment proches pour être considérés comme identiques.
\end{quote}

Afin de manipuler ces mécanismes, le preneur de son peut jouer sur les
paramètres suivant~:

\begin{itemize}
\tightlist
\item
  La directivité des microphones
\item
  L'angle entre les capsules
\item
  La distance entre les capsules
\end{itemize}

Modifier chacun de ses paramètres influe sur l'\textbf{angle de prise de
son}. Plus l'ange de prise de son est faible, plus l'impression de
stéréophonie sera grande. Plus l'angle de prise de son est grand, plus
l'impression de stéréophonie sera faible, jusqu'à tendre vers la
monophonie.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-caution-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Mise en garde}]

Attention de ne pas confondre l'angle de prise de son avec l'angle entre
les capsules.

\end{tcolorbox}

\hypertarget{comment-choisir-un-angle-de-prise-de-son.}{%
\subsection{Comment choisir un angle de prise de
son.}\label{comment-choisir-un-angle-de-prise-de-son.}}

L'angle de prise de son est étroitement lié à la distance du couple par
rapport à l'évènement sonore à enregistrer. En règle générale, plus le
couple est loin des objets sonores à enregistrer, plus son angle de
prise de son sera faible. À l'inverse, plus le couple sera proche, plus
son angle de prise de son sera grand.

Ensuite, lors de la réalisation d'un couple de prise de son, il est
commun d'enregistrer un ensemble d'éléments~: plusieurs instruments
(batterie), voire plusieurs musiciens (quatuor à corde, orchestre).
L'objectif est bien souvent de retrouver une sensation de disposition
des éléments dans l'espace proche de la situation réelle. On cherche
donc un angle de prise de son suffisamment petit pour que les sources
occupent l'intégralité de l'espace stéréophonique, mais également
suffisamment grand pour ne pas créer une sensation de trou au centre.

\hypertarget{comment-ruxe9aliser-un-angle-de-prise-de-son.}{%
\subsection{Comment réaliser un angle de prise de
son.}\label{comment-ruxe9aliser-un-angle-de-prise-de-son.}}

Plusieurs outils existent pour aider le preneur de son à choisir son
angle de prise de son correctement.

Il est important de commencer par les abaques de Michael Williams, ayant
cherché à étudier l'angle de prise de son et ses qualités en fonction
des paramètres vues précédemment. Les résultats de ses travaux se
trouvent sur le site
\href{https://www.mmad.info/MAD/2\%20Ch/2ch.htm}{mmad.info}.

On trouve également beaucoup d'application mobile, comme celle du
constructeur du microphone Neumann, s'appuyant sur les travaux de
Michael Williams pour aider leurs utilisateurs à correctement
positionner leurs microphones. Évidemment, et heureusement, rien n'est
spécifique à un fabricant de microphones en particulier, l'application
d'un constructeur A peut servir pour placer des microphones d'un
constructeur B.

Plus récemment, des chercheurs britanniques ont développé une
application, nommée \href{https://marrsweb.hud.ac.uk/}{MARRS},
permettant de positionner son couple de prise de son par rapport aux
sources via une interface graphique très simple à utiliser. Cette
application est disponible sur mobile et sur navigateur internet.

\hypertarget{priviluxe9gier-le-delta-i-ou-le-delta-t}{%
\subsection{\texorpdfstring{Privilégier le \(\Delta i\) ou le
\(\Delta t\)~?}{Privilégier le \textbackslash Delta i ou le \textbackslash Delta t~?}}\label{priviluxe9gier-le-delta-i-ou-le-delta-t}}

La différence de perception du champ stéréophonique est très différente
entre celui produit par le \(\Delta i\) ou par le \(\Delta t\).

\begin{itemize}
\tightlist
\item
  Un couple reposant sur le \(\Delta i\) aura une sensation de
  localisation des sources précise. De plus si un tel couple enregistre
  une source ce déplaçant a vitesse constante, la sensation de
  déplacement retranscrite par le couple sera, elle aussi, linéaire. Il
  est également possible de sommer les deux microphones ensemble afin
  d'obtenir un signal monophonique. Un tel couple est appelé compatible
  mono.
\item
  Un couple reposant sur le \(\Delta t\) aura une sensation de
  localisation plus floue, mais apportera un sens de l'espace plus grand
  et une dimension spacieuse. À l'inverse d'un couple \(\Delta i\), la
  sensation d'un déplacement linéaire d'une source n'est pas linéaire.
  Il n'est pas possible de sommer les deux capsules pour en obtenir une
  réduction mono sans générer des altérations de timbre sévères.
\end{itemize}

Chaque couple possède ses avantages et ses inconvénients. Heureusement,
nous ne sommes pas limités à l'un où l'autre et nous pouvons à loisir
réaliser une combinaison des deux mécanismes.

\hypertarget{les-topologies-classiques-de-prise-de-son-au-couple}{%
\section{Les topologies classiques de prise de son au
couple}\label{les-topologies-classiques-de-prise-de-son-au-couple}}

Le premier ingénieur à se poser la question du son stéréophonique est
l'anglais Alan Blumlein en 1929. Il imagine l'entièreté de la chaîne
d'enregistrement et de diffusion nécessaire à la stéréophonie.
Cependant, la BBC lui impose comme contrainte que toutes ses
propositions soient compatibles avec des systèmes monophoniques. Il
inventera donc le couple XY et MS.

Plus tard, la plupart des radios européennes développeront des couples
de prises de son mêlant \(\Delta i\) et \(\Delta t\), tel que l'ORTF.

\hypertarget{le-couple-blumlein-xy}{%
\subsection{Le couple Blumlein / XY}\label{le-couple-blumlein-xy}}

Les deux microphones sont ici directifs, placés au même point de
l'espace et ongulé d'une certaine valeur entre eux.

De par les contraintes technologiques de son époque, Blumlein a décrit
ce couple pour une utilisation de deux microphones bidirectionnels. Il
est aujourd'hui plus commun de le rencontrer avec deux cardioïdes.

Dans sa version originale, le couple Blumlein comprend donc deux
microphones bidirectionnels avec un angle de 90°.

La formulation du couple XY comprend deux microphones cardioïdes avec un
angle compris entre 90° et 135°.

\hypertarget{le-couple-ms}{%
\subsection{Le couple MS}\label{le-couple-ms}}

Le couple MS, également inventé par Alan Blumlein, permet de doser la
quantité de stéréophonie après l'enregistrement.

Pour se faire, ce couple utilise deux microphones~:

\begin{itemize}
\tightlist
\item
  Un omnidirectionnel, historiquement, mais aujourd'hui fréquemment
  remplacé par un microphone cardioïde.
\item
  Un bidirectionnel
\end{itemize}

Le microphone omnidirectionnel, ou cardioïde, va rendre compte du centre
de la stéréophonie, tandis que le microphone bidirectionnel rendra
compte de la latéralité.

Une fois enregistrés, ces deux canaux ont besoin d'être convertis, plus
exactement dématricés, vers une paire de canaux stéréophonique.
L'opération est très simple~:

\[L = M+S\] \[R = M-S\]

Cette opération peut être réalisée sur une console de mixage, telle que
décrite ci-dessous.

\begin{figure}

{\centering \includegraphics{methode-pds/"../_resources/171f157be4749ac8446dd9bdfff0625b.png"}

}

\caption{Dématriçage MS}

\end{figure}

\hypertarget{le-couple-ortf}{%
\subsection{Le couple ORTF}\label{le-couple-ortf}}

Le couple ORTF, inventé par la radio française du même nom, combine
l'effet du \(\Delta i\) et du \(\Delta t\) afin de s'approcher de
l'écoute humaine.

Sa topologie est précisément définie. Elle propose l'utilisation d'une
paire de microphones cardioïde, ongulé du 110° et avec un écart de 17
cm.

\hypertarget{les-couples-ab}{%
\subsection{Les couples AB}\label{les-couples-ab}}

Les couples AB peuvent avoir une définition ambiguë. Une partie de la
littérature scientifique considère comme couple AB tout couple non
coïncident. À cet égard l'ORTF est considéré comme un couple AB. Pour
d'autre, les couples AB ne concernent que des couples constitués de
microphones omnidirectionnels.

Ces derniers ont la particularité de n'utiliser que le \(\Delta t\) afin
de placer les sources dans l'espace. Le rendu est donc souvent spacieux,
au prix d'une certaine instabilité et d'un certain manque de précision
de l'image stéréophonique.

\hypertarget{compluxe9ter-une-prise-de-son-au-couple-par-des-appoints}{%
\section{Compléter une prise de son au couple par des
appoints}\label{compluxe9ter-une-prise-de-son-au-couple-par-des-appoints}}

Il est commun, lors d'une prise de son au couple, de chercher à obtenir
une entière satisfaction sonore à la seule aide du couple. Cependant,
cela n'est parfois pas possible, souvent pour des contraintes physiques
et acoustiques (un instrument de l'ensemble jouant moins fort que les
autres). Dans ces cas, l'utilisation d'appoint, donc de microphone
supplémentaire, placé en proximité de la source, va permettre de venir
récupérer une précision supplémentaire de l'instrument.

Lors de l'étape de mixage, le couple servira de base principale et l'on
viendra ajouter la quantité nécessaire d'appoints pour préciser le
propos. Il sera parfois nécessaire de remettre en phase l'appoint et le
couple pour améliorer la sommation de l'ensemble.

\hypertarget{duxe9phasage-et-remise-en-phase}{%
\chapter{Déphasage et remise en
phase}\label{duxe9phasage-et-remise-en-phase}}

\hypertarget{les-effets-sonores-de-duxe9phasage}{%
\section{Les effets sonores de
déphasage}\label{les-effets-sonores-de-duxe9phasage}}

Tous les signaux sont caractérisés par une certaine phase. Celle-ci est
moins tangible que celles de niveau sonore ou de fréquence. En effet,
lorsqu'un signal est écouté seul, celle-ci ne s'entend pas. C'est au
moment où plusieurs signaux corrélés (comprendre, enregistrés au même
moment, par plusieurs microphones) sont sommés que les différences de
phase peuvent s'entendre.

\hypertarget{approche-mathuxe9matique}{%
\section{Approche mathématique}\label{approche-mathuxe9matique}}

Prenons l'exemple d'un son pur~: \(sin (\omega t + \phi)\) où
\(\omega = 2\pi f\)

La phase de ce signal est décrite par \(\omega t +\phi\)

Les deux paramètres responsables de déphasages audibles sont~:

\begin{itemize}
\tightlist
\item
  \(t\), le temps
\item
  \(\phi\), la phase à l'origine
\end{itemize}

Attention, pour un son pur, l'effet de la modification de \(t\) ou de
\(\phi\) semble très similaire. Ce n'est pas le cas pour des signaux
pseudo-périodiques, atténués dans le temps.

\hypertarget{les-sources-de-duxe9phasage}{%
\section{Les sources de déphasage}\label{les-sources-de-duxe9phasage}}

Les causes les plus classiques de déphasages sont~:

\begin{itemize}
\tightlist
\item
  Un câble XLR avec une inversion sur le point chaud et le point froid
\item
  Une prise de son avec une différence de distance entre deux
  microphones
\item
  Une prise de son utilisant deux microphones positionnés de part et
  d'autre d'une membrane
\item
  Un retard de certaines fréquences lié aux objets rencontrés par les
  signaux
\end{itemize}

\hypertarget{en-pratiques}{%
\chapter{En pratiques}\label{en-pratiques}}

Le bon déroulement de l'enregistrement d'instruments acoustiques dépend
de multiple facteur. Trié par ordre d'importance décroissante, nous
trouvons :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Le confort du musicien
\item
  La qualité de l'instrument enregistré
\item
  La qualité de l'acoustique de la pièce où a lieu l'enregistrement
\item
  Le placement du microphone
\item
  Le choix du microphone (technologie et directivité)
\item
  Le choix du préampli
\end{enumerate}

\hypertarget{le-confort-du-musicien}{%
\section{Le confort du musicien}\label{le-confort-du-musicien}}

Même si elle peut sembler triviale, cette « étape » de la chaîne de
prise de son est de loin la plus importante. La qualité de
l'interprétation donnée par le musicien dépendra grandement de son état
moral et psychologique :

\begin{itemize}
\tightlist
\item
  Est-il stressé
\item
  Est-il confiant
\item
  Se sent-il accueilli
\item
  etc.
\end{itemize}

Nous pourrions considérer qu'un ou une musicienne arrivant dans un
studio d'enregistrement se présente avec un taux de confiance maximal
envers l'équipe technique. Dès lors l'objectif des différents
techniciens est de conserver cette jauge au maximum.

Les premières minutes sont particulièrement importantes et va poser un
ressenti fort sur la journée de travail. Il y a donc un équilibre à
trouver entre un accueil chaleureux et décontracté et un rapport
productiviste et sérieux.

Le système permettant aux musiciens de communiquer entre eux et avec les
techniciens est primordial. En pratique, il n'est pas rare de dédier
certains microphones du plateau à cette tâche. Du côté régi, le «
talkback » est l'outil de communication premier des techniciens présents
sur la session. Il convient de l'utiliser avec soin et prudence. Un
musicien peut rapidement se sentir isolé, s'il enregistre seul. Il
convient de maintenir un contact régulier et précis afin de ne pas
l'abandonner dans le seul dans sa cabine. Qui plus est, un quiproquo
peut être vite arrivé avec les systèmes de talkback. Prudence quant à
l'état d'ouverture ou de fermeture du microphone.

\hypertarget{le-choix-de-linstrument}{%
\section{Le choix de l'instrument}\label{le-choix-de-linstrument}}

La plupart des musiciens se présenteront avec leurs instruments. La
marge de manœuvre est donc ici quasi nulle.

Cependant il n'est pas rare que le studio possède du « backline »,
souvent composé de batteries, d'amplificateur guitare et basse, voire de
guitares et de basses. Si l'instrument utilisé par le musicien pose
problème pour la prise de son, proposer une alternative peut s'avérer
être un bon pari. Il convient évidemment de sonder l'ouverture du
musicien par rapport à cette proposition, afin de ne pas le braquer.

Il peut également être intéressant de « préparer » les instruments.
Cette technique est très courante sur les pianos et les batteries, afin
de changer les propriétés acoustiques de l'instrument grâce a
l'utilisation de draps, coussins, couvertures disposées dans ou sur
l'instrument.

\hypertarget{le-choix-de-lacoustique}{%
\section{Le choix de l'acoustique}\label{le-choix-de-lacoustique}}

L'acoustique de la salle d'enregistrement est-elle aussi plus souvent
une contrainte qu'une variable d'ajustement.

On préférera souvent de grandes salles afin de limiter l'apparition
prématurée de premières réflexions. Plus la salle sera petite, plus
celle-ci apportera une forte coloration sur le contenu enregistré. Il
convient donc d'être attentif aux petites cabines de studio, celles-ci
sont souvent très mates, mais leur apport sur le timbre des instruments
qui y sont enregistrés est souvent très important.

Lorsque l'on a la possibilité d'enregistrer dans de grandes salles, il
est souvent intéressant de disposer des quelques panneaux acoustiques
mobiles, afin de modeler la pièce à sa convenance.

Si l'acoustique imposée est défavorable, on préférera dans ce cas des
prises d'hyper proximité, afin de minimiser son effet au maximum.

\hypertarget{placer-et-choisir-son-microphone}{%
\section{Placer et choisir son
microphone}\label{placer-et-choisir-son-microphone}}

En pratique, il est bien difficile de dissocier le choix du microphone
de son placement, les deux étant très interdépendants. Cependant, il
convient de garder à l'esprit que le positionnement du microphone est,
parmi les deux, sans doute le plus déterminant.

La première étape, avant même de choisir un microphone, consiste à
écouter l'instrument dans l'acoustique d'enregistrement. Il s'agit ici
d'une écoute active. On se déplace autour de l'instrument, on s'en
approche, on s'en éloigne, afin de sentir l'interaction entre la source
et l'acoustique du lieu. Aussi, il est important de trouver deux zones
d'émission particulière de l'instrument : la zone de projection maximale
et la zone au timbre le plus favorable. La première peut nous servir à
positionner l'instrumentiste par rapport aux autres instruments afin de
minimiser les reprises entre microphones. La deuxième zone nous indique
l'axe de prise de son.

Cette zone au timbre le plus favorable est relative. Elle dépend de
l'instrument, bien sûr, mais aussi du modèle. Elle dépend également du
mode de jeu, de l'articulation du joueur et évidemment, de l'esthétique
de la musique.

\hypertarget{le-rapport-a-la-distance-du-microphone}{%
\subsection{Le rapport a la distance du
microphone}\label{le-rapport-a-la-distance-du-microphone}}

La distance de positionnement du microphone est un élément excessivement
important sur le rendu esthétique de la prise de son.

En règle générale, plus on prend de distance, plus on approche une prise
de son naturaliste, cherchant à reproduire un évènement sonore dans son
environnement, tel qu'il aurait été entendu dans la pièce. Plus on se
rapproche, plus on fragmente l'événement sonore et plus on l'arrache
aussi a son contexte de diffusion.

Afin de déterminer efficacement le placement d'un microphone, il
convient d'abord d'en connaître sa distance critique. Celle-ci
correspond au point, dans une pièce, où le son provenant directement
d'une source est perçu au même niveau sonore que la réponse acoustique à
cette source. Cela signifie que si nous plaçons notre microphone au-delà
de ce point, nous obtiendrons plus d'acoustique que de son direct de
l'instrument.

Il est important aussi de considérer que la directivité du microphone
influe sur la distance critique. En effet, plus la directivité du
microphone est large (tends vers l'omnidirectionnalité), plus le
microphone paraîtra éloigné de la source. À l'inverse, plus la
directivité d'un microphone est étroite (tends vers la
bidirectionnalité), plus le microphone paraîtra proche.

Dans le cas de l'utilisation de microphone directif, le placement en
proximité et hyperproximité va créer une accentuation du contenu
basse-fréquence de la source. Cela devient parfois un élément
esthétique, comme sur les voix radiophoniques. Cela aussi peut être un
défaut, une exagération qu'il conviendra de corriger en postproduction.

\hypertarget{quand-choisir-une-prise-de-son-stuxe9ruxe9ophonique}{%
\subsection{Quand choisir une prise de son
stéréophonique}\label{quand-choisir-une-prise-de-son-stuxe9ruxe9ophonique}}

La prise de son stéréophonique, comme son nom l'indique, regroupe
l'ensemble des techniques de prise de son dédié au système de diffusion
stéréophonique (deux enceintes séparées de 60° et orientées vers un
auditeur placé à équidistance des deux transducteurs).

L'avantage de tels dispositifs de prises de son est de peupler dès la
prise l'espace stéréophonique qui est donné à l'auditeur lors de la
diffusion. Ils permettent également de rendre compte de la position de
plusieurs évènements sonores ayant lieu dans la même acoustique. Cette
dernière est d'ailleurs bien mieux retranscrite par de tels systèmes de
prise de son.

Il s'agit à nouveau d'un choix esthétique. Faire le choix d'une prise de
son monophonique permet de renforcer la sensation de frontalité et de
densité d'une source. À l'inverse, une prise de son stéréophonique
donnera une définition spatiale accrue.

\hypertarget{quand-choisir-la-multi-microphonie}{%
\subsection{Quand choisir la
multi-microphonie}\label{quand-choisir-la-multi-microphonie}}

La multi-microphonie consiste à enregistrer un instrument via
l'utilisation de microphones (principalement) directifs, placés à
différents endroits jugés pertinents et en hyperproximité.

Cette approche esthétique de la prise de son est devenue indissociable
des « musiques actuelles ». Elle offre l'avantage d'une grande
flexibilité de traitement lors de la phase de mixage. Voir, elle
implique une certaine partie des traitements.

En effet, une prise d'hyperproximité va systématiquement relever deux
défauts :

\begin{itemize}
\tightlist
\item
  un effet de proximité : le grave/bas médium de la source paraît
  hypertrophié lors de l'emploi de microphones directifs.
\item
  Les dynamiques de jeux sont également hypertrophiées.
\end{itemize}

L'effet de proximité implique donc bien souvent l'utilisation d'un
égaliseur, permettant de corriger cette augmentation artificielle du
grave. De même, l'hypertrophie de la dynamique de jeu implique l'usage
d'un compresseur afin de corriger ces variations artificielles.

Afin de recréer une sensation de spatialisation, on utilisera
principalement deux outils. En premier lieu, le potentiomètre de
panoramique afin de diriger ces sons mono dans l'espace stéréophonique,
puis les réverbérations artificielles permettra de reconstituer un champ
acoustique et de réintégrer ces sources dans une scène sonore.

Si l'approche de la prise au couple pouvait être qualifiée de
naturaliste, alors la prise de son en multimicrophone sera son pendant
spectaculaire. Évidemment, il convient de ne pas aussi franchement
opposer ces deux approches et il existe tout un monde de système de
prise de son entre ces deux extrêmes.

\hypertarget{le-choix-du-pruxe9amplificateur}{%
\section{Le choix du
préamplificateur}\label{le-choix-du-pruxe9amplificateur}}

Le rôle du préamplificateur est d'amplifier le signal, le tout en
ramenant le minimum de bruit. Un premier élément de choix de préampli va
se faire sur le niveau de pression acoustique produit par les sources à
enregistrer.

Enregistrer une batterie impose peut de contrainte sur le préampli quand
a sa capacité à amplifier sans rajouter beaucoup de bruit sur le signal.
À l'inverse, enregistrer des instruments peux sonores, possiblement avec
des microphones peux sensibles, implique l'utilisation de préampli avec
une excellente réserve de gain et un excellent rapport signal bruit.

\hypertarget{linfluence-du-pruxe9ampli-sur-la-couleur-du-son}{%
\subsection{L'influence du préampli sur la « couleur » du
son}\label{linfluence-du-pruxe9ampli-sur-la-couleur-du-son}}

Il est assez connu que le préampli peut également devenir un choix
esthétique pour influencer la couleur d'une prise de son. Cette question
semble assez complexe. Voici quelques éléments de réponse :

\begin{itemize}
\tightlist
\item
  Le choix du préampli est d'une influence minime par rapport à
  \textbf{tous} les autres choix précédemment fait.
\item
  Les préamplis sont souvent catégorisés, en termes de couleur, via les
  composants utilisés pour réaliser l'amplification. Attention, un
  composant électronique dépend toujours du contexte dans lequel il est
  placé (ici, du circuit électronique). Il est donc difficile de
  précisément qualifier le son d'un préampli à lampe ou à transistor de
  façon générique.
\item
  Les impédances d'entrée des préamplis ne sont souvent pas évoquées
  dans ces discussions. Hors, pour la plus parts des microphones (hors
  statiques), leur impédance de sortie peut être suffisamment élevée
  pour engendrer une déperdition en aigu et en transitoire. Cette
  déperdition peut être heureuse, ou malheureuse, mais surtout bien
  réelle. Une manière de s'en prémunir peut-être d'utiliser des «
  booster » de microphones (parfois également appelés préamplis),
  permettant d'augmenter le niveau de sortie des microphones et aussi
  d'adapter leur impédance.
\end{itemize}

\part{Outils de mixage}

\hypertarget{anatomie-dune-console-de-mixage}{%
\chapter{Anatomie d'une console de
mixage}\label{anatomie-dune-console-de-mixage}}

\hypertarget{manipulation-de-la-phase}{%
\chapter{Manipulation de la phase}\label{manipulation-de-la-phase}}

\hypertarget{egalisation-et-uxe9galiseurs}{%
\chapter{Egalisation et égaliseurs}\label{egalisation-et-uxe9galiseurs}}

\hypertarget{les-compresseurs}{%
\chapter{Les compresseurs}\label{les-compresseurs}}

\hypertarget{les-limiteurs}{%
\chapter{Les limiteurs}\label{les-limiteurs}}

\hypertarget{les-autres-outils-de-gestion-de-la-dynamique}{%
\chapter{Les autres outils de gestion de la
dynamique}\label{les-autres-outils-de-gestion-de-la-dynamique}}

\hypertarget{mise-en-espace-et-ruxe9verbuxe9ration}{%
\chapter{Mise en espace et
réverbération}\label{mise-en-espace-et-ruxe9verbuxe9ration}}

\hypertarget{saturation-et-distortion-du-signal}{%
\chapter{Saturation et distortion du
signal}\label{saturation-et-distortion-du-signal}}

\hypertarget{effets-modulations}{%
\chapter{Effets \& modulations}\label{effets-modulations}}

\part{Méthodologie de mixage}

\hypertarget{ecoute-critique-deuxiuxe8me-partie}{%
\chapter{Ecoute critique : deuxième
partie}\label{ecoute-critique-deuxiuxe8me-partie}}

\hypertarget{approche-guxe9nuxe9rale}{%
\chapter{Approche générale}\label{approche-guxe9nuxe9rale}}

\hypertarget{etude-des-cas-duxe9cole}{%
\chapter{Etude des cas d'école}\label{etude-des-cas-duxe9cole}}

\hypertarget{piuxe8ges-et-erreurs-uxe0-uxe9viter}{%
\chapter{Pièges et erreurs à
éviter}\label{piuxe8ges-et-erreurs-uxe0-uxe9viter}}

\part{Introduction à la spatialisation sonore}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

Cette section, et les suivantes ont à cœur de traiter le vaste sujet de
la spatialisation sonore. Il est assez rare de trouver des ouvrages
génériques sur les techniques du son abordant aussi cette discipline.
Mais cette lacune s'explique très facilement par la très faible part de
marché représenté pour les consommateurs de format audio immersif, comme
le fameux 5.1. Ces dernières années, les choses bougent un peu. Dolby
est revenu d'une longue traversée du désert avec le «~Dolby Atmos~»,
d'abord dans les salles et les auditoriums de cinéma, et aujourd'hui
dans le monde de la musique. On retrouve ainsi deux logiciels de mixage
phares, Pro Tools d'Avid et Logic Pro X d'Apple, intégrant nativement ce
«~Dolby Atmos~». Cet intérêt pour les technologies immersives se
retrouve aussi chez les constructeurs d'enceintes et de casques,
proposant des systèmes de plus en plus simples pour accéder a cette
expérience d'écoute. Alors, à la lumière de ces récentes évolutions, il
paraît important de se pencher sur les longues et riches histoires de la
spatialisation sonore, ainsi qu'aborder les différentes technologies et
techniques associées.

Cette partie théorique commence par un historique de la spatialisation
sonore, qui nous permettra de réaliser que cette conversation ne date
pas d'hier, ni de l'Atmos. Puis, il conviendra de s'attarder sur les
systèmes de diffusions et le positionnement des enceintes dans l'espace.
On pourra ainsi aborder les différents systèmes normés, amenés par des
constructeurs tels que DTS ou Dolby, mais aussi décrire et catégoriser
les systèmes d'écoutes qui échappent à ces approches rigides. On
différenciera alors les systèmes frontaux, les systèmes englobants à une
dimension, les systèmes englobants à deux dimensions (souvent appelés
«~immersif~») et les systèmes à trois dimensions.

Une fois ces deux blocs très généralistes abordés, nous attaquerons
alors une à une les grandes techniques permettant de réaliser des
mixages à destination de ces systèmes à multiples enceintes, avec dans
l'ordre :

\begin{itemize}
\tightlist
\item
  Le binaural
\item
  L'approche perceptive, ou «~orientée canal~»
\item
  L'ambisonique
\item
  La WFS, ou synthèse de front d'onde
\end{itemize}

Nous discuterons aussi du mixage orienté objet, proposé notamment par le
Dolby Atmos, mais aussi par d'autres, comme l'IRCAM et son «~Spat~»,
également intégré par FLUX:: Immersive dans son Spat Revolution.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Il n'y aura ici que peu de rappels sur les mécanismes de la perception
ainsi que sur notre capacité à localiser les sons dans l'espace. Ces
informations sont accessibles dans le chapitre~\ref{sec-son}.

\end{tcolorbox}

\hypertarget{sec-hist-spat}{%
\chapter{Historique de la spatialisation}\label{sec-hist-spat}}

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-warning-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Avertissement}]

Section en cours de création. Le texte n'est pas corrigé.

\end{tcolorbox}

De nos jours, (2023 à l'écriture de ce chapitre), le ``son immersif''
semble être faire partie des nouvelles technologies et la plupart des
fabricants se lancent sur ce marché. Il est d'ailleurs très fréquent de
voir ce ``son immersif'' vendu comme quelque chose de nouveau et
d'inédit. Pourtant, la question de l'espace sonore, de sa capture et de
sa restitution est presque aussi vieille que celle de l'enregistrement.

Nous tâcherons dans ce chapitre de retracer une histoire du son
spatialisé, en abordant l'apparition des différentes techniques, mais
aussi leurs concepteurs, et les ingénieurs qui y ont participés. Nous
traverserons donc près de cent-cinquante années d'histoire, en
commençant par les premiers essaies de son ``stéréophonique'' jusqu'au
mixage orienté objet et des opportunités de spatialisation qu'il offre.
D'autres part, nous tâcherons également de parler des compositeurs et
des artistes qui se sont accaparés la question de l'espace et sa
réstitution dans leur oeuvre.

Ce chapitre ne peut évidement pas être exhaustif, mais essaye tout de
même de donner une image d'ensemble assez juste.

\hypertarget{de-la-monophonie-uxe0-la-stuxe9ruxe9ophonie-un-besoin-despace}{%
\section{De la monophonie à la stéréophonie : un besoin
d'espace}\label{de-la-monophonie-uxe0-la-stuxe9ruxe9ophonie-un-besoin-despace}}

Pendant près de quatre-vingt ans, la majorité des systèmes de diffusion
sonores sont monophoniques. Il faut en effet attendre la fin des années
soixantes pour que l'écrasante majoritée de la musique enregistrée soit
produite en stéréophonie. Avant cela, le norme est donc à une écoute ne
se constituant que d'un seul haut-parleur.

Pourtant, le besoin d'espace dans la restitution sonore se fait sentir
très tôt, car plusieurs ingénieurs se penchent sur cette question dès le
début du XXème siècle. Il semble que le premier à proposer un système de
diffusion sur deux canaux soit
\textbf{\href{https://fr.wikipedia.org/wiki/Clément_Ader}{Clément Ader}}
(1841-1925). Cet ingénieur français est avant tout connu pour être le
premier à avoir fait décoller un engin motorisé plus lourd que l'air en
1890. Il a également participé au déploiment du réseau téléphonique, à
Paris, en 1879. C'est à ce moment qu'il a l'idée d'utiliser le réseau de
télécommunication pour diffuser l'opéra dans les foyers. Ce dispositif,
nommé
\textbf{\href{https://fr.wikipedia.org/wiki/Théâtrophone}{Théâtrophone}},
est pour la première fois utilisé en 1881. Les auditeurs peuvent alors
écouter la pièce retransmise en direct en plaçant un ``écouteurs'' sur
chacune de leurs oreilles. La diffusion se fait donc sur deux canaux.

A cette époque, les seuls microphones disponibles sont des microphones à
charbons, dont on connait la faible bande passante. La qualité sonore du
dispositif est donc médiocre, mais l'angouement du public est réel, et
perdurera jusque dans les années 1930.

\begin{figure}

{\centering \includegraphics{spatialisation/../_resources/bitmap/various/leGaulois2Avril1924.png}

}

\caption{Extrait du journal ``Le Gaulois'' du 2 Avril 1924}

\end{figure}

La stéréophonie va être pensée, quasiment simultanément par deux
ingénieurs,
\textbf{\href{https://en.wikipedia.org/wiki/Arthur_C._Keller}{Arthur C.
Keller}} (1901-1983) et
\textbf{\href{https://en.wikipedia.org/wiki/Alan_Blumlein}{Alan D.
Blumlein}} (1903-1942). Le premier travail aux laboratoires Bells, sous
la direction
d'\textbf{\href{http://www.byhigh.org/History/Fletcher/DrHarvey.html}{Harvey
Fletcher}} (le même Fletcher que les courbes
Flecther-Munson~\ref{fig-isosonie}). Keller se retrouve à travailler sur
la diffusion stéréophonique car on demande au chef d'orchestre
\textbf{\href{https://en.wikipedia.org/wiki/Leopold_Stokowski}{Leopold
Stokowski}} de produire des concerts sur les ondes de la NBC avec
l'orchestre de Philadelphia. Stokowski est, à l'époque, très insatisfait
de rendu sonore de ce type de dispositif et contact alors les
laboratoires Bells pour y apporter une solution. De cette collaboration
naît une collection d'enregistrements dont le plus vieux semble être
cette interprétation du
\href{https://www.stokowski.org/sitebuilderfiles/311201_Roman_Carnival_MA.mp3}{Le
Carnaval romain (Ouverture)} de Berlioz, interprété le cinq décembre
1931.

De l'autre côté de l'océan, Alan Blumlein travail pour la
\textbf{\href{https://en.wikipedia.org/wiki/Columbia_Graphophone_Company}{Colombia
Graphophone Company}}. L'histoire veut qu'il soit frustré de son
expérience du son au cinéma, ne comprenant pas pourquoi les voix sont
toutes au centre alors que les acteurs se déplacent de part et d'autre
de l'écran. Blumlein va donc proposer, pêle-mêle dans un seul et même
\href{https://en.wikipedia.org/wiki/United_Kingdom_patent_394325}{brevet},
les techniques de prises de son coincidente
XY/\href{https://en.wikipedia.org/wiki/Blumlein_pair}{Blumlein} et MS
(pour garantir la rétro-compatibilité sur les système mono), un système
de gravure à deux canaux sur disques microsillons et la discription du
système d'enceinte que l'on utilise encore aujourd'hui sous le nom
stéréphonie. Il est amusant de constater que dans ses écris, Blumlein ne
parle pas de son stéréophonique mais de son binaural. Ceci est d'autant
plus surprenant qu'il est le premier à revendiquer l'idée que les
haut-parleurs, dans un système stéréophonique, ne correspondent pas aux
oreilles, et qu'il convient donc d'étudier ce système avec une approche
psycho-acoustique. Blumlein invente également un système, qu'il appelle
``shuffling'', permettant de convertir une différence de phase en
différence d'intensité. Pour lui, ce dispositif fait parti intégrante
d'un système de prise de son stéréophonique. Cependant, ce ``shuffler''
ne sera pas du tout employé dans le reste de l'industrie.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

En 1931, La Colombia Graphophone Company et la
\href{https://en.wikipedia.org/wiki/Gramophone_Company}{Gramophone
Company} fusionnent pour devenir
\href{https://en.wikipedia.org/wiki/EMI}{EMI}.

\end{tcolorbox}

Il existe encore quelques enregistrements du travail d'Alan Blumlein,
par exemple, cette démonstration du
\href{https://www.youtube.com/watch?v=rqaMiDqE6QQ}{mouvement en
stéréophonie} (dans un style tout à fait anglais), ou encore cette
interprétation de la
\href{https://www.youtube.com/watch?v=gfWuIEgGUJk}{Chevauchée des
Valkyries pour trois pianos} enregistrée à Abbey Road. Ces deux
enregistrements dates de 1931.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le procédé de gravure stéréophonique sur microsillon de Keller et
Blumlein est très proche, cependant, il ne semble qu'aucun des deux n'ai
eu connaissance des travaux de l'autre. Keller aurait développé sont
système avant Blumlein, mais ce dernier a publié son brevet en premier.
Les deux approches reposent sur l'idée de gravé les deux canaux à 45° de
la verticale. Ce procédé semble être tombé dans l'oublie jusqu'à sa
``\href{https://ieeexplore.ieee.org/document/4065276}{réinvention}''
dans les années cinquantes par la société Westrex.

\end{tcolorbox}

Blumlein décède en plein milieu de la seconde guerre mondiale suite au
crash du bombardier Helifax, dans lequel il effectuait des tests sur le
système de \href{https://en.wikipedia.org/wiki/H2S_radar}{radar H2S}.

Malgré toutes ces avancés, la stéréophonie n'est rapidement adoptée. Il
y a pour cela deux raisons principales. La première est que les systèmes
de graves sur disques proposés par Blumlein ou Keller ne fonctionne pas
sur les gramophones, à cause du poids de la tête de lecture. Il faut
donc attendre leurs remplacements par les disques microsillons au milieu
des années cinquantes. Le second frein est, comme on le rencontrera
souvent, le coût pour s'équiper d'un deuxième amplificiteur et d'une
deuxième enceinte.

\begin{figure}

{\centering \includegraphics{spatialisation/../_resources/bitmap/various/WW1950.jpg}

}

\caption{Sur la diffusion stéréophonique - 1950}

\end{figure}

La situation se débloque dans les années soixantes. La radio devient
stéréophonique, en partie grâce au passage à la modulation FM. Le coût
des équipements devient aussi plus raisonnable. A la fin des années
soixantes, on peut considérer que l'ensemble de la production musicale
est passée à la stéréophonie. Il est d'ailleurs intéressant de noter que
ce passage à la stéréophonie ne s'est pas faite à la même vitesse selon
les esthétiques musicales. Dans les musiques dîtes ``classiques'', la
monophonie représente un tel frein à la représentation de l'espace
acoustique qu'il existe une réelle motivation à basculer sur un mode de
production stéréophonique. Dans les musiques dîtes ``populaires'' ou
``amplifiées'', la nécessité de la stérophonie est moins évidente, elle
d'ailleurs parfois perçu comme superficiel. Par exemple, il faudra
attendre le dernier album des Beatles enregistré (Abbey Road - 1969)
pour que avoir une version stéréo officielle, approuvée par George
Martin. Certains ont vu dans la stéréophonie une passade un peu
exubérante, mais qui ne durerait pas. L'histoire leur aura prouvé le
contraire. Il ne faut pas non plus leur jetter la pierre. Nombre des
premiers enregistrements stéréophoniques exploite les deux canaux de
mixage non pas comme un opportunité de mieux représenter l'espace, mais
surtout pour \textbf{démasquer} les éléments entre eux. On trouve donc
beaucoups de \href{https://www.youtube.com/watch?v=213W-8t9MLQ}{mixages}
avec les instruments répartis entre l'enceinte gauche et droite, et la
voix en plein centre.

Devant la généralisation de la stéréophonie, certains constructeurs,
labels et artistes vont alors tenter la courte aventure de la
quadriphonie.

\#\#~La grande aventure cinématographique du son immersif

Le \href{https://fr.wikipedia.org/wiki/Cin\%C3\%A9ma}{cinéma}, naît
autour de 1984, est une des industries du divertissement qui a le plus
mis en avant les intêrets d'une diffusion spatialisée. Sa dimension
visuelle spectaculaire et immersive (écran géant, salle noire, etc.) a
donc motivé un traitement du son similaire. On qualifie parfois le
cinéma des premiers temps de cinéma ``muet'', lié au fait qu'il
n'existait alors pas de son synchrone rattaché au film. Cependant,
imaginer le dispositif cinématographique comme un dispositif silencieux
est une erreur. Ce dernier est très souvent accompagné par un musicien
et il est alors courant pour le public de parler, de commenter la
projection. N'oublions pas qu'à l'origine le cinéma est un spectacle
forrain. Petit à petit le cinéma prend place dans les théâtres et dans
des lieux qui lui sont dédiés.

Le \href{https://fr.wikipedia.org/wiki/Vitaphone}{Vitaphone} est le
premier système de synchronisation sonore est développé par Westerne
Electric Company, en collaboration avec les laboratoires Bells, en 1924.
Le premier film partiellement parlant est
\emph{\href{https://fr.wikipedia.org/wiki/Le_Chanteur_de_jazz}{Le
Chanter de Jazz}} (1927) et le premier film intégralement parlant est
\href{https://en.wikipedia.org/wiki/Lights_of_New_York_(1928_film)}{Lights
of New York} (1928).

Le cinéma sonore s'appuis alors sur une diffusion monophonique, la
diffusion est d'ailleurs cachée derrière l'écran.

\hypertarget{fantasia-et-le-fantasound}{%
\subsection{Fantasia et le Fantasound}\label{fantasia-et-le-fantasound}}

\href{https://fr.wikipedia.org/wiki/Fantasia_(film,_1940)}{Fantasia} est
un film de
\href{https://fr.wikipedia.org/wiki/Walt_Disney_Pictures}{Walter Disney}
sorti au Etats-Unis en 1940. L'ambition de son auteur est de mettre en
image des oeuvres incontournables de la musique dîte ``classique''. Pour
cela, il s'associe avec le chef d'orchestre Leopold Stokowski (le même
personnage que nous avons évoqué plus haut).

L'ambition technique du film est énorme et, sous les éxigences de Wlat
Disney, pousse l'équipe technique à développer le
\href{http://www.widescreenmuseum.com/sound/fantasound1.htm}{Fantasound}.
Ce fantasound a deux objectifs principaux :

\begin{itemize}
\tightlist
\item
  Premièrement, améliorer le dynamique de diffusion sonore (alors
  limitée par le support)
\item
  Deuxièmement, \textbf{permettre de déplacer des sons dans l'espace}.
\end{itemize}

Le premier point donne naissance au premier VCA, piloter par la
fréquence d'un signal sinusoïdal inscrit sur le film. Le deuxième point
est solutionné par l'invention du premier ``pan pot''. Le Fantasound
utilise cinq canaux de diffusions, trois enceintes frontales (gauche,
centre et droit) ainsi que deux enceintes arrières (gauche et droite).
Fantasia est donc le premier film ``surround'' de l'histoire.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le Fantasound est donc l'ancêtre de ce que l'on appelle aujourd'hui le
5.1 (sans le caisson de grave).

\end{tcolorbox}

Cependant, le coût global du système Fantasound le rend impraticable,
pour le film Fantasia lui-même mais également pour d'autres productions.
En effet, il faut alors un petit régiment d'opérateur pour pouvoir
correctement diffuser le film.

\hypertarget{le-dolby-stereo-et-le-son-optique-matricuxe9}{%
\subsection{Le Dolby Stereo et le son optique
matricé}\label{le-dolby-stereo-et-le-son-optique-matricuxe9}}

Durant toute la période du son analogique, le plus grand ennemi de la
chaîne de production est le bruit. Ce bruit est particulièrement
inhérent aux supports magnétiques et optiques alors utilisés. C'est
ainsi que \href{https://fr.wikipedia.org/wiki/Ray_Dolby}{Ray Dolby}
lance son entreprise, \href{https://fr.wikipedia.org/wiki/Dolby}{Dolby
Laboratories}, en 1965, en commercialisant le
\href{https://en.wikipedia.org/wiki/Dolby_noise-reduction_system}{Dolby
NR} (1966).

Dans les années 70, les laboratoires Dolby élabore également un système
de diffusion cinématographie multicanal. Ce dispositif d'enceinte dit
LCRS (Gauche, Centre, Droit, et une enceinte arrière dite ``Surround''),
est associé à un matriçage 4-2-4 grandement ``inspiré'' par les travaux
de Peter Scheiber sur le matriçage quadriphonique. Ils auront simplement
la mauvaise idée d'appeler ce système ``Dolby Stereo''.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-important-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}]

Le mixage est réalisé sur quatres canaux : gauche, centre, droit et
arrière. Ces quatres canaux sont alors \textbf{matricés} sur deux canaux
que l'on nomme \emph{gauche total} et \emph{droite total}.

\begin{longtable}[]{@{}lllll@{}}
\toprule()
& L & R & C & S \\
\midrule()
\endhead
Lt & 1 & 0 & \(\sqrt{2}\over{2}\) & \(j\times{\sqrt{2}}\over{2}\) \\
Rt & 0 & 1 & \(\sqrt{2}\over{2}\) & \(-j\times{\sqrt{2}}\over{2}\) \\
\bottomrule()
\end{longtable}

Pour décoder le signal et retrouver quatres canaux de diffusion, on doit
alors \textbf{dématricer} les signaux Lt et Rt.

\begin{longtable}[]{@{}lll@{}}
\toprule()
& Lt & Rt \\
\midrule()
\endhead
L & 1 & 0 \\
R & 0 & 1 \\
C & 1 & 1 \\
S & 1 & -1 \\
\bottomrule()
\end{longtable}

Le canal central est alors formé par les signaux \textbf{en phase} du
matriçage bicanal. Le canal arrière est composé des signaux \textbf{en
phase} dans le matriçage bicanal.

\end{tcolorbox}

Les performances de la restitution de l'espace de ce système sont assez
médiocres, ou en tout cas, déséquilibrées vers la scène frontale. Cela
s'explique évidemment par le dispositif cinématographique et par la
présence de l'écran géant captant toute l'attention du spectateur. Il
reste tout de même difficile de le considérer comme un système
englobant, car l'écart entre les enceintes latérales et l'enceinte
arrière est tellement important que l'effet de source fantôme ne peut
pas être opérant.

Aussi, il est rare que ce canal «~surround~», ou arrière, ne soit
constitué que d'une seule enceinte à la diffusion. Il est courant de
rencontrer un dispositif en «~U~», situé à l'arrière du spectateur. Cela
n'arrange malheureusement pas nos histoires de précisions de restitution
du champ spatiale.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-important-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}]

En ce qui concerne la gestion du canal LFE (Low Frequency Effect), il
n'y a pas de canal dédié. C'est donc un simple système de «~bass
management~», où une partie du grave est filtré des «~têtes~» (enceintes
principales) et redirigé vers le subwoofer.

\end{tcolorbox}

Le tour de force de Dolby est en réalité de contourner la limitation du
support optique sans pour autant remettre en cause la chaîne de
production cinématographique. Même après l'avènement du son numérique,
une version Dolby Stereo était toujours présente sur la pellicule, pour
les salles non équipées en système de diffusion numérique, ou en cas de
panne de ce dernier.

Un des métrages emblématique de cette technologie Dolby Stereo est
\textbf{\href{https://fr.wikipedia.org/wiki/Star_Wars,_\%C3\%A9pisode_IV_:_Un_nouvel_espoir}{La
Guerre des Etoiles}} de
\href{https://fr.wikipedia.org/wiki/George_Lucas}{Georges Lucas}.

\hypertarget{le-passage-au-son-numuxe9rique}{%
\subsection{Le passage au son
numérique}\label{le-passage-au-son-numuxe9rique}}

Le matriçage du signal à de grandes conséquences sur l'intellégibilité
de l'espace et pause des problèmes importants de flou de localisation.
Lorsque le son numérique se démocratise, la nécessité du matriçage
disparait. On peut ainsi stocker plusieurs canaux audio numérisés sur
pellicule. D'ailleurs, plus besoin non plus de réducteur de bruit non
plus, la dynamique du signal numérisé est bien plus grande que celle
offerte par les supports analogiques.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le passage au son numérique fût le début d'une longue traversée du
désert pour l'entreprise Dolby.

\end{tcolorbox}

L'arrivée du son numérique impose aussi une rude concurence chez les
acteurs de cette mutation. On trouvera ainsi la société nîpone
\href{https://en.wikipedia.org/wiki/Sony}{Sony}, les californiens de
\href{https://en.wikipedia.org/wiki/DTS_(company)}{DTS} et encore et
toujours Dolby. On arrive d'ailleurs très bien à relire l'histoire de
cette courses aux nouveaux formats audio numériques en regardant une
pellicule de cette époque

\begin{figure}

{\centering \includegraphics{spatialisation/../_resources/bitmap/various/35mm_film_audio_macro.jpg}

}

\caption{Bord d'une copie 35~mm. À droite le Dolby Stereo (analogique),
à gauche, le Sony SDDS, au centre, le Dolby Digital, et enfin, tout à
droite, la bande de timecode du DTS}

\end{figure}

Dolby occupe déjà toute une partie de la pellicule avec le stockage
optique analogique du Dolby Stereo. Sony arrive alors le premier avec
son système de son numérique sur support optique avec le SDDS (Sony
Dynamic Digital Sound). Lorsque Dolby termine l'élaboration de son
encodage~AC-3 pour le Dolby Digital, il ne reste alors que l'espace
entre les perforations. Finalement, DTS est obligé de trouver une
solution de contournement et n'inscrit qu'une piste de timecode sur le
film. Cette piste permet alors de synchroniser un lecteur de CD-ROM
contenant la piste audio du film.

Le Dolby digital et le format DTS sont tous deux pensés pour une
diffusion sur un système~5.1. Le SDDS propose une couverture de l'espace
frontale plus importante, avec 5~enceintes accompagnées de deux
enceintes arrière pour le «~surrounds~». En pratique, ces canaux de
diffusions supplémentaires ne sont pas exploités en phase de mixage, et
les mixeurs se content de fournir un 5.1 compatible avec l'ensemble des
formats. Le premier film mixé en DTS est
\href{https://fr.wikipedia.org/wiki/Jurassic_Park}{Jurassic Park}
(1993), de Steven Spielberg, tandis que le premier film utilisant le
système Sony est
\href{https://fr.wikipedia.org/wiki/Last_Action_Hero}{Last Action
Hereos} (1993) par John McTiernan

Le 5.1 n'a pas franchement eu de succès dans son exploitation
commerciale. Les raisons sont toujours un peu les mêmes~: le coût, la
place, l'esthétique (certains et certaines n'aiment pas peupler leur
séjour d'enceintes), et les câbles. Ce format s'est donc limité à un
public de niche, souvent associé à l'audiophilie.

Il y eu ensuite une multitudes de formats dérivés et d'évolutions, comme
le Dolby Digital Surround EX, rajoutant une enceinte centrale à
l'arrière. Les formats domestiques fûrent également nombreux, avec les
Dolby Surround, Dolby Logic Pro, Dolby Logic Pro II, etc.

L'évolution ``majeure'' suivante est le passage au 7.1, ou l'on
considère alors deux enceintes plein gauche et droite et deux enceintes
arrière pour compléter le LCR classique. Le premier film mixé en 7.1 est
\href{https://en.wikipedia.org/wiki/Toy_Story_3}{Toy Story 3} (2010),
des studios Pixar.

\hypertarget{passage-au-mixage-orientuxe9-objet-et-le-retour-en-force-de-dolby}{%
\subsection{Passage au mixage orienté objet et le retour en force de
Dolby}\label{passage-au-mixage-orientuxe9-objet-et-le-retour-en-force-de-dolby}}

En 2012, Dolby annonce un tout nouveau format de mixage, le
\href{https://en.wikipedia.org/wiki/Dolby_Atmos}{Dolby Atmos}. Il s'agit
d'une technologie hybride entre mixage orienté canal et mixage orienté
objet. Cette approche de mixage orienté objet consiste à considérer une
source sonore (un canal audio mono par exemple) comme un objet, auquel
on associe des informations de mixage (volume et position dans
l'espace), qui sont ensuite interprétées par un décodeur. Ce dispositif
permet initialement de travailler sur un système d'enceintes dit 7.1.4,
soit une 7.1 augmentée de quatres enceintes en élévation. Il s'agit donc
d'un des premiers format cinéma intégrant la composante d'élévation.

L'avantage d'une approche orientée objet est de solutionner la
problématique de ``mixdown'' des films. En effet, un métrage
précédemment mixé en 7.1 doit ensuite être downmixé en 5.1 pour les
cinéma moins bien équipés, puis aussi en stéréo pour exploitation
télévisuelle. Ici, il suffit d'indiquer au décodeur le système de
haut-parleurs qui lui est connecté et les méta-données de mixage seront
interprété pour retranscrire au mieux le mixage. On peut même réalisé un
mixage dédié à une écoute au casque, en utilisant la synthèse binaurale.

Ce format Dolby Atmos est un succès majeur, replaçant Dolby dans une
situation de monopole. Très rapidement, le logiciel \emph{Pro Tools}
d'AVID intègre le premier panner Dolby Atmos, et les salles de cinéma
sont rapidement équipés en Atmos.

Ce succès s'infusera aussi dans le monde de la musique. En 2021, Apple
annonce le support natif du Dolby Atmos (avec pour la première fois, le
moteur de rendu Dolby Atmos intégré) dans son logiciel de musique
assitée par ordinateur \emph{Logic Pro}. De plus, son service de
streaming, Apple Music, intègre également le support de la lecture de
mixages réalisés avec le Dolby Atmos.

\hypertarget{le-binaural-la-spatialisation-sonore-pour-tous}{%
\section{Le binaural : la spatialisation sonore pour
tous}\label{le-binaural-la-spatialisation-sonore-pour-tous}}

Il est bon que nous donnions ici une définition précise de binaural. De
nos jours, le binaural rassemble l'ensemble des techniques et des moyens
permettant de reproduire l'effet du corps humain (tête, oreilles, torse)
sur un signal audio. Un signal binaural comporte donc deux canaux,
filtrés par la réponse en fréquence du corps humain. Cependant, dans
l'histoire du son, le terme binaural a souvent été utilisé comme
synonyme du son stéréophonique.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Par ailleurs, le termes ``stéréophonie'' se substitue toujours pour
désigner tous flux audio comprenant deux canaux. Ce n'est rigoureusement
pas juste, car la stéréophonie sous-entendant la diffusion sur un
système de haut-parleurs spécifique.

\end{tcolorbox}

L'\href{https://www.researchgate.net/publication/233582452_Binaural_Recording_Technology_A_Historical_Review_and_Possible_Future_Developments}{histoire
du son binaural} s'anime également dans les années 1930, dans les
laboratoires Bell. H. Flecther dirige alors une équipe travaillant sur
la mise au point d'un mannequin de cire équipé de microphones sur les
joues, nommé Oscar.

\begin{figure}

{\centering \includegraphics{spatialisation/../_resources/bitmap/binaural/oscar.png}

}

\caption{Oscar : premier dispositif d'enregistrement binaural}

\end{figure}

Ce premier dispositif permet de réaliser un certain nombre de test sur
notre perception. Il est alors rapidement montré que la parte de l'image
dans l'écoute d'un signal binaural entraine l'augmentation d'erreurs de
localisation.

En Europe, deux chercheurs de la société Néerlandaise
\href{https://fr.wikipedia.org/wiki/Philips}{Philips}, De Boer et
Vermeulen, développe le premier mannequin avec une simulation de l'effet
du pavillon, grâce à l'intégration du microphone directement dans
l'oreille.

Dans les années 40, De Boer dépose un brevet pour un système de prise de
son utilisant une simple sphere d'au moins quatorze centimètre de
diamètre en lieu et place d'une tête de mannequin. Les microphones sont
alors placés de part d'autre de la sphère.

Toujours aux Pays-Bas, il est alors fait l'expérience de la diffusion de
contenu binaural sur les ondes radio, utilisant sans doute le mannequin
de De Boer et Vermeulen.

Durant les années cinquantes, plusieurs companies développent leur
propre systèmes de prise de son binaural, notemment Schoeps et AKG.

\begin{figure}

\begin{minipage}[b]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{spatialisation/../_resources/bitmap/binaural/akg-dummyhead1.png}

}

\caption{Première tête factice d'AKG}

}

\end{minipage}%
%
\begin{minipage}[b]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{spatialisation/../_resources/bitmap/binaural/schoeps-sphere.png}

}

\caption{Sphère de prise de son Schoeps}

}

\end{minipage}%

\end{figure}

Les années soixante et soixante-dix sont marquées par de nombreuses
études sur l'écoute binaural et l'effet de notre corps sur les signaux.
Le système KEMAR devient le premier mannequin de référence. Les
mannequins précédents étant souvent récupéré de grands magasins, leur
propriétés acoustiques ne correspondent à celle du corps humain. Ce
paramètre est alors corrigé par le modèle KEMAR et est ainsi le premier
utilisé pour des mesures de protèses auditives.

En 1973, la société Neumann dévoile sa tête artificielle \textbf{KU-80},
équipée de microphones omni-directionnels \textbf{KM83}. L'année
suivante, AKG propose elle aussi son système de prise de son binaural
\textbf{D99c}.

\begin{figure}

\begin{minipage}[b]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{spatialisation/../_resources/bitmap/binaural/kemar.png}

}

\caption{KEMAR}

}

\end{minipage}%
%
\begin{minipage}[b]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{spatialisation/../_resources/bitmap/binaural/neumann-ku80.png}

}

\caption{Neumann KU80}

}

\end{minipage}%
%
\begin{minipage}[b]{0.33\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{spatialisation/../_resources/bitmap/binaural/akg-d99c.png}

}

\caption{AKG d99c}

}

\end{minipage}%

\end{figure}

En 1997, un groupe de chercheur publie une
\href{https://www.aes.org/e-lib/browse.cfm?elib=7375}{étude comparative
des différentes têtes artificilles} de l'époque. Il en ressort un
problème persistant de trouble de la localisation, particulièrement sur
la discrimination de l'avant et de l'arrière. Est alors mis en cause la
forme des pavillons des différents mannequins. En partant des résultats
de cette étude, plusieurs initiatives vont apparaitres, et vont alors
mesurer la réponse en fréquence de la tête d'un grand nombre d'individu,
et chercher ainsi à trouver la courbe correspondant au plus grand
nombre. Ce type d'approche donnera, entre-autre, naissance à la tête
KU-100 de Neumann.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le résultat de ce type de mesures se nomment \textbf{HRTF}, pour
Head-Related Transfer Function, ou, fonction de transfert de la tête.

\end{tcolorbox}

Grâce au passage à l'audio-numérique, ainsi qu'à l'augmentation
significative de la puissance de calcul des ordinateurs, on voit
apparaître dans les années quatre-vingt-dix la technique de la
\href{https://www.aes.org/e-lib/browse.cfm?elib=8319}{synthèse binaural}
(voir section~\ref{sec-binaural-synthese}). Il devient alors possible à
partir de simples prises de son monophonique de recréer l'effet de la
tête sur le signal grâce à une batterie de filtres (toujours ces
fameuses HRTF).

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Astuce}]

En France, \href{https://sonbinaural.com/}{Lucie Hardoin} est une
spécialiste de prise de son et de la post-production binaurale. Elle met
à disposition sur son site web un grand nombre d'extrait pour en
découvrir les qualités sonores.

\end{tcolorbox}

\hypertarget{les-pionniers-de-la-musique-spatialisuxe9}{%
\section{Les pionniers de la musique
spatialisé}\label{les-pionniers-de-la-musique-spatialisuxe9}}

S'il est important de couvrir l'histoire technologique, il l'est tout
autant de raconter celle de ceux qui ont pensé la spatialisation sonore
dans leurs créations. Les mouvements de la
\href{https://fr.m.wikipedia.org/wiki/Musique_concr\%C3\%A8te}{musique
concrète} et de la
\href{https://fr.m.wikipedia.org/wiki/Musique_\%C3\%A9lectroacoustique}{musique
électroacoustique} ont été particulièrement fécond sur ce sujet.

\href{https://fr.m.wikipedia.org/wiki/Pierre_Schaeffer}{Pierre
Schaeffer} (1910-1995), ingénieur français diplômé de l'école
polytechnique, propose les
\href{http://archive.olats.org/pionniers/pp/schaeffer/theorieSchaeffer.php}{fondations
esthétiques et théorique} de la musique concrète dans les années
quarante. Au coeur de ces idées est celle de
l'\href{http://www.musiques-recherches.be/musiques-recherches/presentation}{acousmatique}.
Une musique dîte acousmatique est une musique qui est complètement
arrachée à tout context (notemment visuel) et n'est plus que son. Ce
type de musique est donc grandement le fruit des avancés technologiques
en matière d'enregistrement sonore. L'objectif de écoute acousmatique
est de permettre à l'auditeur une plus grande imagination à la réponse
du stimuli sonore seul. Ce concept est étroitement lié avec l'art
radiophonique et ses moyens de diffusion. Suite à sa rencontre avec
\href{https://fr.wikipedia.org/wiki/Pierre_Henry}{Pierre Henri}
(1927-2017), les deux hommes crééront
``\href{https://fr.m.wikipedia.org/wiki/Symphonie_pour_un_homme_seul}{Symphonie
pour un homme seul}'' en 1950. Henri collaborera aussi avec
\href{https://fr.wikipedia.org/wiki/Edgard_Var\%C3\%A8se}{Edgar Varèse}
en 1954 pour la création de \emph{Déserts} au Théâtre des
Champs-Elysées, en tant que spatialisateur. Le concert est aussi diffusé
à la radio, et pour la première fois en stéréophonie.

En 1951, Schaeffer créer le ``Groupe de Recherche en Musique Concrète'',
avec Pierre Henri à sa tête, qui deviend dès 1958 le
``\href{https://fr.m.wikipedia.org/wiki/Groupe_de_recherches_musicales}{Groupe
de Recherche Musique}'' (GRM). On y retrouve alors, entre autre,
\href{https://fr.m.wikipedia.org/wiki/Iannis_Xenakis}{Iannis Xenakis},
\href{https://fr.m.wikipedia.org/wiki/Michel_Chion}{Michel Chion} et
\href{https://fr.m.wikipedia.org/wiki/Fran\%C3\%A7ois_Bayle}{François
Bayle} (Pierre Henri quitte le projet en 1958, avant la création du
GRM).

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Pierre Schaeffer fonde également le
\href{https://fr.m.wikipedia.org/wiki/Service_de_la_recherche_de_la_RTF}{service
de recherche de la RTF} en 1964, dédié à la recherche autour de radio et
de la télévision.

\end{tcolorbox}

Cette branche de la musique a à coeur d'étudier les effets de la
captation sonore et de sa diffusion. Si on y réflechi beaucoup sur le
sujet de la transformation du son par la manipulation de son support de
stockage, on se pose également la question du moyen de diffusion. En
1974, François Bayle invente l'orchestre de hautparleurs qu'il nomme
\href{https://inagrm.com/fr/showcase/news/202/lacousmonium}{acousmonium}.
Ce système de diffusion est constitué de multiples hautparleurs, de
taille et qualités sonores différentes, placés sur scène, comme des
musiciens. Ces hautparleurs sont alors ``orchestré'' par le compositeur
qui opère depuis une table de mixage, parfois aussi appelée table de
spatialisation. Ce dispositif existe toujours et est régulièrement
utilisé en concert.

\begin{figure}

{\centering \includegraphics{spatialisation/../_resources/bitmap/various/acousmonium-74.png}

}

\caption{Une des première forme de l'acousmonium}

\end{figure}

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Astuce}]

A découvrir, une
\href{https://www.ina.fr/ina-eclaire-actu/audio/phd98021693/ecouter-grm-2eme-partie-l-acousmonium}{archive
de 1983} sur l'acousmonium et la musique que l'on lui fait jouer.

\end{tcolorbox}

Egalement, est créé en 1970 le Groupe de musique expérimentale de
Bourges (\textbf{GMEB}) par
\href{https://fr.wikipedia.org/wiki/Fran\%C3\%A7oise_Barri\%C3\%A8re}{Françoise
Barrière} et
\href{https://fr.wikipedia.org/wiki/Christian_Clozier}{Christian
Clozier}. Il sera à l'origine de l'invention d'une table de
spatialisation nommé
\href{https://misame.org/wp-content/uploads/1670/18/9-Concept-du-Gmebaphone-p126.pdf}{Gmebaphone}.
Si l'acousmonium propose un ``routage'' dynamique des signaux vers les
différents hautparleurs, le Gmebaphone adopte une approche de filtrage,
découpant le signal entrant en bandes pour les répartir sur différents
hautparleurs spécialisés.

\begin{figure}

{\centering \includegraphics{spatialisation/../_resources/bitmap/various/gmebaphone.jpeg}

}

\caption{Le Gmebaphone}

\end{figure}

Le GMEB devient l'IMEB en 1997 (Institut de Musique Expérimentale de
Bourges) avant d'être fermé définitivement en juillet 2011.

A partir des années 50, un grand nombre de compositeurs (principalement
de musique électro-acoustique et électronique) se poseront cette
question de
l'\href{http://sonhors.free.fr/panorama/sonhors13.htm}{espace et la
spatialisation}. On peut alors citer :
\href{https://fr.wikipedia.org/wiki/Iannis_Xenakis}{Iannis Xenakis},
\href{https://fr.wikipedia.org/wiki/Olivier_Messiaen}{Olivier Messaien},
\href{https://fr.wikipedia.org/wiki/Karlheinz_Stockhausen}{Karlheinz
Stockhausen} et un certain
\href{https://fr.wikipedia.org/wiki/Pierre_Boulez}{Pierre Boulez} qui
fondra l'\href{http://www.ircam.fr/}{IRCAM} en 1970.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Astuce}]

A noter l'excellent site
\href{https://electrodoc.musiques-recherches.be/fr/accueil}{Electrodoc},
centre de documentation en musiques électroacoustiques. On y trouve de
multiples documentations sur les personnes et les oeuvres rattachées à
la musique électroacoustique.

\end{tcolorbox}

\hypertarget{la-quadriphonie-une-entreprise-infructueuse}{%
\section{La quadriphonie : une entreprise
infructueuse}\label{la-quadriphonie-une-entreprise-infructueuse}}

La \href{https://en.wikipedia.org/wiki/Quadraphonic_sound}{quadriphonie}
(quadraphonic, quadrasonic ou encore quadrophonic en anglais) est le
premier format dit ``surround'' accessible au grand public. Les
premières tentatives de productions musicales en en quadriphonie
commencent en 1969. Le directeur artistique Thomas Mowrey a alors
réalisé un grand nombre de disques quadriphoniques, notamment pour le
label \href{https://en.wikipedia.org/wiki/Deutsche_Grammophon}{Deutsche
Grammophon}.

Il a existé trois formats de quadriphonie. Ils sont notés de la façon
suivante~: K-M-N. K indique le nombre de canaux de mixage, M le nombre
de canaux du support de diffusion et N le nombre de canaux de
restitution (ici, N est donc toujours égal à quatre).

\begin{itemize}
\item
  Le 4-4-4, que l'on pourrait qualifier de «~vrai~» quadriphonie. Cela
  impose un équipement tout particulier pour le support de diffusion. En
  effet, l'écrasante majorité des magnétophones à bandes et des disques
  microsillons sont stéréo. Certains constructeurs ont donc vendu des
  magnétophones «~quadriphoniques~», tandis que d'autres ont tenté de
  stocker ces quatre canaux sur disques microsillons grâce à des
  techniques de modulation d'amplitude. Cependant, ces procédés imposent
  tout de même d'équiper son lecteur vinyle d'une pointe en diamant
  spécifique.
\item
  Le 4-2-4, cherche à simplifier les choses pour les auditeurs. Grâce à
  un jeu de matriçage, on encode le signal quadriphonique sur deux
  canaux, que l'on espère récupérer intact par dématriçage. Si ce
  matriçage fonctionne parfaitement pour des sons purs, il n'en est rien
  pour des sons complexes, qui peuvent alors induire une corrélation
  importante entre les différents canaux. Le matriçage le plus
  convaincant fût proposé par
  \href{https://en.wikipedia.org/wiki/Peter_Scheiber}{Peter Scheiber} et
  perfectionné par
  \href{https://en.wikipedia.org/wiki/Benjamin_Bauer}{Benjamin Bauer}
  (\href{https://en.wikipedia.org/wiki/Stereo_Quadraphonic}{SQ
  Quadriphonic}), mais même celui-la posait un problème sur la
  correlation des canaux de diffusions. En effet le niveau de séparation
  entre deux enceintes adjacentes n'était que de trois décibels. Ce jeu
  d'encodage et de décodage distord l'espace sonore et ne produit pas
  des résultats satisfaisants.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Il ``inspirera'' pourtant les laboratoires de Dolby pour élaborer leur
fort mal nommé «~Dolby Stéréo~»

\end{tcolorbox}

\begin{itemize}
\tightlist
\item
  Reste le 2-2-4, que l'on pourrait qualifier du «~pire des deux
  mondes~». Le principe consiste à «~inventer~» des canaux arrière à un
  mixage stéréophonique, pour produire un effet englobant. Le résultat
  est souvent flou et insatisfaisant.
\end{itemize}

La plupart des enregistrements multi-canaux produits par la Deutsche
Grammophon ne sont jamais sortis qu'en stéréo. En effet, le label n'a
pas été convaincu par la qualité du rendu sonore quadriphonique,
notemment à cause du matriçage 4-2-4.

La complexité d'installation, et l'existance de nombreux formats (dont
certains n'offrant pas une qualité de restitution satisfaisante),
expliquent largement l'échec commercial du format quadriphonique.

L'exploitation commerciale du son quadriphonique, ou sa tentative
d'exploitation, ne se cantonne bien-sûr pas qu'à la musique dîte
``classique''. Un grand nombre d'artiste et de groupe ``pop'' verront
leur mixage stéréo déclinés en quadriphonie. Les plus connus sont sans
doute les \textbf{Pink Floyd}. Dès
\href{https://www.wired.com/2009/05/dayintech-0512/}{1967}, ils
embarquent en concert l'azimuth coordinator, leur permettant de recréer
une diffusion quadriphonique. En 1972-1973, leur ingénieur du son de
l'époque, Alan Parson propose un mix quadriphonique de leur album alors
en production, The Dark Side of the Moon.

Malgré tout, le format sera un échec commercial cuisant : trop cher pour
équiper un grand nombre de personne, souvent de qualité douteuse à cause
de l'étape de matriçage, existant sous de nombreux formats, etc. On
trouve tout même aujourd'hui un certains nombre de mixages
quadriphonique des années soixante-dix édités sur SACD ou DVD-Audio. Le
label anglais
\href{https://en.wikipedia.org/wiki/Dutton_Vocalion}{Dutton Vocalion} a
dans son catalogue plusieurs dixaines de ces
\href{https://www.duttonvocalion.co.uk/products.php?cat=3}{rééditions},
principalement de musique dîte ``classique''.

\hypertarget{lambisonique-duxe9corruxe9ler-lespace-de-production-et-lespace-duxe9coute}{%
\section{L'ambisonique : décorréler l'espace de production et l'espace
d'écoute}\label{lambisonique-duxe9corruxe9ler-lespace-de-production-et-lespace-duxe9coute}}

Depuis le milieu des années soixante, une équipe de chercheurs anglais
de la
\href{https://en.wikipedia.org/wiki/National_Research_Development_Corporation}{National
Research Development Corporation} mènent de nombreuses recherches sur la
spatialisation sonore et sur le son ``surround''. Nous sommes donc en
plein coeur du (bref) boom de la quadriphonie. Parmis eux, on retrouve
particulièrement le mathématicien
\href{https://en.wikipedia.org/wiki/Michael_Gerzon}{Micheal Gerzon}
(1945-1996)

Ensemble, ils élaborent une proposition alternative au son matricé
quadriphonique qu'ils nomment
``\href{https://intothesoundfield.music.ox.ac.uk}{ambisonique}''. Le
principe fondamentale de cette technique est de décomposer l'espace
sonore en plusieurs ``directions'', ou plus justement, en plusieurs
harmoniques sphériques. Alors, nous ne prend plus le son, ni ne le
mixons, en tenant compte d'un système de diffusion précis (stéréophonie
ou quadriphonie par exemple), mais plutôt en représentant un
\textbf{espace échantillonné}.

Le premier apport concret des recherches de Michael Gerzon et de ses
collègues est le développement d'une technique de prise de son utilisant
un tétraèdre de microphones.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/2_calrec-4-web.jpg}

}

\caption{Le tétraèdre, monté avec des microphones Calrecs, ancêtre des
microphones ambisoniques}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/1_mag-plus-c-web.jpg}

}

\caption{Michael Gerzon installant le système tétraédrique}

}

\end{minipage}%

\end{figure}

De tels dispositifs étant limités par l'encombrement spatial de chaque
microphone, il fût ensuite inventé les microphones ambisoniques,
regroupant les quatres capsules de façons aussi coincidentes que
possible. Le premier de ce type est le Soundfield, qui fit son batême en
Fevrier 1975.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/8_26.-ambi-landscape-g-web.jpg?itok=FgQnOxz6}

}

\caption{Microphone Soundfield}

\end{figure}

La même année, Michael Gerzon rédige deux articles sur le
\href{https://www.michaelgerzonphotos.org.uk/articles/Ambisonics\%201.pdf}{principe
général} de l'ambisonique et son
\href{https://intothesoundfield.music.ox.ac.uk/sites/default/files/intothesoundfield/documents/media/ambisonics_2.pdf}{utilisation
en studio}. On y trouve notamment la définition des différents formats
d'ambisonique, principalement:

\begin{itemize}
\tightlist
\item
  Le A-Format, correspondant aux canaux du microphones Soundfield
\item
  Le B-Format, format matricé WXYZ (W est le canal omni, ou commun, les
  autres canaux sont les harmoniques sphériques permettant d'apposer une
  direction au son)
\end{itemize}

L'ambisonique, comme technique de production et de prise de son, ne
rencontra malheureusement qu'un intêret très limité. On notera tout de
même le label \href{https://www.wyastone.co.uk/}{Nimbus records -
Enregistrements ambisoniques} qui a enregistré la quasi-intégralité de
son catalogue en ambisonique. Elle reste alors longtemps une technique
restreinte au monde de la recherche.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Michael Gerzon est très influencé par le brevet de 1931 d'Alan Blumlein
sur le son stéréophonique. On y retrouve la même idée de matriçage
(Stéréo - MS, A-Format - B-Format) et une emphase sur le prise de son
coincidente. Gerzon a d'ailleurs écrit un
\href{http://decoy.iki.fi/dsound/ambisonic/motherlode/data/6939.pdf}{article}
sur le circuit de shuffler d'Alan Blumlein.

\end{tcolorbox}

\hypertarget{les-grands-instituts-de-recherches}{%
\section{Les grands instituts de
recherches}\label{les-grands-instituts-de-recherches}}

\hypertarget{lircam-institut-de-recherche-et-coordination-acoustiquemusique-1970}{%
\subsection{L'IRCAM : Institut de recherche et coordination
acoustique/musique
(1970)}\label{lircam-institut-de-recherche-et-coordination-acoustiquemusique-1970}}

\#\#\#~AALTO

\hypertarget{iem}{%
\subsection{IEM}\label{iem}}

`\{=html\}

\hypertarget{les-espaces-haut-parlants}{%
\chapter{Les espaces haut-parlants}\label{les-espaces-haut-parlants}}

Une fois n'est pas coutume, nous allons aborder le problème de la
spatialisation par sa fin~: le système de diffusion. De quoi parle-t-on
lorsque l'on parle d'un système «~immersif~». À vrai dire, que qualifie
réellement ce terme «~immersif~»~?

Si nous raisonnons simplement, notre expérience naturelle du son est
immersive. Nous sommes (plus ou moins) capables d'identifier la position
d'un évènement sonore dans l'espace. Dès lors, placer une enceinte dans
un lieu est déjà une expérience immersive. En effet, nous pouvons nous
déplacer autour, nous en éloigner, nous rapprocher, etc. Aussi, la
réverbération naturelle du lieu va aussi créer une sensation
d'enveloppement, plus ou moins grande, en fonction de son temps de
décroissance et de sa puissance sonore.

Nous commençons donc à pressentir qu'il ne faut pas confondre
l'\textbf{espace d'écoute}, situé après les enceintes, et
l'\textbf{espace produit}, situé avant les enceintes. Quand on nous
parle d'«~immersif~», c'est bien à l'espace produit que l'on fait
référence. Selon la formule de Jean-Marc Duchenne, on définit ainsi
l'\textbf{espace haut-parlant} comme ce que l'on donne à entendre.

\hypertarget{catuxe9gorisation-des-espaces-haut-parlants}{%
\section{Catégorisation des espaces
haut-parlants}\label{catuxe9gorisation-des-espaces-haut-parlants}}

On peut généralement différencier deux types de spectacle sonores~: ceux
où la position de l'auditeur est connue et fixe, et ceux où l'on ne peut
pas présupposer du positionnement de l'auditeur. Par exemple, lors de
l'écoute d'un disque, on suppose que l'auditeur se positionnera au point
d'écoute idéal (sweetspot), qui était alors la même place que
l'ingénieur du son pendant sa production. À l'inverse, en muséographie,
l'auditeur se déplace en permanence et, même si souvent guidés par un
sens de visite, ses déplacements sont aléatoires.

Ces deux grandes catégories ont une forte influence sur le choix des
technologies de spatialisation.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le cas du concert amplifié est un peu plus ambigu. Les zones dédiées au
public sont connues à l'avance, et l'on suppose que celui-ci ne se
déplace pas pendant le spectacle. Cependant, on cherche à tout prix à
éviter la création d'un sweetspot. Cela impliquerait que le rendu sonore
serait idéal pour quelques personnes et médiocre pour le reste du
public. On parle alors de zones de diffusions, que l'on tente de rendre
aussi homogènes que possible. Ce travail est celui du caleur système.

On considère d'ailleurs souvent que les mixages live sont monophoniques,
et que le distribue le même mixage sur plusieurs points de diffusion.
Cela se nomme la «~multi-mono~». Ici, la nécessité de multiples points
de diffusions relève de l'homogénéité de la diffusion, et rarement du
souci de la spatialisation. Cependant, les techniques de spatialisation
permettent aussi d'accroître cette homogénéité, tout en ajoutant une
dimension spatiale au spectacle.

\end{tcolorbox}

Le second cas, où l'auditeur est libre de ses déplacements, donne
également la plus grande liberté sur le choix du système à déployer. Les
haut-parleurs pourront alors peupler l'espace en n'importe quel point et
deviennent alors un élément à part entière de la création sonore. On
pourrait même envisager le choix d'un haut-parleur pour une réponse en
fréquence particulière, ou pour tout autre défaut qui pourrait prendre
sens dans la narratologie d'une œuvre. Cette approche a été un des
points de réflexion centraux de la musique concrète et acousmatique. Les
espaces haut-parlants supposant un emplacement d'écoute idéal sont les
plus courants. Ils concernent la musique enregistrée, le cinéma et une
grande majorité du spectacle vivant.

\hypertarget{les-systuxe8mes-de-diffusions}{%
\section{Les systèmes de
diffusions}\label{les-systuxe8mes-de-diffusions}}

On peut sous-catégoriser les espaces haut-parlants en caractérisant le
système de haut-parleurs utilisé. On distingue ainsi quatre grandes
familles~:

\begin{itemize}
\tightlist
\item
  Les systèmes frontaux
\item
  Les systèmes englobants à une dimension
\item
  Les systèmes englobants à deux dimensions
\item
  Les systèmes à trois dimensions
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-important-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}]

On considère ici un système de coordonnées sphérique, comprenant donc la
distance ( \(\rho\) , sur le schéma ci-dessous), l'azimut ( \(\Theta\) )
et l'élévation ( \(\delta\) ). Ce repère offre l'avantage d'être au plus
proche de notre perception de l'espace.

\begin{figure}[H]

{\centering \includegraphics{spatialisation/../_resources/bitmap/math/Spherical-Coordinates--28Latitude-2C-Longitude-29.png}

}

\caption{\label{fig-sphere}Repère de coordonnées sphériques}

\end{figure}

\end{tcolorbox}

Dans la première catégorie, on retrouve notamment deux systèmes
historiques~: la monophonie et la stéréophonie. Le premier se résume par
un espace haut-parlant comprenant un unique haut-parleur. Le second est
décrit comme un espace haut-parlant comprenant deux haut-parleurs,
formant un triangle équilatéral avec l'auditeur. On pourra également
évoquer le système LCR, principalement associé au cinéma. En spectacle,
on trouve parfois des systèmes en lignes d'enceintes, comme le L-ISA
d'L-acoustique, ou encore certains systèmes utilisant la \textbf{WFS}
(voir le chapitre~\ref{sec-wfs})

Les systèmes englobants à une dimension comprennent l'ensemble des
systèmes de haut-parleurs encerclant l'auditeur, offrant ainsi un degré
complet de liberté de spatialisation. Le mixeur peut ainsi placer un son
tout autour de l'auditeur en changeant son angle d'incidence. On pense
alors au système quadriphonique, et à tous les systèmes de cinéma dit
«~surround~»~: LCRS, 5.1, 7.1, etc.

Les systèmes englobants à deux dimensions rajoutent un nouvel axe de
liberté, permettant d'élever un son. Le Dolby Atmos est sans doute le
représentant le plus connu de cette famille de système. Ces systèmes
sont le plus souvent, pour des raisons physiques évidentes,
demi-sphériques, et seule l'élévation positive y est possible. Ces dômes
peuvent prendre des formes diverses et variées, avec plusieurs couronnes
d'enceintes en hauteur.

Les derniers systèmes, et également les plus rares, sont les systèmes
proposant trois axes de liberté. On a donc un \textbf{maillage}
d'enceinte ponctuant l'espace et permettant ainsi de créer des effets de
profondeurs, non pas par des moyens perceptifs (rapport de volume,
réverbération, etc.), mais pas des moyens physiques (enceinte réellement
présente au point de diffusion).

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Astuce}]

Afin de simplifier le vocabulaire, on admettra que «~surround~» est
synonyme de systèmes d'enceintes englobant à une dimension, et, que
«~immersive~» et «~3D~» son synonyme de système englobant à deux
dimensions.

\end{tcolorbox}

\hypertarget{une-simple-analogie-image-son}{%
\section{Une simple analogie
image-son}\label{une-simple-analogie-image-son}}

La notion d'échantillonnage d'un signal se retrouve dans de multiples
disciplines, notamment celles de l'image et de la vidéo. Par exemple,
une image diffusée sur un écran est spatialement échantillonnée. Un peu
comme les peintres impressionnistes qui créaient l'illusion d'une image
unie à partie de touche de pinceau distincte, on retrouve ici un
principe parfaitement analogue. Une image numérique est donc cadre d'un
certain nombre de points, et chacun de ces points s'appelle un pixel.
C'est le plus petit grain d'une image. Si l'on utilise trop peu de
pixels pour décrire une image, ceux-ci deviennent plus gros, et l'on
distingue alors ces pixels, et l'illusion d'une image unie est perdue.

La notion intéressante rendue évidente par le traitement de l'image est
la notion d'échantillonnage de l'espace. Dans le champ d'application du
son, cette «~résolution d'espace~» existe aussi, et est directement liée
au nombre de haut-parleurs. Plus le nombre de haut-parleurs est grand,
plus la cohérence de notre espace haut-parlant sera grande. On pourrait
alors qualifier les systèmes mono, stéréo, voir 5.1 et 7.1 de systèmes
basse résolution.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Gardons bien en tête cette idée d'échantillonnage d'espace, car c'est
exactement le sujet de l'ambisonique. La WFS reprend aussi cette
d'échantillonnage, mais l'applique au front d'onde de l'onde sonore.

\end{tcolorbox}

Si l'on prend en exemple le système stéréophonique, nous avons à notre
disposition deux enceintes, une à gauche de l'auditeur et une à sa
droite. De manière assez évidente, si nous envoyons un signal seulement
sur l'enceinte gauche, le son semblera venir de la gauche et vice-versa.
Alors, que se passe-t-il lorsque nous envoyons le même signal (amplitude
et phase identique) sur les deux enceintes~? Il se créer alors un effet
psychoacoustique qui va nous donner l'illusion que le son provient du
«~centre de gravité~» du système (barycentre serait plus juste). Ce
phénomène se nomme \textbf{centre fantôme}. Si l'on introduit un écart
de gain entre les deux enceintes, cette source fantôme se déplace vers
l'enceinte la plus forte. Il s'agit alors d'une forme d'interpolation.
On déduit ainsi des points de diffusions physiquement inexistants grâce
aux points de diffusions réels environnants.

Par rapport à notre question de résolution, plus celle d'un système est
faible, plus on peut supposer que l'espacement entre les enceintes sera
grand. Le poids mis sur cette stratégie d'interpolation est alors plus
important, jusqu'au point où l'illusion du centre fantôme cesse
d'opérer.

\hypertarget{uxe9tudes-des-systuxe8mes-normuxe9s}{%
\section{Études des systèmes
normés}\label{uxe9tudes-des-systuxe8mes-normuxe9s}}

\hypertarget{les-systuxe8mes-frontaux}{%
\subsection{Les systèmes frontaux}\label{les-systuxe8mes-frontaux}}

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/900px-1_0_channels_(mono)_label.svg.png}

}

\caption{Monophonie}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/900px-2_1_channels_(stereo_subwoofer)_label.svg.png}

}

\caption{Stereophonie}

}

\end{minipage}%

\end{figure}

La monophonie n'offre évidemment aucun axe de liberté pour à la
spatialisation. On pourra éventuellement «~tricher~» un effet de
profondeur en jouant sur le volume des sources sonores et sur le mixage
de la réverbération. Depuis la fin des années soixante, la norme de
production et d'écoute est la stéréophonie. La stéréophonie repose sur
deux enceintes, formant un triangle équilatéral avec l'auditeur. Elle
offre alors une scène sonore de 60° face à l'auditeur, et donc un
premier axe de liberté dans la spatialisation. Il semble évident que
l'on ne peut pas faire jouer un son plus à gauche que l'enceinte gauche,
et plus à droite que l'enceinte droite. Dès lors, les axes formés par
chacune des enceintes avec le point d'écoute idéal sont des frontières
infranchissables par les sons.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Astuce}]

Le transaural est une technique de spatialisation qui permet, dans une
certaine mesure, d'effacer ces frontières. Mais cela vient avec un
certain nombre d'inconvénients détaillé dans la
chapitre~\ref{sec-transaural}.

\end{tcolorbox}

Chacune des enceintes est alimentée par un signal audio dédié. On
associe alors au système de diffusion stéréophonique un mixage
stéréophonique, comptant deux canaux.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-warning-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Avertissement}]

Il ne faut pas confondre «~stéréophonie~» et «~deux canaux~». Si la
stéréophonie implique un mixage sur deux canaux, un mixage sur deux
canaux n'implique pas de la stéréophonie. Par exemple, une écoute au
casque n'est pas une écoute stéréophonique. Un mixage binaural repose
aussi sur deux canaux, mais n'est pas du tout indiqué pour une écoute
sur un système stéréophonique.

\end{tcolorbox}

Comme nous l'avons vu précédemment ( chapitre~\ref{sec-hist-spat} ), au
cinéma, le besoin d'un canal central, caché derrière l'écran, c'est très
rapidement fait sentir, principalement avec l'essor des formats
larges-écrans type Cinerama et Cinemascope. On trouve donc des systèmes
LCR, soit «~left~», «~center~», «~right~». Cependant, le support optique
de la pellicule ne permet pas d'y stocker plus de deux canaux. On
réalise alors un matriçage, permettant de réduire le mixage LCR sur deux
canaux (appelés Lt, pour «~Left total~» et Rt, pour «~Right total~»),
puis, à la diffusion du film, on opère le dématriçage vers le système
LCR. Le canal central est alors alimenté par la sommation des canaux L
et R.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le canal central est alors formé par les signaux \textbf{en phase} du
matriçage bicanal.

\end{tcolorbox}

Une telle réduction n'est pas indolore sur le signal, et nuit largement
à la cohérence d'espace de la diffusion.

\hypertarget{sec-sys-surr-1L}{%
\subsection{Les systèmes englobants à une
dimension}\label{sec-sys-surr-1L}}

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/4_0_channels_(quadrophonic)(quadrophonie)_label.svg}

}

\caption{Quadriphonie}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\includegraphics{index_files/mediabag/900px-4_1channel.svg.png}

}

\end{minipage}%

\end{figure}

La quadriphonie est le premier système de ce type marquant, apparu dans
les années soixante-dix. On place alors les quatre enceintes en carré et
l'auditeur au centre. On notera ainsi que les angles enceintes-auditeur
sont de 90°, soit 30° de plus que la stéréophonie. Nous pouvons déduire
que l'on gagne globalement en couverture spatiale, mais l'on perd en
précision sur les sources fantômes.

Son homologue dans le monde du cinéma est le LCRS, composé de trois
enceintes frontales (gauche, centre, droit) et d'une enceinte arrière.
La position exact des enceintes en cinéma est toujours un sujet délicat.
On considère généralement que les enceintes gauche et droite forme une
stéréophonie (plus ou moins 30°) auxquelles ont rajoute une enceinte
centrale et une enceinte arrière (respectivement 0° et 180°). Cependant,
la diffusion cinématographique n'est pas vraiment tournée vers un point
précis. En effet, il convient de convenablement couvrir l'ensemble des
spectateurs de la salle. Alors, dans les auditoriums de mixage ainsi que
dans les salles, cette preservation d'angles est somme toute assez
relative.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Astuce}]

Le système LCRS est un système historique et n'est plus du tout utilisé
aujourd'hui. La quadriphonie quand à elle continue d'avoir une certaine
popularité. On peut y avoir deux phénomènes : une nostalgie toujours
plus présente pour le ``vintage'', mais aussi une certaine facilité de
prise en main pour les artistes. Il est en effet assez facile
d'expliquer la quadriphonie comme quatre espace stéréophoniques (même si
ce n'est pas rigoureusement exact).

\end{tcolorbox}

C'est grâce à la transition du son analogique vers le son numérique que
l'on voit apparaître de nouveaux systèmes de diffusions englobants.
Toujours dans le cinéma, le premier et le plus connu est le système~5.1,
défendu par Dolby et par DTS.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/900px-5_1_channels_(surround_sound)_label.svg.png}

}

\caption{5.1}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{index_files/mediabag/900px-7_1_channels_surround_sound.svg.png}

}

\caption{7.1}

}

\end{minipage}%

\end{figure}

Il s'agit au final d'une simple extension du système LCRS, que l'on va
augmenter d'un canal de LFE distinct et d'un canal arrière
supplémentaire. Alors, le terme arrière est un peu exagéré, car ces
enceintes sont placées à plus ou moins 110~degrés de l'enceinte
centrale. On a donc plutôt un placement latéral, légèrement décalé vers
l'arrière. On notera aussi l'écart important entre les canaux latéraux
avant et ces canaux arrière, grand de 80°. Pire, les enceintes arrières
sont séparées d'un angle de 140°. Il est donc délicat d'envisager un
placement de sources fantôme à l'arrière de l'auditeur. Aussi, il est
plus sage de considérer, lors d'un mixage, qu'un système~5.1 n'offre
qu'une scène sonore que de 220°.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le système quadriphonique est quelque part plus homogène et couvre un
espace plus grand que le système~5.1. Par contre, sa définition et sa
précision sont moindres sur l'espace frontal.

\end{tcolorbox}

Le système~5.1 est défini dans la recommandation de l'ITU (International
Union Broadcast)
n°~\href{https://www.itu.int/rec/R-REC-BS.775/}{BS.775-1}. On note
d'ailleurs que le placement des enceintes possède une marge de
tolérance, celles-ci pouvant être placées entre plus ou moins 100°
jusqu'à plus ou moins 120° du centre.

Cette recommandation de l'ITU propose également un ordonnancement des
canaux. En effet, ce sujet n'est pas normé, et donne lieu parfois à
certaines erreurs de rendus. L'ITU propose alors de ranger les canaux
dans l'ordre suivant~: gauche, droit, centre, LFE, arrière gauche,
arrière droit. Cependant, Pro Tools, logiciel de mixage et montage son
le plus répandu dans le monde professionnel, adopte l'agencement
suivant~: gauche, centre, droit, arrière gauche, arrière droit, LFE. Il
convient alors d'être excessivement vigilant quant à la diffusion d'un
contenu~5.1, et de bien vérifier le bon routage de chaque canal.

Le format marquant suivant est le 7.1~Dolby Surround. On conserve alors
le 5.1 que nous avons déjà décrit et y rajoutons deux enceintes,
véritable arrière gauche et arrière droit. Il s'est principalement
imposé en salle de cinéma.

\begin{figure}

{\centering \includegraphics{index_files/mediabag/900px-8_0_channels_surround_sound.svg.png}

}

\caption{Octophonie}

\end{figure}

Nous pouvons également évoquer un système supplémentaire, l'octophonie,
mais qui n'a pas eu de réelle exploitation commerciale. En d'autres
termes, son utilisation s'est bornée à l'exploitation lors de spectacles
vivants, sans intégrer la problématique du stockage, du transport et de
la restitution antérieure du programme. Il s'agit cependant de systèmes
relativement classiques.

L'octophonie est un nom que l'on rencontre assez fréquemment. Cependant,
son nom est souvent rattaché à deux systèmes différents. Dans ce livre,
nous appellerons «~octophonie~» un système de haut-parleurs
régulièrement positionnés sur un cercle. Les enceintes sont alors toutes
espacées de 45°. On peut voir ce système comme une augmentation de la
résolution de la quadriphonie. Cette octophonie offre deux avantages~:
sa couverture est homogène et sa densité satisfaisante.

L'autre système associé à l'octophonie est le cube, que nous aborderons
dans la section suivante.

\hypertarget{les-systuxe8mes-englobants-uxe0-deux-dimensions}{%
\subsection{Les systèmes englobants à deux
dimensions}\label{les-systuxe8mes-englobants-uxe0-deux-dimensions}}

Avant de nous attarder sur un autre (encore) format de spatialisation de
Dolby, nous pouvons faire un détour par le Japon. La société NHK (Nippon
Hōsō Kyōkai, ou compagnie de télédiffusion japonaise) fait partie du
réseau de télédiffusion publique japonaise. Celle-ci possède une branche
dédiée à la recherche nommée «~NHK Science \& Technology Research
Laboratories~». Ils ont alors proposé un nouveau format de son
«~surround~»~: le 22.2.

Ce système propose trois niveaux d'élévation~: un au sol, un à hauteur
d'oreille, et un dernier positionné en hauteur. On y ajoute également
une enceinte dite de «~voice of god~», placée au-dessus de la tête de
l'auditeur.

\begin{itemize}
\tightlist
\item
  Le niveau inférieur est constitué de trois haut-parleurs frontaux
\item
  Le niveau moyen est composé de dix haut-parleurs. On pourra alors le
  décomposer comme une octophonie (une enceinte tous les 45°), plus deux
  enceintes supplémentaires sur la scène frontale.
\item
  Le niveau supérieur comporte huit haut-parleurs, disposés comme une
  octophonie, plus une enceinte juste au-dessus de l'auditeur.
\end{itemize}

Ce dispositif offre une couverture relativement homogène de l'espace et
surtout plus dense que la plupart de ces concurrents. Malheureusement,
hors du Japon, ce système n'est pas du tout répandu.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

A consulter,
\href{https://www.nhk.or.jp/strl/publica/bt/en/fe0045-6.pdf}{le document
de NHK sur son 22.2}.

\end{tcolorbox}

Revenons aussi sur nos questions d'octophonie. Cette appelation est
parfois utilisée pour parler d'un système de haut-parleur cube composé
de deux plans~:

\begin{itemize}
\tightlist
\item
  une quadriphonie au sol
\item
  une quadriphonie en élévation
\end{itemize}

On couvre ainsi une sphère complète, mais avec une résolution plutôt
faible. On met ici beaucoup de pression sur l'effet de source fantôme.

Nous pouvons aussi aborder les systèmes définis algorithmiquement. On
indique alors un nombre de haut-parleurs souhaités, et l'on obtient un
arrangement de points dans l'espace positionnés homogènement.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-caution-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Mise en garde}]

Si le placement de point de façon homogène sur un cercle paraît être une
tâche triviale, ce n'est pas du tout le cas pour une sphère.

\end{tcolorbox}

Retenons deux lois de répartitions importantes~:

\begin{itemize}
\tightlist
\item
  Le maillage
  \href{http://neilsloane.com/sphdesigns/index.html}{t-design}
\item
  Le maillage de
  \href{https://en.wikipedia.org/wiki/Lebedev_quadrature}{Lebedev}
\end{itemize}

Nous reviendrons plus particulièrement sur ces maillages lors de leurs
utilisations dans le cadre de l'ambisonique. En dehors de ce cas, ces
lois peuvent être utilisées dans la construction de dômes où de sphères
de haut-parleurs.

Enfin, nous avons donc les arrangements de haut-parleurs associés au
Dolby Atmos. Le plus commun est le 7.1.4, reprenant un 7.1 Dolby et y
rajoutant une quadriphonie en élévation. Une première réduction consiste
à réduire la couche d'élévation à deux canaux (7.1.2). On trouve
également les 5.1.4 et 5.1.2, reprenant la même logique.

Plus intéressant, le Dolby Atmos propose aussi un format~9.1.6, qui
apporte enfin une homogénéité correcte, au moins sur le plan principal.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-warning-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Avertissement}]

Les techniques de mixage entourant le Dolby Atmos sont très différentes
des techniques classiques, reposant sur des lois de panoramiques. Le
Dolby Atmos est avant tout un format de mixage orienté objet. Nous
abordons cet aspect dans le chapitre~\ref{sec-mix-obj}.

\end{tcolorbox}

Si Dolby possède aujourd'hui la force de frappe la plus importante, on
trouve tout de même quelques acteurs pour tenter de lui faire
concurrence. DTS propose son propre format de mixage orienté objet,
nommé DTS:X. Les systèmes de diffusion sont cependant calqués sur ceux
de Dolby. On retrouve aussi Auro~3D, également avec son propre format de
mixage orienté objet. Compatible avec les systèmes Dolby Atmos, on
retrouve aussi le 13.1 (7.1.4, plus une enceinte centrale sur le plan
d'élévation et une ``voice of god'') et 11.1 (5.1.4, plus une enceinte
centrale sur le plan d'élévation et une ``voice of god'').

\hypertarget{le-binaural}{%
\chapter{Le binaural}\label{le-binaural}}

\href{https://en.wikipedia.org/wiki/Binaural_recording}{Binaural
recording}

\href{https://en.wikipedia.org/wiki/Binaural_recording\#/media/File:FrequenzgangDruckempfänger.svg}{Binaural
recording DPA}

\hypertarget{la-prise-de-son-binaurale}{%
\section{La prise de son binaurale}\label{la-prise-de-son-binaurale}}

\hypertarget{sec-binaural-synthese}{%
\section{La synthèse binaurale}\label{sec-binaural-synthese}}

\hypertarget{sec-transaural}{%
\section{Le transaural}\label{sec-transaural}}

\hypertarget{orientuxe9-canal}{%
\chapter{Orienté canal}\label{orientuxe9-canal}}

\hypertarget{lapproche-perceptive}{%
\section{L'approche perceptive}\label{lapproche-perceptive}}

\hypertarget{sec-vbap}{%
\subsection{le VBAP}\label{sec-vbap}}

\hypertarget{le-vbip}{%
\subsection{Le VBIP}\label{le-vbip}}

\hypertarget{sec-lbap}{%
\subsection{Le LBAP}\label{sec-lbap}}

\hypertarget{autres-variantes}{%
\subsection{Autres variantes}\label{autres-variantes}}

\hypertarget{lapproche-matricielle}{%
\section{L'approche matricielle}\label{lapproche-matricielle}}

\hypertarget{le-dbap}{%
\subsection{Le DBAP}\label{le-dbap}}

\hypertarget{le-knn}{%
\subsection{Le KNN}\label{le-knn}}

\hypertarget{lambisonique}{%
\chapter{L'ambisonique}\label{lambisonique}}

\hypertarget{HOA-decode-allrad}{%
\section{Décodeurs}\label{HOA-decode-allrad}}

\hypertarget{mixage-orientuxe9-objet}{%
\chapter{Mixage orienté objet}\label{mixage-orientuxe9-objet}}

Par définition, un mixage son consiste à mélanger un certain nombre de
canaux d'entrés vers un nombre de canaux de sorties plus faible. Le
mixeur a pour rôle de réaliser et de maîtriser cette sommation.

Lors d'un mixage orienté objet, la méthode de travail est alors assez
différente. Pour chaque canal d'entrée, nous allons y associer des
\textbf{métadonnées} de mixage, par exemple son gain ou sa position dans
l'espace.

Une fois cette association faite entre audio et métadonnées de mixage,
on utilise un décodeur qui va, par lecture des métadonnées, adapter ces
informations en fonction du système de haut-parleurs qui lui est
affecté. Le mixage, c'est-à-dire la sommation des canaux, est alors
réellement fait à l'étape de décodage. Quelque part, le mixeur réalise
ici un ``non-mixage''.

L'avantage principal du mixage orienté objet est donc de pouvoir
produire différents formats d'écoutes à partir du même mixage (en
théorie). On pourrait alors à partir des mêmes métadonnées produire un
rendu pour un système stéréophonique, 5.1 et 9.1.6 (ou pourquoi pas, en
ambisonique 22e ordre !).

Même si le mixage orienté objet n'implique pas un mixage spatialisé,
cette technique de production est souvent employée dans ce contexte pour
tenter de simplifier les problématiques de format multiple. Par exemple,
on pourra travailler sur un mixage immersif, et pouvoir du même coup
obtenir un mixage stéréophonique. On réalise alors un gain de temps
évident par rapport à la méthode traditionnelle qui consiste à réaliser
``n'' mixages si l'on doit produire ``n'' formats de sorties.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-warning-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Avertissement}]

Cette facilité de création de rendus différents n'épargne cependant pas
les comportements parfois surprenants d'un mixage d'un système à un
autre. Par exemple, un mixage réalisé sur une écoute quadriphonique
risque d'être surprenant lors de son passage sur un arrangement 5.1. Il
est généralement sage de travailler sur le système le plus grand que
l'on souhaite cibler et de contrôler les ``downmix''. L'inverse peut
amener à certaines surprises.

\end{tcolorbox}

Plusieurs fabricants proposent des formats et des outils de mixage
orienté objet. En tête, on retrouve Dolby et son Dolby Atmos, possédant
au jour d'aujourd'hui la plus grande part de marché (intégration native
dans Pro Tools et Logic Pro). DTS et Auro 3D proposent également leurs
propres outils. Enfin, Freinhaufer a défini le codec MPEG-H,
implémentant l'Audio Definition Model comme base de métadonnées. L'ADM
étant un format ouvert nous servira donc à décortiquer le fonctionnement
de l'encodage et le décodage d'un mixage orienté objet.

\hypertarget{laudio-definition-model}{%
\section{L'Audio Definition Model}\label{laudio-definition-model}}

\hypertarget{pruxe9sentation}{%
\subsection{Présentation}\label{pruxe9sentation}}

L'\href{https://www.itu.int/rec/R-REC-BS.2076-2-201910-I/en}{Audio
Definition Model} est une autre recommandation de l'ITU, dont la
dernière édition date de 2019. Ce papier concentre beaucoup
d'informations importantes. Principalement, il s'agit de décrire une
base commune, espérant devenir une base commune entre les différents
acteurs de l'audio orienté objet. Le premier objectif est donc d'assurer
l'interopérabilité entre les différentes solutions de mixage orienté
objet.

Techniquement, l'ADM est donc un catalogue de descripteurs d'audio. Pour
chaque canal audio, un certain nombre d'informations textuelles y sont
associées. Elles sont donc \textbf{lisibles} par un être humain, et
\textbf{éditables}.

\hypertarget{description-des-muxe9tadonnuxe9es}{%
\subsection{Description des
métadonnées}\label{description-des-muxe9tadonnuxe9es}}

L'ADM permet la représentation de quatre ``types'' d'audio :

\begin{itemize}
\tightlist
\item
  Le \emph{channel-based} ou orienté-canal
\item
  L'\emph{HOA} ou Ambisonie d'ordre plus élevé
\item
  Les \emph{Matrix} ou formats matricés
\item
  Les objets
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-warning-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Avertissement}]

Le mot ``objet'' a deux sens dans la documentation de l'ADM. Un objet
est un format, permettant le rendu dynamique d'un élément sonore
(changement de position, de volume, etc.). Cependant, un objet est
également un contenu, qui permet de référencer un bloc d'échantillons
d'un canal audio.

En ce sens un objet audio en ADM peut représenter le canal d'un flux
orienté objet, le canal d'un flux HOA, un élément d'une matrice ou un
objet sonore !

\end{tcolorbox}

\begin{figure}

{\centering \includegraphics{spatialisation/../_resources/bitmap/adm/admStruct.png}

}

\caption{\label{fig-adm-struct}Organigramme de l'ADM}

\end{figure}

L'ADM permet de définir plusieurs programmes, appelés
``\emph{audioProgramme}''. Prenons comme exemple le cas d'une série
télévisée diffusée en France et en Grande-Bretagne. Nous aurions, dans
ce cas, un premier \emph{audioProgramme} contenant les voix françaises
et le reste de la bande-son, puis ,un second contenant les voix
anglaises et le reste de la bande-son. Nous aurions alors trois
\textbf{contenus audio} (appelés \emph{audioContent}) : les voix
anglaises, les voix françaises et le reste de la bande-son (bruitages,
montage son, musique, etc.). L'\emph{audioProgramme} ``version
anglaise'' contiendrait le \emph{audioContent} voix anglaise et le reste
de la bande son, celui ``version française'' contiendrait les
\emph{audioContent} voix française et le reste de la bande son. Ainsi,
le spectateur peut choisir d'écouter l'\emph{audioProgramme} qu'il
préfère, de façon interactive.

Chacun de ces \emph{audioContent} contiennent eux-même des objets,
appelés \emph{audioObject}. Dans notre exemple, nous aurions différents
objets dans l'\emph{audioContent} voix française correspondant aux
différents comédiennes et comédiens. Ces \emph{audioObject} permettent
d'indiquer quels échantillons audio du fichier BW64 sont concernés. Il
convient alors d'indiquer quel est le format audio de ces échantillons.
Les \emph{audioObject} pointent vers un \emph{audioPack} qui lui même
pointe vers un certain nombre de sous modules permettant de caractériser
intégralement le format audio et \textbf{où il doit être positionné}
dans l'espace.

Si l'\emph{audioObject} est de type ``directSpeaker'', on l'affecte à un
haut-parleur, dont on renseigne une position fixe. Si ce haut-parleur
existe dans l'arrangement de haut-parleurs connecté au décodeur ADM, le
signal y est routé, sinon on interpole avec les haut-parleurs les plus
proches.

Si l'\emph{audioObject} est de type ambisonique, on cherche les autres
objets appartenant au même flux, puis on décode l'ensemble, sur le
système connecté au décodeur ADM.

Si l'\emph{audioObject} est la composante d'une matrice, on cherche les
autres objets appartenant au même flux, puis on dématrice l'ensemble
vers nouvel \emph{audioPack} de type ``directSpeaker''.

Si l'\emph{audioObject} est de type ``object'', on regarde ses
\textbf{métadonnées de spatialisation} puis on interpole cette position
en utilisant les haut-parleurs les plus proches du point indiqué.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Astuce}]

Gardons en tête que les \emph{audioObject} ``directSpeaker'' ou
ambisonique sont des \textbf{mixages}. Les scènes sonores qu'ils
représentent sont statiques et immuables. Un \emph{audioObject} de
format objet contient un élément sonore (une voix, un instrument, un
bruitage), que le décodeur ADM va ensuite mixer. Un objet peut donc être
interactif. L'utilisateur pourrait changer son volume, sa position, etc.

\end{tcolorbox}

\hypertarget{les-muxe9tadonnuxe9es-de-spatialisation}{%
\subsection{Les métadonnées de
spatialisation}\label{les-muxe9tadonnuxe9es-de-spatialisation}}

L'ADM n'intègre qu'un jeu de paramètre très sommaire :

\begin{itemize}
\tightlist
\item
  Le niveau
\item
  La position (en coordonnées cartésiennes et sphériques)
\item
  La taille et diffusion de la source
\end{itemize}

Le niveau est un simple réglage de gain. La position permet de placer
l'objet dans un espace virtuel en trois dimensions et selon deux
systèmes de coordonnées. On préfère généralement le système sphérique,
plus proche de notre perception sonore, cependant, la description de
certains mouvements est plus simple dans un repère plutôt qu'un autre.
Le paramètre de distance permet de placer une source \textbf{entre les
haut-parleurs et le point d'écoute idéal}.

La largeur permet de jouer sur l'étalement de l'objet dans l'espace. En
pratique, accroître ce paramètre augmente le nombre de haut-parleurs
contribuant à la diffusion de l'objet sonore. Associé à la taille, le
paramètre de diffusion permet d'ajouter de la décorrélation sur les
haut-parleurs contribuant à la largeur de restitution de la source.

Il n'y a donc pas de descripteurs perceptifs ou d'espaces. L'approche de
la spatialisation y est donc très basique, voire simpliste. Comme nous
le verrons dans les sections plus pratiques, cela impose des techniques
de mixage relativement complexes à fin de contourner ses limitations.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Malheureusement la plupart des moteurs de mixage orienté objet souffrent
de ces mêmes lacunes, y compris le Dolby Atmos. L'exception principale
est l'IRCAM Spat ainsi que le Spat Revolution de FLUX:: Immersive.

\end{tcolorbox}

\hypertarget{inscription-des-muxe9tadonnuxe9es-dans-un-fichier-audio}{%
\subsection{Inscription des métadonnées dans un fichier
audio}\label{inscription-des-muxe9tadonnuxe9es-dans-un-fichier-audio}}

L'ADM décrit la possibilité d'inscrire les métadonnées de mixage
directement dans un fichier audio, contenant lui-même l'ensemble des
données audio nécessaires. Dans le cadre d'un mixage orienté objet, ce
fichier audio peut posséder autant de canaux que d'objets déclarés. Le
format retenu pour les stockages de ces informations est le
\textbf{BW64} (Broadcast Wavefile 64 bit).

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Le \href{https://www.itu.int/rec/R-REC-BS.2088-1-201910-I/en}{BW64} est
une extension du format
\href{https://www.itu.int/rec/R-REC-BS.1352-3-200712-I/en}{BWF}. Tous
deux sont également définis dans des recommandations de l'ITU. Ces
fichiers prennent la forme de simples fichiers ``wave''
(monfichier.wav).

Également, on parle d'un en-tête de fichier, pour qualifier l'ensemble
des métadonnées (nom, type de fichier, conteneur, etc.) précèdent la
donnée utile (ici, les échantillons audio). Attention, les métadonnées
ne sont pas toutes relatives à l'ADM. La plupart les fichiers possèdent
des métadonnées pour indiquer aux programmes comment exploiter les
données qu'ils stockent.

\end{tcolorbox}

\begin{figure}

\begin{minipage}[b]{0.35\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{spatialisation/../_resources/bitmap/adm/basicWave.png}

}

\caption{\label{fig-wavefile}Structure d'un fichier wave}

}

\end{minipage}%
%
\begin{minipage}[b]{0.65\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{spatialisation/../_resources/bitmap/adm/bw64.png}

}

\caption{\label{fig-bw64}Structure d'un fichier bw64}

}

\end{minipage}%
\newline
\begin{minipage}[b]{\linewidth}

{\centering 

Illustations extraites du document BS.2088-2 de l'ITU

}

\end{minipage}%

\end{figure}

La figure Figure~\ref{fig-bw64} fait mention de plusieurs ``chunk''
(section, bloc) nommé ``\emph{axml}'', ``\emph{bxml}'', ``\emph{sxml}'',
``\emph{chna}''. La globalité des informations est stockée sous la forme
d'un
\href{https://fr.wikipedia.org/wiki/Extensible_Markup_Language}{XML}
dans les \emph{chunks} ``axml'', ``bxml'' ou ``sxml''. Le \emph{chunk}
``chna'' stocke les informations permettant de faire les liens entre les
données audio et leur description dans l'ADM. Il est en général
recommandé d'utiliser le \emph{chunk} ``axml'' (le ``bxml'' est alors
plutôt utilisé pour les surcouches à l'ADM, aussi appelés profiles).

\hypertarget{les-profils-adm}{%
\section{Les profils ADM}\label{les-profils-adm}}

Certains constructeurs ont choisis de proposer des sur-spécification à
l'ADM, aussi appelés ``profils''. Ces profils ont généralement deux buts
:

\begin{itemize}
\tightlist
\item
  Rajouter des métadonnées spécifiques à l'utilisation de codec audio
  propriétaire.
\item
  Limite les spécifications de l'ADM pour correspondre aux usages de
  certains domaines
\end{itemize}

Les deux principaux profils connus sont ceux du
\href{https://www.iis.fraunhofer.de/en/ff/amm/dl/whitepapers/adm-profile.html}{MPEG-H
de Fraunhofer} et de
\href{https://professionalsupport.dolby.com/s/article/Dolby-Atmos-ADM-Profile-specification?language=en_US}{Dolby}

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-important-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Important}]

Aucun des deux constructeurs n'ont choisit de maintenir le support de
l'ambisonique dans leur format.

De plus, il n'existe à ce jour, aucun outil pour convertir un ADM d'un
profil quelquonque vers un ADM Dolby. La compatibilité des formats n'est
donc pas assurée.

\end{tcolorbox}

\#\#~L'ADM Sériel (S-ADM)

Pour certaines applications, comme le live ou le streaming, la
description des métadonnées sous forme d'un dictionnaire XML n'est pas
adéquate. Ici, les flux audio sont en temps réel et ne dépendent pas
nécessairement d'un fichier audio. Il existe donc une norme sérielle de
l'ADM, permettant de transmettre les métadonnées dans une connexion
numérique, type AES, MADI ou encore à travers de l'audio sur IP.

La description du S-ADM est disponible dans
l'\href{https://www.itu.int/rec/R-REC-BS.2125/en}{ITU-R BS.2125}.

\hypertarget{ladm-osc}{%
\section{L'ADM OSC}\label{ladm-osc}}

L'ADM OSC est une initiative menée par FLUX:: Immersive, L-Acoustic et
Radio France pour proposer une base de communication commune entre les
différents moteurs de mixage orienté objet dans le monde du Live. Cela
assure donc une interopérabilité minimale entre les principaux acteurs
du milieu. À ce jour, les acteurs suivants se sont joints à la
conversation : d\&b Audiotechnik, DiGiCo, Dolby, Lawo, Magix, Merging
Technologies, Meyer Sound, Steinberg.

Les logiciels implémentant l'ADM OSC comptent SPAT Revolution
(FLUX::SE), L-ISA Controller (L-Acoustics), Ovation (Merging
Technologies), Nuendo (Steinberg), SpaceMap Go (Meyer Sound), QLAB 5
(Figure 53), Space Controller (Sound Particles), Modulo Kinetic (Modulo
Pi), Iosono (Barco).

Le code source de ce projet, développé sous une licence open source, est
disponible dans ce répository
\href{https://github.com/immersive-audio-live/ADM-OSC}{github}

\hypertarget{luxe9tape-de-rendue}{%
\section{L'étape de rendue}\label{luxe9tape-de-rendue}}

Tout ce que nous avons vu pour l'instant, au sujet de l'ADM, ne concerne
au final que la description d'un mixage, et nous n'avons pour l'instant
pas envisagé le ``comment''. En d'autres termes, nous avons une liste
d'ingrédients, mais ne savons pas comment les mélanger et les cuisiner
entre eux.

Il existe une
\href{https://www.itu.int/rec/r-rec-bs.2127/en}{recommandation de l'ITU
(BS-2127)} consacrée au sujet du ``renderer'', ou processeur de rendu.
On fournit donc audio et métadonnées à ce moteur de rendu, qui, grâce à
l'analyse de ces métadonnées et au système de haut-parleurs qui lui est
connecté, peut calculer le gain de reproduction de chaque source et
chaque haut-parleur.

\hypertarget{description-de-la-loi-de-panoramique}{%
\subsection{Description de la loi de
panoramique}\label{description-de-la-loi-de-panoramique}}

La loi de panoramique recommandée par l'ITU BS-2127 empreinte beaucoup
au \textbf{LBAP} (voir la section~\ref{sec-lbap}). Nous sommes donc sur
une loi de panoramique favorisant un point d'écoute idéal, situé à égale
distance des haut-parleurs.

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Ici, la distance ne s'exprime qu'entre les haut-parleurs et le point
d'écoute idéal. En d'autres termes, la distance maximale correspond au
plan des haut-parleurs, la distance minimale correspond au point
d'écoute idéale. La distance ne contribue pas au gain de la source, mais
plutôt à une sorte de spreading.

\end{tcolorbox}

L'algorithme se décrit de la façon suivante :

\begin{itemize}
\tightlist
\item
  On recherche les couches (en élévation) de haut-parleurs au-dessus et
  en dessous de la source. On calcule alors le gain \(z\) en interpolant
  entre les deux couches.
\item
  Sur chaque couche trouvée, on recherche les deux lignes de
  haut-parleurs en avant et en arrière de la source. On calcule ainsi le
  gain \(y\) en interpolant entre les deux lignes.
\item
  Enfin, sur chaque ligne trouvée, on recherche la paire de
  haut-parleurs à gauche et à droit de la source, permettant finalement
  de calculer le gain \(x\) entre les deux haut-parleurs.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, leftrule=.75mm, arc=.35mm, bottomtitle=1mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacityback=0, left=2mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, toptitle=1mm, titlerule=0mm, bottomrule=.15mm, toprule=.15mm, coltitle=black, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}]

Si une source est positionnée sur un haut-parleur, alors seul celui-ci
contribue à la diffusion sonore.

\end{tcolorbox}

\hypertarget{largeur-et-duxe9corruxe9lation}{%
\subsection{Largeur et
décorrélation}\label{largeur-et-duxe9corruxe9lation}}

Le paramètre de ``size'' ou taille permet de faire paraître une source
plus grande en augmentant le nombre de haut-parleurs contribuant à la
diffusion de la source. Ce paramètre ``size'' est enfaîte un
macro-paramètre qui manipule trois autres paramètres:

\begin{itemize}
\tightlist
\item
  La largeur (étalement horizontal)
\item
  La hauteur (étalement vertical)
\item
  La profondeur (étalement dans la profondeur)
\end{itemize}

Par principe de source fantôme, augmenter le nombre de haut-parleurs
contribuant à la diffusion d'une source n'augmente pas véritablement sa
taille apparente dans notre perception de la scène sonore. La source
vient plutôt se positionner au
\href{https://fr.wikipedia.org/wiki/Barycentre}{barycentre} des
haut-parleurs, pondéré par leur énergie de diffusion. Pour réellement
créer un effet de ``taille'', il est nécessaire d'introduire une
différence suffisamment importante pour que notre oreille ait l'illusion
d'un étalement dans l'espace. Cette différence doit également être
suffisamment faible pour ne pas déformer le signal d'origine. On appelle
cela la décorrélation. L'ITU recommande ici l'utilisation de filtres
passe-tout sur chaque canal de diffusions.

\hypertarget{duxe9codage-ambisonique}{%
\subsection{Décodage ambisonique}\label{duxe9codage-ambisonique}}

L'ITU décrit l'utilisation d'un décodage AllRAD. Voir la (section
\textbf{HOA-decode-allrad?})

\hypertarget{sec-wfs}{%
\chapter{La synthèse de fronts d'ondes (WFS)}\label{sec-wfs}}

\part{Les outils de spatialisation sonore}

\hypertarget{choisir-une-station-de-travail}{%
\chapter{Choisir une station de
travail}\label{choisir-une-station-de-travail}}

\hypertarget{panner-binaural}{%
\chapter{Panner binaural}\label{panner-binaural}}

\hypertarget{panner-orientuxe9-canaux}{%
\chapter{Panner orienté canaux}\label{panner-orientuxe9-canaux}}

\hypertarget{panner-ambisonique}{%
\chapter{Panner ambisonique}\label{panner-ambisonique}}

\hypertarget{gestion-des-effets}{%
\chapter{Gestion des effets}\label{gestion-des-effets}}

\hypertarget{sec-mix-obj}{%
\chapter{Le mixage orienté objet}\label{sec-mix-obj}}

\hypertarget{mpeg-h-et-adm}{%
\section{MPEG-H et ADM}\label{mpeg-h-et-adm}}

\hypertarget{dolby-atmos}{%
\section{Dolby Atmos}\label{dolby-atmos}}

\hypertarget{ircam-spat}{%
\section{IRCAM Spat}\label{ircam-spat}}

\hypertarget{flux-spat-revolution}{%
\section{FLUX:: Spat Revolution}\label{flux-spat-revolution}}



\end{document}
