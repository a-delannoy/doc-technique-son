# L'ambisonique

![Dôme ambisonique du Théâtre de Gennevilliers](https://www.journal-laterrasse.fr/wp-content/uploads/2022/05/sousledomeambisonique.jpg)

L'ambisonique (ou ambisonie), s'attache à décrire le champ acoustique en trois dimensions d'un espace donné en un point. C'est à la fois une technique de prise de son, grâce à l'utilisation de microphones particuliers et une solution de panning en post-production. De part son indépendance par rapport au dispositif du système de diffusion, on qualifie parfois un mixage ambisonique de *mixage orienté scène*. En effet, un signal ambisonique décrit, à l'aide de canaux audio, une scène sonore, et non pas un certain arrangement de haut-parleur (par opposition à l'orienté canal).

L'ambisonie se distingue également des approches plus conventionnelles (approche perceptives du panning usuel) par son approche **physique**. Nous verrons que dans son fonctionnement, l'ambisonie réalise l'**échantillonnage du champ de pression acoustique**. Cet échantillonnage peut varier en précision en fonction de l'**ordre** auquel nous souhaitons travailler.

Nous commencerons par étudier l'ambisonie dit du "premier ordre", tel que proposé par Michael Gerzon et son équipe dans les années soixante-dix. Seulement ensuite, nous questionnerons l'ambisonie d'ordre plus élevé, apparut au début des années 2000.

## L'ambisonie du premier ordre (FOA)

### Captation du champs sonore

L'ambisonie du premier ordre (ou FOA pour First Order Ambisonic) voit le jour sous la forme d'une technique de prise de son. Celle-ci permet l'enregistrement d'un scène sonore sur **quatres canaux**, que l'on peut ensuite décoder sur n'importe quel système de haut-parleurs.

Pour capturer le champ acoustique en un point, il faut donc s'intéresser au champ acoustique lui-même. Nous l'avons vu à la @sec-le-son-physique, sous sa forme acoustique, une onde sonore se caractérise par la variation locale dans le temps de la pression. Pour mesurer la pression en un point, nous pouvons utiliser un microphone omnidirectionnel (également appelé microphone à pression). Ce microphone omnidirectionnel va donc rendre compte a chaque instant du temps de la valeur de la pression. A ce stade, il n'est pas question de parler de spatialisation, la capatation d'une tel capsule étant monophonique.

Il conviendrait donc de mesurer la "direction" du déplacement local des particules d'air. Quelque part, on se demande dans **quel sens et quelle direction varie la pression**. Pour cela, on cherche à mesurer la vitesse de ce déplacement, et donc la variation de la pression en un point. Pour se faire, on utilise un microphone bidirectionnel (aussi appelé à gradient de pression). Ce microphone va donc mesurer, à chaque un instant du temps, la différence entre la pression entre un point de l'espace et un autre très rapproché. On caractérise donc une **variation dans l'espace**.

<!-- :::{.callout-tip}

Quelques mots sur le formalisme mathématique. Soit $p(t,\vec{r})$, le champ de pression, $v(t,\vec{r})$ sa vitesse et $s(t,\vec{r})$, une onde sonore. Ces trois fonctions dépendent du **temps** et de l'**espace** (représenté par le vecteur unitaire $\vec{r}$).

Lorsqu'un évènement sonore est produit, on approxime

::: -->

```{python}

#| label: fig-ms
#| fig-align: "center"
#| fig-cap: "Pression et variation de pression sur l'axe Y. Les portions rouges ont une phase positive, les portions bleues ont une phase négative."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

phi = np.arange(-np.pi,np.pi,0.01)
omni = np.full(
  shape=len(phi),
  fill_value=dbnorm(1),
  dtype=int
)

bidir = dbnorm(np.cos(phi))
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

fig, axs = plt.subplots(nrows=1, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()
axs[0].plot(phi, omni, color='red')
axs[0].set_title('Omnidirectionnel \n (M / W)')
axs[1].plot(phi, bidir_pos, color='red')
axs[1].plot(phi, bidir_neg, color='blue')
axs[1].set_title('Bidirectionnel \n (S / Y)')

for ax in axs:
    ax.set_ylim(-20,0)
    ax.set_rticks([-20, -12, -6, 0, 3])  # Less radial ticks
    ax.legend()
    ax.grid(True)

plt.show()

```

Une capsule bidirectionnelle nous permet de mesurer dans quel axe se déplace les molécules d'air (si les les molécules oscillent dans l'axe du microphone, on obtient un niveau mesurable, si les molécules oscillent sur l'axe normal (à 90°) de l'axe du microphone, on obtient un niveau négligeable). Cependant cela ne nous renseigne pas si la source sonore responsable de la perturbation se trouve plutôt devant ou derrière le microphone. Cependant, si nous associons au même point de l'espace une capsule omnidirectionnelle et une capsule bidirectionnelle, nous allons pouvoir lever cette indétermination.


```{python}

#| label: fig-m-et-s
#| fig-align: "center"
#| fig-cap: "Représentation des composantes W et Y sur le même graphique. Les portions rouges ont une phase positive, les portions bleues ont une phase négative."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

phi = np.arange(-np.pi,np.pi,0.01)
omni = np.full(
  shape=len(phi),
  fill_value=dbnorm(1),
  dtype=int
)

bidir = dbnorm(np.cos(phi))
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

fig, ax = plt.subplots(nrows=1, ncols=1,subplot_kw={'projection': 'polar'})
fig.tight_layout()
ax.plot(phi, omni, color='red')
ax.plot(phi, bidir_pos, color='red')
ax.plot(phi, bidir_neg, color='blue')
ax.plot(np.pi/8,0, markersize=20)
ax.set_title('Association de deux harmoniques sphériques \n (M et S / W et Y)')

ax.set_ylim(-20,0)
ax.set_rticks([-20, -12, -6, 0, 3])  # Less radial ticks
ax.legend()
ax.grid(True)

plt.show()

```

On constate donc que, selon l'angle d'incidence de la source par rapport aux capsules, celle subit une atténuation (et une modification de la phase si la valeur absolue de l'angle d'incidence est ici supérieur à 90°) dans le canal de captation Y, permettant donc de coder sa position autour du microphone. Le canal W capte la source de la même manière, peut importe son angle d'incidence. Nous venons ici de fabriquer un couple MS (voir @sec-pds-stereo-ms).

Notre dispositif permet ici de capter des ondes sonores selon un seul axe (ici, Y). Si l'on souhaite étendre ce dispositif pour capter l'espace en trois dimensions, nous serions naturellement tenté d'ajouter deux autres capsules bidirectionnelles supplémentaires.

```{python}

#|fig-align: 'center'
#| label: fig-foa
#| fig-cap: "Composantes ambisonique du premier ordre. Les surfaces rouges ont une phase positive, les surfaces bleues ont une phase négative."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
# The following import configures Matplotlib for 3D plotting.
from mpl_toolkits.mplot3d import Axes3D
from scipy.special import sph_harm

# Grids of polar and azimuthal angles
theta = np.linspace(0, np.pi, 300)
phi = np.linspace(0, 2*np.pi, 300)
# Create a 2-D meshgrid of (theta, phi) angles.
theta, phi = np.meshgrid(theta, phi)
# Calculate the Cartesian coordinates of each point in the mesh.
xyz = np.array([np.sin(theta) * np.sin(phi),
                np.sin(theta) * np.cos(phi),
                np.cos(theta)])

def plot_Y(ax, el, m):
    # """Plot the spherical harmonic of degree el and order m on Axes ax."""

    # NB In SciPy's sph_harm function the azimuthal coordinate, theta,
    # comes before the polar coordinate, phi.
    Y = sph_harm(abs(m), el, phi, theta)

    # Linear combination of Y_l,m and Y_l,-m to create the real form.
    if m < 0:
        Y = np.sqrt(2) * (-1)**m * Y.imag
    elif m > 0:
        Y = np.sqrt(2) * (-1)**m * Y.real
    Yx, Yy, Yz = np.abs(Y) * xyz

    # Colour the plotted surface according to the sign of Y.
    cmap = plt.cm.ScalarMappable(cmap=plt.get_cmap('bwr'))
    cmap.set_clim(-0.5, 0.5)

    ax.plot_surface(Yx, Yy, Yz,
                    facecolors=cmap.to_rgba(Y.real),
                    rstride=2, cstride=2)

    # Draw a set of x, y, z axes for reference.
    ax_lim = 0.5
    ax.plot([-ax_lim, ax_lim], [0,0], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [-ax_lim, ax_lim], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [0,0], [-ax_lim, ax_lim], c='0.5', lw=1, zorder=10)
    
    ax_lim = 0.3
    ax.set_xlim(-ax_lim, ax_lim)
    ax.set_ylim(-ax_lim, ax_lim)
    ax.set_zlim(-ax_lim, ax_lim)
    ax.axis('off')

fig = plt.figure()
order = 1
spec = gridspec.GridSpec(ncols=pow(order+1,2), nrows=1, figure=fig)
axName = ['W','Y','Z','X']
for l in range(order+1):
  for m in range(-l,l+1):
    ax = fig.add_subplot(spec[2*l+m], projection='3d')
    ax.set_title(axName[2*l+m])
    plot_Y(ax, l, m)

# TODO: ADD 2D VERSION (ALL HARMONIC ON ONE PLOT)

plt.show()

```

En pratique, les microphones ambisoniques n'utilisent pas cet arrangement de capsules. En effet, l'encombrement des capsules bidirectionnelles compromet sévèrement la coincidence du système. La qualité d'un tel microphone dépend largement de sa capacité à positionner les capsules avec la plus grande coincidence possible, au risque sinon de déterriorer la précision de localisation dans le haut du spectre. On utilise alors plutôt quatre capsules cardioïde, placé sur les surfaces d'un tétraèdre. Cet arrangement est mathématiquement strictement équivalent à l'utilisation d'une capsule omnidirectionnelle et de trois capsules bidirectionnelles. Seulement, l'encombrement moindres des capsules cardioïdes permet une meilleure coincidence de celles-ci.

![Microphone Sennheiser Ambeo](https://d2j6dbq0eux0bg.cloudfront.net/images/29143418/1438893864.jpg){width=50%}

On appelle le flux audio en sortie d'un microphone ambisonique du premier order **Format-A**, dans lequel chaque canal correspond à une capsule précise. Par opposition, on appele généralement **Format-B** un flux ambisonique du premier ordre encodé, où chaque canal correspond à une des composantes W, X, Y, Z.

:::{.callout-note}

L'appellation **Format-A** se retrouve également pour les ordres supérieurs, même si ces microphones sont rares ! Le terme **Format-B** est quant à lui, discutable pour les ordre supérieurs.

:::

### Synthèse du champs sonore

Nous avons vu qu'un microphone ambisonique nous permet de capturer l'espace acoustique entendu d'un point. Nous pouvons également "synthétiser", c'est à dire encoder une source sonore monophonique dans un espace acoustique virtuel ambisonique. Pour cela, on utilise simplement des panners ambisoniques.

Pour une incidence donnée de cette sources sonore, le panner va affecter une partie de son énergie aux différentes composantes d'un signal ambisonique (W, X, Y, Z) et une phase particulière (positive ou négative). Il est également possible d'encoder des signaux multicanaux (stéréo, quadriphonie, 5.0). Il s'agit d'une technique très efficace pour adapter un mixage réalisé sur un arrangement de haut-parleurs particuliers vers un autre.


Nous ferons état de ces différentes techniques et des différents panners ambisoniques dans le @sec-outils-ambisoniques .

### Restitution du champs sonore

Une fois le signal enregistré, ou encodé en ambisonique, il convient de le décoder sur un arrangement de haut-parleurs particulier. Cette phase de décodage est peut être la plus complexe à appréhender (et explique très certainement pourquoi l'ambisonique reste à ce jour si peu utilisée).

Illustrons le procédé de décodage en considérant un flux audio ambisonique 2D (W, X, Y) et un système de diffusion quadriphonique.

```{python}

#| label: fig-amb2D-quad
#| fig-align: "center"
#| fig-cap: "Décodage par projection basique."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

db = lambda x: 20*np.log10(np.abs(x))
dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

phi = np.arange(-np.pi,np.pi,0.01)
omniLin = np.full(shape=len(phi),fill_value=1/np.sqrt(2),dtype=float)
omni = db(omniLin)

bidirLin = np.cos(phi)
bidir = db(bidirLin)
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

bidir2Lin = np.sin(phi)
bidir2 = db(bidir2Lin)
bidir2_pos = np.ma.masked_where(phi<0, bidir2)
bidir2_neg = np.ma.masked_where(phi>=0, bidir2)

alphaSource = -np.pi/8
sourceDir = omniLin+np.cos(alphaSource)*bidirLin+np.sin(alphaSource)*bidir2Lin
sourceDir = dbnorm(sourceDir)

speakerPos = [np.pi/4, 3*np.pi/4, 5*np.pi/4, 7*np.pi/4]
speakerWeight = [4, 4, 4, 4] #in dB

fig, axs = plt.subplots(nrows=1, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()

axs[0].plot(phi, omni, color='crimson')
axs[0].plot(phi, bidir_pos, color='red')
axs[0].plot(phi, bidir_neg, color='blue')
axs[0].plot(phi, bidir2_pos, color='red')
axs[0].plot(phi, bidir2_neg, color='blue')
axs[1].plot(phi,sourceDir)
axs[0].set_title("Encodage d'une source virtuelle\nen ambisonie d'ordre 1, 2D")
axs[1].set_title("Directivité résultante")

for ax in axs:
  ax.plot(speakerPos, speakerWeight, "D", ms=20, color='black')
  ax.plot(alphaSource, 0, "o", ms=10, color='purple', label='Source virtuelle')
  ax.set_ylim(-20,0)
  ax.set_rticks([-20, -12, -6, 0, 6])  # Less radial ticks
  ax.legend()
  ax.grid(True)

plt.show()


```

La figure ci-dessus représente une approche de décodage par projection dite basique.

Pour connaitre la quantité de chaques canaux à emettre sur chaque enceintes, il suffit de regarder l'axe enceinte-centre, et de regarder pour quelle valeur cet axe coupe les harmoniques sphériques. Dans ce cas précis, on trouve :

$$
\begin{array}{ll}
  L_{front} = W + \frac{1}{\sqrt(2)}(X - Y) \\
  R_{front} = W + \frac{1}{\sqrt(2)}(X + Y) \\
  L_{back} = W - \frac{1}{\sqrt(2)}(X + Y) \\
  R_{back} = W - \frac{1}{\sqrt(2)}(X - Y) \\
\end{array}
$$

<!-- ```{python}

#| fig-align: "center"
#| label: fig-ms-sum
#| fig-cap: "Résultante de la somme et de la différence des composantes W et X. Les portions rouges ont une phase positive, les portions bleues ont une phase négative."

import numpy as np
import math
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
from matplotlib.colors import ListedColormap, BoundaryNorm

phi = np.arange(0,2*np.pi,0.01)
omni = np.full(
  shape=len(phi),
  fill_value=1,
  dtype=int
)
bidir = np.cos(phi)

cardio1 = (1/3)*omni+bidir
cardio2 = (1/3)*omni-bidir

points1 = np.array([phi, np.abs(cardio1)]).T.reshape(-1, 1, 2)
segments1 = np.concatenate([points1[:-1], points1[1:]], axis=1)
# Create a continuous norm to map from data points to colors
norm = plt.Normalize(-1, 1)
lc1 = LineCollection(segments1, cmap='bwr', norm=norm)
# Set the values used for colormapping
lc1.set_array(cardio1)
lc1.set_linewidth(2)

points2 = np.array([phi, np.abs(cardio2)]).T.reshape(-1, 1, 2)
segments2 = np.concatenate([points2[:-1], points2[1:]], axis=1)
# Create a continuous norm to map from data points to colors
lc2 = LineCollection(segments2, cmap='bwr', norm=norm)
# Set the values used for colormapping
lc2.set_array(cardio2)
lc2.set_linewidth(2)


fig, axs = plt.subplots(nrows=1, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()
# axs[0].plot(phi, np.abs(cardio1), color='red')
line1 = axs[0].add_collection(lc1)
axs[0].set_title('Cardioïde pointant vers l\'Est \n (M+S / W+X)')
line2 = axs[1].add_collection(lc2)
# axs[1].plot(phi, np.abs(cardio2), color='blue')
axs[1].set_title('Cardioïde pointant vers l\'Ouest \n (M-S / W-X)')

for ax in axs:
    # ax.set_theta_zero_location("E")
    ax.set_rticks([0.5, 1, 1.414])  # Less radial ticks
    ax.set_rlabel_position(-22.5)  # Move radial labels away from plotted line
    ax.legend()
    ax.grid(True)

plt.show()

``` -->

<!-- Si nous additionnons le signal obtenue par la cellule omnidirectionnelle et la cellule bidirectionnelle, nous crééons une directivité cardioïdes qui écoute vers l'avant du microphone bidirectionnelle, et donc, rejette ce qui se trouve dans son dos. Si l'on soustrait au microphone omnidirectionnel la tension obtenue par le microphone bidirectionnel, on créer alors une directivité cardioïdes qui écoute à l'arrière du microphone omnidirectionnel et rejette ce qui se trouve devant lui. -->

## Décodeurs {#HOA-decode-allrad}