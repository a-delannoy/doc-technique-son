# L'ambisonique

L'ambisonique (ou ambisonie), s'attache à décrire le champ acoustique en trois dimensions d'un espace donné en un point. C'est à la fois une technique de prise de son, grâce à l'utilisation de microphones particuliers et une solution de panning en post-production. De part son indépendance par rapport au dispositif du système de diffusion, on qualifie parfois un mixage ambisonique de *mixage orienté scène*. Nous ici l'implication que nous décrivons, à l'aide de canaux audio, une scène sonore, et non pas un certain arrangement de haut-parleur (par opposition à l'orienté canal).

L'ambisonie se distingue également des approches plus conventionnelles (approche perceptives du panning usuel) par son approche **physique**. Nous verrons que dans son fonctionnement, l'ambisonie réalise l'**échantillonnage du champ de pression acoustique**. Cet échantillonnage peut varier en précision en fonction de l'**ordre** auquel nous souhaitons travailler.

Nous allons commencer par étudier l'ambisonie dit du "premier ordre", tel que proposé par Michael Gerzon et son équipe dans les années soixante-dix. Seulement ensuite, nous questionnerons l'ambisonie d'ordre plus élevé, apparut au début des années 2000.

## L'ambisonie du premier ordre (FOA)

L'ambisonie du premier ordre (ou FOA pour First Order Ambisonic) voit le jour sous la forme d'une technique de prise de son. Celle-ci permet l'enregistrement d'un scène sonore sur **quatres canaux**, que l'on peut ensuite décoder sur n'importe quel système de haut-parleurs.

Pour capturer le champ acoustique en un point, il faut donc s'intéresser au champ acoustique lui-même. Nous l'avons vu à la @sec-le-son-physique, sous sa forme acoustique, une onde sonore se caractérise par la variation locale de la pression. Pour mesurer la pression en un point, nous pouvons utiliser un microphone omnidirectionnel (également appelé microphone à pression). Ce microphone omnidirectionnel va donc rendre compte a chaque instant du temps de la valeur de la pression. A ce stade, il n'est pas question de parler de spatialisation, la capatation d'une tel capsule étant monophonique.

Il conviendrait donc de mesurer la "direction" du déplacement local des particules d'air. Quelque part, on se demande dans **quel sens varie la pression**. Pour cela, on cherche à mesurer la vitesse de ce déplacement, et donc la variation de la pression en un point. Pour se faire, on utilise un microphone bidirectionnel (aussi appelé à gradient de pression). Ce microphone va donc mesurer, à chaque un instant du temps, la différence entre la pression qui à lieu tout de suite et celle qui a eu lieu. On caractérise donc une **variation dans le temps**.

:::{.callout-tip}

Pour clarifier le sujet, faisons le parallèle avec une voiture sur une route. On peut facilement mesure sa position sur la route (à quelle borne kilométrique se situe t-elle ?). Sa vitesse correspond à la variation de son déplacement dans le temps (combien de temps à telle mise pour passer d'une borne kilométrique A à une borne kilométrique B). Son accélération est alors la mesure de la variation de la vitesse. Quand j'accélère, la vitesse augmente, quand je décélère, la vitesse diminue, quand l'accélération est nulle, la vitesse est constante.

Nous pourrions pousser ce raisonnement dans l'absurde : si la voiture oscille entre marche avant et marche arrière (donc sa position moyenne est toujours la même), nous pouvons faire une parallèle direct avec ce que vie une particule d'air lorsqu'elle est traversée par une onde sonore.

:::

```{python}

#| label: fig-ms
#| fig-align: "center"
#| fig-cap: "Pression et variation de pression sur l'axe X"

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors
from matplotlib.collections import LineCollection
from matplotlib.colors import ListedColormap, BoundaryNorm

phi = np.arange(0,2*np.pi,0.01)
omni = np.full(
  shape=len(phi),
  fill_value=1,
  dtype=int
)

bidir = np.cos(phi)

points = np.array([phi, np.abs(bidir)]).T.reshape(-1, 1, 2)
segments = np.concatenate([points[:-1], points[1:]], axis=1)
# Create a continuous norm to map from data points to colors
norm = plt.Normalize(-1, 1)
lc = LineCollection(segments, cmap='bwr', norm=norm)
# Set the values used for colormapping
lc.set_array(bidir)
lc.set_linewidth(2)


fig, axs = plt.subplots(nrows=1, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()
axs[0].plot(phi, omni, color='red')
axs[0].set_title('Omnidirectionnel \n (M / W)')
line = axs[1].add_collection(lc)
# fig.colorbar(line, ax=axs[1])
# axs[1].plot(phi, np.abs(bidir))
axs[1].set_title('Bidirectionnel \n (S / X)')

for ax in axs:
    # ax.set_theta_zero_location("E")
    ax.set_rticks([0.5, 1])  # Less radial ticks
    ax.set_rlabel_position(-22.5)  # Move radial labels away from plotted line
    ax.legend()
    ax.grid(True)

plt.show()

```

Une capsule bidirectionnelle nous permet de mesurer dans quel axe se déplace les molécules d'air (si les les molécules oscillent dans l'axe du microphone, on obtient une tension mesurable, si les molécules oscillent sur l'axe normal (à 90°) de l'axe du microphone, on obtient une tension négligeable). Cependant cela ne nous renseigne pas si la source sonore responsable de la perturbation se trouve plutôt devant ou derrière le microphone. Cependant, si nous associons au même point de l'espace une capsule omnidirectionnelle et une capsule bidirectionnelle, nous allons pouvoir lever cette indétermination.

```{python}

#| label: fig-ms-cardio
#| fig-align: "center"
#| fig-cap: "Résultante de la somme et de la différence des composantes W et X"

import numpy as np
import math
import matplotlib.pyplot as plt

phi = np.arange(0,2*np.pi,0.01)
omni = np.full(
  shape=len(phi),
  fill_value=1,
  dtype=int
)
bidir = np.cos(phi)

cardio1 = 0.5*(omni+bidir)
cardio2 = 0.5*(omni-bidir)

fig, axs = plt.subplots(nrows=1, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()
axs[0].plot(phi, np.abs(cardio1), color='red')
axs[0].set_title('Cardioïde pointant vers l\'Est \n (M+S / W+X)')
axs[1].plot(phi, np.abs(cardio2), color='blue')
axs[1].set_title('Cardioïde pointant vers l\'Ouest \n (M-S / W-X)')

for ax in axs:
    # ax.set_theta_zero_location("E")
    ax.set_rticks([0.5, 1])  # Less radial ticks
    ax.set_rlabel_position(-22.5)  # Move radial labels away from plotted line
    ax.legend()
    ax.grid(True)

plt.show()

```

Si nous additionnons le signal obtenue par la cellule omnidirectionnelle et la cellule bidirectionnelle, nous crééons une directivité cardioïdes qui écoute vers l'avant du microphone bidirectionnelle, et donc, rejette ce qui se trouve dans son dos. Si l'on soustrait au microphone omnidirectionnel la tension obtenue par le microphone bidirectionnel, on créer alors une directivité cardioïdes qui écoute à l'arrière du microphone omnidirectionnel et rejette ce qui se trouve devant lui. Nous venons ici de fabriquer un couple MS. 

Notre dispositif permet ici de capter des ondes sonores selon un axe (ici, X). Si l'on souhaite étendre ce dispositif pour capter l'espace en trois dimensions, nous serions naturellement tenté d'ajouter deux autres capsules bidirectionnelles.

```{python}

#|fig-align: 'center'

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
# The following import configures Matplotlib for 3D plotting.
from mpl_toolkits.mplot3d import Axes3D
from scipy.special import sph_harm

# Grids of polar and azimuthal angles
theta = np.linspace(0, np.pi, 300)
phi = np.linspace(0, 2*np.pi, 300)
# Create a 2-D meshgrid of (theta, phi) angles.
theta, phi = np.meshgrid(theta, phi)
# Calculate the Cartesian coordinates of each point in the mesh.
xyz = np.array([np.sin(theta) * np.sin(phi),
                np.sin(theta) * np.cos(phi),
                np.cos(theta)])

def plot_Y(ax, el, m):
    # """Plot the spherical harmonic of degree el and order m on Axes ax."""

    # NB In SciPy's sph_harm function the azimuthal coordinate, theta,
    # comes before the polar coordinate, phi.
    Y = sph_harm(abs(m), el, phi, theta)

    # Linear combination of Y_l,m and Y_l,-m to create the real form.
    if m < 0:
        Y = np.sqrt(2) * (-1)**m * Y.imag
    elif m > 0:
        Y = np.sqrt(2) * (-1)**m * Y.real
    Yx, Yy, Yz = np.abs(Y) * xyz

    # Colour the plotted surface according to the sign of Y.
    cmap = plt.cm.ScalarMappable(cmap=plt.get_cmap('bwr'))
    cmap.set_clim(-0.5, 0.5)

    ax.plot_surface(Yx, Yy, Yz,
                    facecolors=cmap.to_rgba(Y.real),
                    rstride=2, cstride=2)

    # Draw a set of x, y, z axes for reference.
    ax_lim = 0.5
    ax.plot([-ax_lim, ax_lim], [0,0], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [-ax_lim, ax_lim], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [0,0], [-ax_lim, ax_lim], c='0.5', lw=1, zorder=10)
    
    ax_lim = 0.3
    ax.set_xlim(-ax_lim, ax_lim)
    ax.set_ylim(-ax_lim, ax_lim)
    ax.set_zlim(-ax_lim, ax_lim)
    ax.axis('off')

fig = plt.figure()
order = 1
spec = gridspec.GridSpec(ncols=pow(order+1,2), nrows=1, figure=fig)
axName = ['W','Y','Z','X']
for l in range(order+1):
  for m in range(-l,l+1):
    ax = fig.add_subplot(spec[2*l+m], projection='3d')
    ax.set_title(axName[2*l+m])
    plot_Y(ax, l, m)

plt.show()

```

## Captation du champs sonore

## Synthèse du champs sonore

## Décodeurs {#HOA-decode-allrad}