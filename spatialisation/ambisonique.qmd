# L'ambisonique

![Dôme ambisonique du Théâtre de Gennevilliers](../_resources/bitmap/ambisonic/ambisonic_dome.jpeg)

L'ambisonique (ou ambisonie) s'attache à décrire le champ acoustique en trois dimensions d'un espace donné en un point. C'est à la fois une technique de prise de son, grâce à l'utilisation de microphones particuliers et une solution de panning en postproduction. De par son indépendance par rapport au dispositif du système de diffusion, on qualifie parfois un mixage ambisonique de « *mixage orienté scène »*. En effet, un signal ambisonique décrit, à l'aide de canaux audio, une scène sonore, et non pas un certain arrangement de haut-parleur (par opposition à l'orienté canal).

L'ambisonie se distingue également des approches plus conventionnelles (approche perceptive du panning usuel) par son approche **physique**. Nous verrons que dans son fonctionnement, l'ambisonie réalise l'**échantillonnage du champ de pression acoustique**. Cet échantillonnage peut varier en précision en fonction de l'**ordre** auquel nous souhaitons travailler.

Nous commencerons par étudier l'ambisonie dit du "premier ordre", tel que proposé par Michael Gerzon et son équipe dans les années soixante-dix. Seulement ensuite, nous envisagerons l'ambisonie d'ordre plus élevé, pour pallier aux défauts de l’ambisonie du premier ordre.

## L'ambisonie du premier ordre (FOA)

### Captation du champ sonore

L'ambisonie du premier ordre (ou FOA pour « First Order Ambisonic ») voit le jour sous la forme d'une technique de prise de son. Celle-ci permet l'enregistrement d'une scène sonore sur **quatre canaux**, que l'on peut ensuite décoder sur n'importe quel système de haut-parleurs.

Pour capturer le champ acoustique en un point, il faut donc s'intéresser au champ acoustique lui-même. Nous l'avons vu à la @sec-le-son-physique, sous sa forme acoustique, une onde sonore se caractérise par la variation locale dans le temps de la pression. Pour mesurer la pression en un point, nous pouvons utiliser un microphone omnidirectionnel (également appelé microphone à pression). Ce microphone omnidirectionnel va donc rendre compte à chaque instant du temps de la valeur de la pression. À ce stade, il n'est pas question de parler de spatialisation, la captation d'une telle capsule étant monophonique.

Il conviendrait donc de mesurer la "direction" du déplacement local des particules d'air. Quelque part, on se demande dans **quel sens et quelle direction varie la pression**. <!--Pour cela, on cherche à mesurer la variation dans l'espace de la pression d'un point.--> Pour se faire, on utilise un microphone bidirectionnel (aussi appelé à gradient de pression). Ce microphone va donc mesurer, pour chaque instant du temps, la différence entre la pression entre un point de l'espace et un autre très rapproché. On caractérise donc une **variation dans l'espace**.

<!-- :::{.callout-tip}

Quelques mots sur le formalisme mathématique. Soit $p(t,\vec{r})$, le champ de pression, $v(t,\vec{r})$ sa vitesse et $s(t,\vec{r})$, une onde sonore. Ces trois fonctions dépendent du **temps** et de l'**espace** (représenté par le vecteur unitaire $\vec{r}$).

Lorsqu'un évènement sonore est produit, on approxime

::: -->

```{python}

#| label: fig-ms
#| fig-align: "center"
#| fig-cap: "Pression et variation de pression sur l'axe Y. Les portions rouges ont une phase positive, les portions bleues ont une phase négative."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

phi = np.arange(-np.pi,np.pi,0.01)
omni = np.full(
  shape=len(phi),
  fill_value=dbnorm(1),
  dtype=int
)

bidir = dbnorm(np.cos(phi))
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

fig, axs = plt.subplots(nrows=1, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()
axs[0].plot(phi, omni, color='red')
axs[0].set_title('Omnidirectionnel \n (M / W)')
axs[1].plot(phi, bidir_pos, color='red')
axs[1].plot(phi, bidir_neg, color='blue')
axs[1].set_title('Bidirectionnel \n (S / Y)')

for ax in axs:
    ax.set_ylim(-20,0)
    ax.set_rticks([-20, -12, -6, 0, 3])  # Less radial ticks
    ax.legend()
    ax.grid(True)

plt.show()

```

Une capsule bidirectionnelle nous permet de mesurer sur quel axe se déplacent les molécules d'air (si les molécules oscillent dans l'axe du microphone, on obtient un niveau mesurable, si les molécules oscillent sur l'axe normal (à 90°) de l'axe du microphone, on obtient un niveau négligeable). Cependant, cela ne nous indique pas si la source sonore responsable de la perturbation se trouve plutôt devant ou derrière le microphone. Néanmoins, si nous associons au même point de l'espace une capsule omnidirectionnelle et une capsule bidirectionnelle, nous allons pouvoir lever cette indétermination.


```{python}

#| label: fig-m-et-s
#| fig-align: "center"
#| fig-cap: "Représentation des composantes W et Y sur le même graphique. Les portions rouges ont une phase positive, les portions bleues ont une phase négative."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

phi = np.arange(-np.pi,np.pi,0.01)
omni = np.full(
  shape=len(phi),
  fill_value=dbnorm(1),
  dtype=int
)

bidir = dbnorm(np.cos(phi))
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

fig, ax = plt.subplots(nrows=1, ncols=1,subplot_kw={'projection': 'polar'})
fig.tight_layout()
ax.plot(phi, omni, color='red')
ax.plot(phi, bidir_pos, color='red')
ax.plot(phi, bidir_neg, color='blue')
ax.plot(np.pi/8,0, markersize=20)
ax.set_title('Association de deux harmoniques sphériques \n (M et S / W et Y)')

ax.set_ylim(-20,0)
ax.set_rticks([-20, -12, -6, 0, 3])  # Less radial ticks
ax.legend()
ax.grid(True)

plt.show()

```

On constate alors que, selon l'angle d'incidence de la source par rapport aux capsules, celle-ci subit une atténuation (et une modification de la phase si la valeur absolue de l'angle d'incidence est ici supérieure à 90°) dans le canal de captation Y, permettant donc de coder sa position autour du microphone. Le canal W capte la source de la même manière, peu importe son angle d'incidence. Nous venons ici de fabriquer un couple MS (voir @sec-pds-stereo-ms).

Notre dispositif permet ici de capter des ondes sonores selon un seul axe (ici, Y). Si l'on souhaite étendre ce dispositif pour capter l'espace en trois dimensions, nous serions naturellement tentés d'ajouter deux autres capsules bidirectionnelles supplémentaires.

```{python}

#|fig-align: 'center'
#| label: fig-foa
#| fig-cap: "Composantes ambisonique du premier ordre. Les surfaces rouges ont une phase positive, les surfaces bleues ont une phase négative."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
# The following import configures Matplotlib for 3D plotting.
from mpl_toolkits.mplot3d import Axes3D
from scipy.special import sph_harm

# Grids of polar and azimuthal angles
theta = np.linspace(0, np.pi, 300)
phi = np.linspace(0, 2*np.pi, 300)
# Create a 2-D meshgrid of (theta, phi) angles.
theta, phi = np.meshgrid(theta, phi)
# Calculate the Cartesian coordinates of each point in the mesh.
xyz = np.array([np.sin(theta) * np.sin(phi),
                np.sin(theta) * np.cos(phi),
                np.cos(theta)])

def plot_Y(ax, el, m):
    # """Plot the spherical harmonic of degree el and order m on Axes ax."""

    # NB In SciPy's sph_harm function the azimuthal coordinate, theta,
    # comes before the polar coordinate, phi.
    Y = sph_harm(abs(m), el, phi, theta)

    # Linear combination of Y_l,m and Y_l,-m to create the real form.
    if m < 0:
        Y = np.sqrt(2) * (-1)**m * Y.imag
    elif m > 0:
        Y = np.sqrt(2) * (-1)**m * Y.real
    Yx, Yy, Yz = np.abs(Y) * xyz

    # Colour the plotted surface according to the sign of Y.
    cmap = plt.cm.ScalarMappable(cmap=plt.get_cmap('bwr'))
    cmap.set_clim(-0.5, 0.5)

    ax.plot_surface(Yx, Yy, Yz,
                    facecolors=cmap.to_rgba(Y.real),
                    rstride=2, cstride=2)

    # Draw a set of x, y, z axes for reference.
    ax_lim = 0.5
    ax.plot([-ax_lim, ax_lim], [0,0], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [-ax_lim, ax_lim], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [0,0], [-ax_lim, ax_lim], c='0.5', lw=1, zorder=10)
    
    ax_lim = 0.3
    ax.set_xlim(-ax_lim, ax_lim)
    ax.set_ylim(-ax_lim, ax_lim)
    ax.set_zlim(-ax_lim, ax_lim)
    ax.axis('off')

fig = plt.figure()
order = 1
spec = gridspec.GridSpec(ncols=pow(order+1,2), nrows=1, figure=fig)
axName = ['W','Y','Z','X']
for l in range(order+1):
  for m in range(-l,l+1):
    ax = fig.add_subplot(spec[2*l+m], projection='3d')
    ax.set_title(axName[2*l+m])
    plot_Y(ax, l, m)

# TODO: ADD 2D VERSION (ALL HARMONIC ON ONE PLOT)

plt.show()

```

En pratique, les microphones ambisoniques n'utilisent pas cet arrangement de capsules. En effet, l'encombrement des capsules bidirectionnelles compromet sévèrement la coïncidence du système. La qualité d'un tel microphone dépend largement de sa capacité à positionner les capsules avec la plus grande coïncidence possible, au risque sinon de détériorer la précision de localisation dans le haut du spectre. On utilise alors plutôt quatre capsules cardioïdes, placé sur les surfaces d'un tétraèdre. Cet arrangement est mathématiquement strictement équivalent à l'utilisation d'une capsule omnidirectionnelle et de trois capsules bidirectionnelles. Seulement, l'encombrement moindre des capsules cardioïdes permet une meilleure coïncidence de celles-ci.

![Microphone Sennheiser Ambeo](https://d2j6dbq0eux0bg.cloudfront.net/images/29143418/1438893864.jpg){width=50%}

On appelle le flux audio en sortie d'un microphone ambisonique du premier ordre **Format-A**, dans lequel chaque canal correspond à une capsule précise. Par opposition, on appelle généralement **Format-B** un flux ambisonique du premier ordre encodé, où chaque canal correspond à une des composantes W, X, Y, Z.

:::{.callout-note}

L'appellation **Format-A** se retrouve également pour les ordres supérieurs, même si ces microphones sont rares ! Le terme **Format-B** est, quant à lui, discutable pour les ordres supérieurs.

:::

### Synthèse du champ sonore

Nous avons vu qu'un microphone ambisonique nous permet de capturer l'espace acoustique entendu d'un point. Nous pouvons également "synthétiser", c'est-à-dire encoder une source sonore monophonique dans un espace acoustique virtuel ambisonique. Pour cela, on utilise simplement des panners ambisoniques.

Pour une incidence donnée de cette source sonore, le panner va affecter une partie de son énergie aux différentes composantes d'un signal ambisonique (W, X, Y, Z) et une phase particulière (positive ou négative). Il est également possible d'encoder des signaux multicanaux (stéréo, quadriphonie, 5.0). Il s'agit d'une technique très efficace pour adapter un mixage réalisé sur un arrangement de haut-parleurs particuliers vers un autre.


Nous ferons état de ces différentes techniques et des différents panners ambisoniques dans le @sec-outils-ambisoniques .

### Restitution du champ sonore

Une fois le signal enregistré, ou encodé en ambisonique, il convient de le décoder sur un arrangement de haut-parleurs particulier. Cette phase de décodage est peut-être la plus complexe à appréhender (et explique très certainement pourquoi l'ambisonique reste à ce jour si peu utilisée).

Illustrons le procédé de décodage en considérant un flux audio ambisonique 2D (W, X, Y) et un système de diffusion quadriphonique.

```{python}

#| label: fig-amb2D-quad
#| fig-align: "center"
#| fig-cap: "Décodage par projection basique."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

db = lambda x: 20*np.log10(np.abs(x))
dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

phi = np.arange(-np.pi,np.pi,0.01)
omniLin = np.full(shape=len(phi),fill_value=1/3,dtype=float)
omni = db(omniLin)

bidirLin = np.cos(phi)
bidir = db(bidirLin)
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

bidir2Lin = np.sin(phi)
bidir2 = db(bidir2Lin)
bidir2_pos = np.ma.masked_where(phi<0, bidir2)
bidir2_neg = np.ma.masked_where(phi>=0, bidir2)

alphaSource = -np.pi/8
sourceDir = omniLin+np.cos(alphaSource)*bidirLin+np.sin(alphaSource)*bidir2Lin
sourceDir = dbnorm(sourceDir)

speakerPos = [np.pi/4, 3*np.pi/4, 5*np.pi/4, 7*np.pi/4]
speakerWeight = [4, 4, 4, 4] #in dB

fig, axs = plt.subplots(nrows=1, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()

axs[0].plot(phi, omni, color='crimson')
axs[0].plot(phi, bidir_pos, color='red')
axs[0].plot(phi, bidir_neg, color='blue')
axs[0].plot(phi, bidir2_pos, color='red')
axs[0].plot(phi, bidir2_neg, color='blue')
axs[1].plot(phi,sourceDir)
axs[0].set_title("Encodage d'une source virtuelle\nen ambisonie d'ordre 1, 2D")
axs[1].set_title("Directivité résultante")

for ax in axs:
  ax.plot(speakerPos, speakerWeight, "D", ms=20, color='black')
  ax.plot(alphaSource, 0, "o", ms=10, color='purple', label='Source virtuelle')
  ax.set_ylim(-20,0)
  ax.set_rticks([-20, -12, -6, 0, 6])  # Less radial ticks
  ax.legend()
  ax.grid(True)

plt.show()


```

La figure ci-dessus représente une approche de décodage par **projection** dite **basique**. Pour connaître la quantité de chaque canal à émettre sur chaque enceinte, il suffit de regarder l'axe enceinte-centre, et de lire pour quelle valeur cet axe coupe les harmoniques sphériques. Dans ce cas précis, on trouve :

$$
\begin{array}{ll}
  L_{front} = \frac{1}{3}W + X - Y \\
  R_{front} = \frac{1}{3}W + X + Y \\
  L_{back} = \frac{1}{3}W - X - Y \\
  R_{back} = \frac{1}{3}W - X + Y \\
\end{array}
$$

On peut également étudier la directivité formée pour une source et projeter sur les haut-parleurs pour observer leurs différentes contributions. On remarque dans ce cas (décodage dit basique) la présence d'un lobe arrière. Cela signifie que les enceintes peuvent contribuer à la diffusion d'une source en **opposition de phase** lorsque celles-ci ont certaines positions.

:::{.callout-tips}
On appelle aussi le décodage par projection "SAD", pour Sample Ambisonic Decoding. En effet, l'opération consiste à échantillonner la valeur de chaque harmonique sphérique en fonction de l'angle d'incidence de la source.
:::

Il existe d'autres modes de décodage permettant de changer la directivité associée à une source. Ces modes supplémentaires sont "maxRe" et "InPhase".


```{python}

#| label: fig-amb-dec-mode
#| fig-align: "center"
#| fig-cap: "Décodage par projection basique, maxRe et inPhase."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

db = lambda x: 20*np.log10(np.abs(x))
dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

fig, axs = plt.subplots(nrows=2, ncols=3,subplot_kw={'projection': 'polar'})
fig.tight_layout()

#common
phi = np.arange(-np.pi,np.pi,0.01)
alphaSource = -np.pi/8

speakerPos = [np.pi/4, 3*np.pi/4, 5*np.pi/4, 7*np.pi/4]
speakerWeight = [4, 4, 4, 4] #in dB

#Basic plot
omni = np.full(shape=len(phi),fill_value=db(1/3),dtype=float)
bidir = db(np.cos(phi))
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

bidir2 = db(np.sin(phi))
bidir2_pos = np.ma.masked_where(phi<0, bidir2)
bidir2_neg = np.ma.masked_where(phi>=0, bidir2)

sourceDir = dbnorm(1/3+np.cos(alphaSource)*np.cos(phi)+np.sin(alphaSource)*np.sin(phi))

axs[0][0].plot(phi, omni, color='crimson')
axs[0][0].plot(phi, bidir_pos, color='red')
axs[0][0].plot(phi, bidir_neg, color='blue')
axs[0][0].plot(phi, bidir2_pos, color='red')
axs[0][0].plot(phi, bidir2_neg, color='blue')

axs[1][0].plot(phi, sourceDir)

#maxRe plot
omni = np.full(shape=len(phi),fill_value=db(1/np.sqrt(2)),dtype=float)
bidir = db(np.cos(phi))
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

bidir2 = db(np.sin(phi))
bidir2_pos = np.ma.masked_where(phi<0, bidir2)
bidir2_neg = np.ma.masked_where(phi>=0, bidir2)

sourceDir = dbnorm(1/np.sqrt(2)+np.cos(alphaSource)*np.cos(phi)+np.sin(alphaSource)*np.sin(phi))

axs[0][1].plot(phi, omni, color='crimson')
axs[0][1].plot(phi, bidir_pos, color='red')
axs[0][1].plot(phi, bidir_neg, color='blue')
axs[0][1].plot(phi, bidir2_pos, color='red')
axs[0][1].plot(phi, bidir2_neg, color='blue')

axs[1][1].plot(phi, sourceDir)

#inPhase plot
omni = np.full(shape=len(phi),fill_value=db(1),dtype=float)
bidir = db(np.cos(phi))
bidir_pos = np.ma.masked_where(np.abs(phi)>np.pi/2, bidir)
bidir_neg = np.ma.masked_where(np.abs(phi)<=np.pi/2, bidir)

bidir2 = db(np.sin(phi))
bidir2_pos = np.ma.masked_where(phi<0, bidir2)
bidir2_neg = np.ma.masked_where(phi>=0, bidir2)

sourceDir = dbnorm(1+np.cos(alphaSource)*np.cos(phi)+np.sin(alphaSource)*np.sin(phi))

axs[0][2].plot(phi, omni, color='crimson')
axs[0][2].plot(phi, bidir_pos, color='red')
axs[0][2].plot(phi, bidir_neg, color='blue')
axs[0][2].plot(phi, bidir2_pos, color='red')
axs[0][2].plot(phi, bidir2_neg, color='blue')

axs[1][2].plot(phi, sourceDir)

# axs[1][0].plot(phi,sourceDir)
# axs[1][0].set_title("Directivité résultante")

for axl in axs:
  for ax in axl:
    ax.plot(speakerPos, speakerWeight, "D", ms=6, color='black')
    ax.plot(alphaSource, 0, "o", ms=10, color='purple')
    ax.set_ylim(-20,0)
    ax.set_rticks([-20, -12, -6, 0, 6])  # Less radial ticks
    ax.legend()
    ax.grid(True)

plt.show()


```

Le décodage basique permet un rendu psychoacoustique correct du registre basse fréquence (jusqu'à 500 Hz environ) et offre une précision de localisation maximale au point d'écoute idéal.

Un décodage dit "maxRe" a pour conséquence d'améliorer la localisation dans les hautes fréquences (>700 Hz environ). On constate aussi la réduction des lobes arrière, et donc une contribution moindre des composantes en opposition de phase dans les enceintes.

Lorsqu'un décodeur utilise une optimisation InPhase, la totalité des lobes arrière est supprimée. Cela signifie qu'aucune enceinte ne diffuse de composantes en opposition de phase. Cela a pour conséquence d'améliorer l'homogénéité de la diffusion, d'augmenter la largeur du point d'écoute idéal, au détriment de la précision de localisation.

:::{.callout-note}

Il n'est pas rare de trouver le mode "maxRe" par défaut dans les décodeurs.

:::

Afin de tenir compte des différences de perception entre les basses fréquences et les hautes fréquences, il est souvent préconisé d'adapter le mode de décodage en fonction de la plage de fréquence. Par exemple, Michael Gerzon propose un décodage "perceptif", en mode basique dans le bas du spectre et maxRe dans les fréquences aiguës. Jérome Daniel fait également le lien entre zone de couverture, mode de décodage et plage de fréquences.

![Mode de décodage et zone de couverture. J. Daniel (2001).](../_resources/bitmap/ambisonic/coverage.png)

:::{.callout-important}

Une restitution ambisonique sur un arrangement de haut-parleurs à deux ou trois dimensions n'est pas équivalente. En effet, un décodage 2D offre une meilleure précision de localisation.

:::

### Décodage pour arrangement de haut-parleurs irréguliers

Le décodage par projection mentionné précédemment fonctionne bien pour des arrangements de haut-parleurs réguliers dans l'espace. Cependant, la majorité des systèmes utilisés dans l'industrie de l'audio ne sont pas réguliers (stéréophonie, 5.1, 7.1.4, etc). Dès lors un décodage par projection ne sera pas homogène en niveau.

```{python}

#| label: fig-amb-loudness
#| fig-align: "center"
#| fig-cap: "Le décodage par projection sur un arrangement 5.0 n'est homogène en énergie."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors

db = lambda x: 20*np.log10(np.abs(x))
dbnorm = lambda x: 20*np.log10(np.abs(x)/np.max(x))

fig, axs = plt.subplots(nrows=2, ncols=2,subplot_kw={'projection': 'polar'})
fig.tight_layout()

phi = np.arange(-np.pi,np.pi,0.01)

omni = np.full(shape=len(phi),fill_value=1,dtype=float)
bidir = np.cos(phi)
bidir2 = np.sin(phi)

### QUAD PLOT

speakerPos = [np.pi/4, 3*np.pi/4, 5*np.pi/4, 7*np.pi/4]
speakerWeight = np.full(shape=len(speakerPos),fill_value=4,dtype=float) #in dB

axs[0][0].plot(speakerPos, speakerWeight, "D", ms=10, color='black')
axs[0][1].plot(speakerPos, speakerWeight, "D", ms=10, color='black')

energy = 0
for spkr in speakerPos:
  sourceDir = 1/3*omni+np.cos(spkr)*bidir+np.sin(spkr)*bidir2
  energy = energy + np.power(sourceDir,2)
  axs[0][0].plot(phi,dbnorm(sourceDir))

axs[0][1].plot(phi,dbnorm(energy))

axs[0][0].set_title("Projection sur une quadriphonie")
axs[0][1].set_title("Energie résultante")

### 5.1 PLOT

speakerPos = [0, -30/180*np.pi, 30/180*np.pi, -110/180*np.pi, 110/180*np.pi]
speakerWeight = np.full(shape=len(speakerPos),fill_value=4,dtype=float) #in dB

ax.plot(speakerPos, speakerWeight, "D", ms=10, color='black')

axs[1][0].plot(speakerPos, speakerWeight, "D", ms=10, color='black')
axs[1][1].plot(speakerPos, speakerWeight, "D", ms=10, color='black')

energy = 0
for spkr in speakerPos:
  sourceDir = 1/3*omni+np.cos(spkr)*bidir+np.sin(spkr)*bidir2
  energy = energy + np.power(sourceDir,2)
  axs[1][0].plot(phi,dbnorm(sourceDir))

axs[1][1].plot(phi,dbnorm(energy))

axs[1][0].set_title("Projection sur un 5.1")
axs[1][1].set_title("Energie résultante")

for axl in axs:
  for ax in axl:
    
    ax.set_ylim(-20,0)
    ax.set_rticks([-20, -12, -6, 0, 6])  # Less radial ticks
    ax.legend()
    ax.grid(True)

plt.show()


```

Il existe alors plusieurs stratégies pour pallier ce problème. La plus utilisée est le décodage **AllRAD** (All-Round Ambisonic Decoder). Celle-ci consiste à décoder le signal ambisonique en deux étapes. Tout d'abord on le décode sur un arrangement de [240 haut-parleurs parfait](http://neilsloane.com/sphdesigns/), puis on utilise une loi de panoramique VBAP pour réduire ces 240 haut-parleurs à l'arrangement réel.

Une autre stratégie assez connue est l'**EPAD** (Energy Preserving Ambisonic Decoding), qui permet de produire un champ d'énergie invariant en fonction de l'angle d'incidence de la source.

:::{.callout-important}

Peu importe que l'on utilise une stratégie de décodage AllRAD ou EPAD, il convient de **toujours** avoir plus de canaux d'enceintes que de canaux ambisoniques.

:::

##  L'ambisonie d'ordre plus élevé (HOA)

L'HOA (pour *Higher Order Ambisonic*) est une extension du système proposé par Michael Gerzon. En effet, l'ambisonie du premier ordre introduit un certain nombre d'effets indésirables lorsqu'on le décode sur un arrangement comprenant un trop grand nombre de haut-parleurs. Il en résulte alors un flou de localisation important, voir l'apparition de problèmes de timbre.

Le FOA reposant sur l'exploitation des harmoniques sphériques aux ordres 0 et 1, il était alors tout indiqué d'utiliser les harmoniques d'ordre supérieur.

```{python}

#|fig-align: 'center'
#| label: fig-hoa
#| fig-cap: "Composantes ambisonique jusqu'à l'ordre quatre. Les surfaces rouges ont une phase positive, les surfaces bleues ont une phase négative."

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
# The following import configures Matplotlib for 3D plotting.
from mpl_toolkits.mplot3d import Axes3D
from scipy.special import sph_harm

# Grids of polar and azimuthal angles
theta = np.linspace(0, np.pi, 300)
phi = np.linspace(0, 2*np.pi, 300)
# Create a 2-D meshgrid of (theta, phi) angles.
theta, phi = np.meshgrid(theta, phi)
# Calculate the Cartesian coordinates of each point in the mesh.
xyz = np.array([np.sin(theta) * np.sin(phi),
                np.sin(theta) * np.cos(phi),
                np.cos(theta)])

def plot_Y(ax, el, m):
    # """Plot the spherical harmonic of degree el and order m on Axes ax."""

    # NB In SciPy's sph_harm function the azimuthal coordinate, theta,
    # comes before the polar coordinate, phi.
    Y = sph_harm(abs(m), el, phi, theta)

    # Linear combination of Y_l,m and Y_l,-m to create the real form.
    if m < 0:
        Y = np.sqrt(2) * (-1)**m * Y.imag
    elif m > 0:
        Y = np.sqrt(2) * (-1)**m * Y.real
    Yx, Yy, Yz = np.abs(Y) * xyz

    # Colour the plotted surface according to the sign of Y.
    cmap = plt.cm.ScalarMappable(cmap=plt.get_cmap('bwr'))
    cmap.set_clim(-0.5, 0.5)

    ax.plot_surface(Yx, Yy, Yz,
                    facecolors=cmap.to_rgba(Y.real),
                    rstride=2, cstride=2)

    # Draw a set of x, y, z axes for reference.
    ax_lim = 0.5
    ax.plot([-ax_lim, ax_lim], [0,0], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [-ax_lim, ax_lim], [0,0], c='0.5', lw=1, zorder=10)
    ax.plot([0,0], [0,0], [-ax_lim, ax_lim], c='0.5', lw=1, zorder=10)
    
    ax_lim = 0.4
    ax.set_xlim(-ax_lim, ax_lim)
    ax.set_ylim(-ax_lim, ax_lim)
    ax.set_zlim(-ax_lim, ax_lim)
    ax.axis('off')

fig = plt.figure()
order = 4
spec = gridspec.GridSpec(ncols=2*order+1, nrows=order+1, figure=fig)
# axName = ['W','Y','Z','X']
for l in range(order):
  for m in range(-l,l+1):
    ax = fig.add_subplot(spec[l, m+order], projection='3d')
    # ax.set_title(axName[2*l+m])
    plot_Y(ax, l, m)

# TODO: ADD 2D VERSION (ALL HARMONIC ON ONE PLOT)

plt.show()

```

Chaque nouvel ordre ajoute donc un certain nombre de canaux au flux ambisonique. On trouve le nombre de canaux d'un ambisonique d'ordre N avec la formule suivante:

$$ N_{ch} = (N+1)^2$$

On rappelle que lors d'un décodage, on doit toujours avoir plus de canaux d'enceintes que de canaux ambisoniques. Augmenter l'ordre augmente la limite du nombre de haut-parleurs minimum. Cependant, la rétrocompatibilité des ordres inférieurs est garantie par la suppression des canaux correspondant aux ordres supérieurs. Par exemple, un flux ambisonique d'ordre 7 (64 canaux) est trop important pour le décoder sur un système Dolby Atmos 7.1.4 (11 canaux, hors sub). Nous pourrions alors tronquer le signal ambisonique d'ordre 7 pour ne garder que les canaux de 1 à 9. Nous aurions ainsi réalisé une réduction de l'ordre 7 à l'ordre 2, ce dernier étant tout à fait adéquat pour un décodage sur un arrangement de 11 haut-parleurs.

:::{.callout-important} 
Ainsi, nous admettrons ces deux règles du décodage ambisonique d'ordre élevé:

+ Le nombre de canaux HOA doit toujours être inférieur au nombre de canaux d'enceintes
+ Si possible, l'ordre ambisonique doit être le plus élevé possible (tout en respectant la condition précédente)
:::

### Les outils de captations d'ordre plus élevé

Il existe un certain nombre de systèmes de prise de son ambisonique d'ordre supérieur. À l'ordre deux, on mentionnera les microphones suivants : [Core Sound OctoMic](https://www.core-sound.com/products/octomic), [Voyage Spatial Mic](https://voyage.audio/spatialmic/) et l'Audiotechnica. Au troisième ordre, le [Zylia](https://www.zylia.co/), le [Spcmic](https://spcmic.com/) et l'[Eigenmike](https://mhacoustics.com/products).

:::{layout-ncol="3"}

![](../_resources/bitmap/ambisonic/octomic.jpg)

![](../_resources/bitmap/ambisonic/voyagemic.jpg)

![](../_resources/bitmap/ambisonic/voyagemic.jpg)

![](../_resources/bitmap/ambisonic/zylia.jpg)

![](../_resources/bitmap/ambisonic/spcmic.png)

![](../_resources/bitmap/ambisonic/eigenmike.png)

:::

La plupart de ces microphones sont fournis avec des encodeurs spécialisés. En effet, chacun d'entre eux utilise des techniques sensiblement différentes afin de capturer l'espace acoustique. Dès lors, l'encodage du signal des capsules vers de l'ambisonique est bien souvent un procédé propriétaire.

Le nombre de canaux de sortie importants contre indique rapidement l'usage de sorties analogiques. La majorité de ces microphones préfère des sorties USB (fonctionnement d'interface audio) ou audionumériques (Audio sur IP, ADAT).

### Les différents formats ambisoniques

Bien que la notion de ["format" ambisonique](https://en.wikipedia.org/wiki/Ambisonic_data_exchange_formats) ne soit pas spécifique à l'ambisonie d'ordre élevé, le multiplication du nombre de canaux rend sa compréhension impérative.
Deux paramètres sont à prendre en compte : l'ordonnancement des canaux et la normalisation de la composante W par rapport aux autres.

On compte trois principaux ordonnancement ambisoniques, nommés : **Furse-Malham (FuMa)**, **Single Index Designation (SID)** et **Ambisonic Channel Numbering (ACN)**. Le FuMa défini l'ordre des canaux jusqu'au troisième ordre. Le SID est défini par J. Daniel mais reste peut utilisé. L'ACN est aujourd'hui le plus utilisé (format Ambix).

<!-- ![Ordonnancement FuMa](../_resources/bitmap/ambisonic/sorting_acn.png) -->

:::{layout-ncol="3"}

|   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|
|   |   |   | $W_{0}$  |   |   |   |
|   |   | $Y_{2}$ | $Z_{3}$ | $X_1$|   |   |
|   | $V_{8}$ | $T_{6}$ | $R_4$ | $S_5$ | $U_7$ |   |
| $Q_{15}$ | $O_{13}$ | $M_{11}$ | $K_{9}$ | $L_{10}$ | $N_{12}$ | $P_{14}$ |

: FuMa

|   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|
|   |   |   | $0$  |   |   |   |
|   |   | $2$ | $3$ | $1$|   |   |
|   | $5$ | $7$ | $8$ | $6$ | $4$ |   |
| $10$ | $12$ | $14$ | $15$ | $13$ | $11$ | $9$ |

: SID

|   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|
|   |   |   | $0$ |   |   |   |
|   |   | $1$ | $2$ | $3$|   |   |
|   | $4$ | $5$ | $6$ | $7$ | $8$ |   |
| $9$ | $10$ | $11$ | $12$ | $13$ | $14$ | $15$ |

: ACN

:::

Concernant la normalisation, il existe trois variantes: **maxN**, **N3D** et **SN3D**. La normalisation **maxN** assure que le gain d'une source monophonique pannée n'excède jamais 1 (le panner fonctionne alors seulement en atténuation). La normalisation **N3D** assure que les différentes composantes soient encodées à égale puissance. Enfin, la normalisation **SN3D** est la plus répandue. Elle assure qu'aucune composante ne dépasse les valeurs crêtes du canal W.

:::{.callout-important}
La normalisation n'a aucun effet sur le rendu sonore ambisonique. Il est d'ailleurs possible de passer d'une normalisation à une autre. Il convient seulement d'être vigilant lors de la manipulation de flux ambisonique, et de bien s'assurer de leurs formats d'acquisition, avant de correctement paramétrer ses outils.
:::

Aujourd'hui, le format le plus commun d'ambisonique est l'**[Ambix](https://www.researchgate.net/publication/266602800_AMBIX_-A_SUGGESTED_AMBISONICS_FORMAT)**, utilisant un triage ACN et une normalisation SN3D. Son prédécesseur était ce qu'on nomme couramment le B-Format, ou parfois FuMa, utilisant un triage FuMa et une normalisation maxN (avec une atténuation de -3 dB).

## Avantages de l'ambisonie

Malgré sa complexité théorique certaine, l'ambisonique offre un bon nombre d'avantages par rapport aux autres techniques de mixage. Avant tout, un mixage ambisonique ne dépend pas du système de restitution. Il peut être décodé après mixage sur, virtuellement n'importe quel arrangement d'enceinte (bien que nous ayons vu certaines contraintes à respecter pour satisfaire les critères de qualité sonore). Travailler à un ordre élevé permet également un décodage vers du binaural cohérent. Il s'agit d'ailleurs d'une approche de la synthèse binaurale courante (Meta 360 et autres casquent de réalité virtuelle).

Le traitement d'un signal ambisonique (égalisation, compression) s'assimile au traitement de multiples canaux. Les outils sont relativement rares, mais cela reste possible. Les traitements impliquant des systèmes linéaire et invariant temporellement (comme les égaliseurs) s'appliquent sans précautions particulières. Attention néanmoins aux traitements dynamiques et non linéaires, ceux-ci peuvent briser la cohérence de la scène sonore. Il est alors recommandé d'utiliser le canal W comme canal de détection afin d'appliquer le traitement de façon indifférenciée sur les autres composantes. On trouve également des traitements spécifiques à l'ambisonique, comme des compresseurs directionnels, permettant de maîtriser l'énergie d'un mixage provenant d'une certaine direction.

L'ambisonie est souvent apprécié pour sa malléabilité et son interactivité. En effet, l'encodage par harmonique sphérique permet d'appliquer des effets en temps réel, même après mixage (et donc sommation). Il est possible de tourner la scène sonore, de l'inverser, de zoomer dedans, etc. Cette propriété de l'ambisonique explique son utilisation courante dans les médias de l'interaction, comme la VR et le jeu-vidéo.