% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage[french]{babel}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Guide pratique de la prise de son et du mixage appliqués à la musique},
  pdfauthor={Jean-Loup Pecquais},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Guide pratique de la prise de son et du mixage appliqués à la musique}
\author{Jean-Loup Pecquais}
\date{2022-12-29}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{avant-propos}{%
\chapter{Avant-propos}\label{avant-propos}}

Ce livre est né de la nécessité d'un support de cours pour la formation professionnelle ``Technique de Prise de Son'', dispensée par l'auteur. Il intègre donc l'ensemble des notions abordées, expliquées en détail, ainsi que des exemples sonores.

Ce livre est écrit dans la philosophie de l'Open Source. L'intégralité de son contenu est donc disponible gratuitement. Son code source est accessible dans un dépôt GitHub. Ainsi, il est possible à tout à chacun de reporter les éventuelles erreurs ou de proposer des modifications. La grande majorité des outils utilisés pour sa rédaction et la création du contenu sont open source : R \& Rmarkdown, Python, FAUST et draw.io.

\hypertarget{a-qui-sadresse-cet-ouvrage}{%
\section{A qui s'adresse cet ouvrage}\label{a-qui-sadresse-cet-ouvrage}}

Ce livre s'adresse à toutes personnes désireuses d'en apprendre plus sur le son ainsi que sur les métiers de preneur de son et de mixeur. Ainsi, il fait état des principes physiques nécessaires à la bonne appréhension des techniques de travail des métiers susnommés, avec le souci de les rendre accessibles à toutes et tous.

Il pourra donc servir aux musiciens, aux étudiants, et pourquoi pas, à certains professionnels des métiers du son et du divertissement en général.

\hypertarget{mise-uxe0-jour}{%
\section{Mise à jour}\label{mise-uxe0-jour}}

La distribution numérique de ce livre permet une mise à jour régulière de son contenu. Cela implique deux choses :

\begin{itemize}
\tightlist
\item
  Certaines sections peuvent être incomplètes, et seront complétées plus tard
\item
  C'est une bonne idée de revenir consulter ce site régulièrement
\end{itemize}

\begin{quote}
Pour l'instant, ce livre n'inclut pas encore d'exemples sonores, cela est en cours de création.
\end{quote}

\hypertarget{structures}{%
\section{Structures}\label{structures}}

Dans un premier temps, le livre aborde des principes généraux, aussi bien sur la physique que sur l'environnement de production de la musique enregistrée. Est ensuite abordé l'ensemble de la chaîne audio, en y explicitant le rôle et le fonctionnement de chacun de ses composants. L'objectif est de fournir une base technique objective au preneur de son.

Dans un second temps, le livre détaille un ensemble de techniques de prise de son et de mixage, insistant particulièrement sur les mécanismes généraux de la prise et sur l'écoute critique.

\begin{quote}
La partie dédiée à la pratique du mixage son n'est pas encore disponible en ligne.
\end{quote}

\hypertarget{uxe0-propos-de-lauteur}{%
\section{À propos de l'auteur}\label{uxe0-propos-de-lauteur}}

Jean-Loup Pecquais est formateur et consultant dans le monde de l'audio professionnel (FLUX:: Immersive, Whiti Audio, Arkalya). Il est plus particulièrement spécialisé dans les techniques de mixage sonore immersives. Il est diplômé de l'ENS Louis-Lumière en 2019.

\hypertarget{part-guxe9nuxe9ralituxe9s}{%
\part{Généralités}\label{part-guxe9nuxe9ralituxe9s}}

\hypertarget{quantifier-et-qualifier-le-son}{%
\chapter{Quantifier et qualifier le son}\label{quantifier-et-qualifier-le-son}}

Le son peut s'appréhender de plusieurs façons différentes. Particulièrement, sa description physique et psychoacoustique est très précieuse pour tous les praticiens du son. Il convient donc, afin de pouvoir proposer un dispositif cohérent de prise de son, de comprendre la physique élémentaire du son ainsi que d'être capable de le décrire efficacement.

\hypertarget{phuxe9nomuxe8ne-physique}{%
\section{Phénomène physique}\label{phuxe9nomuxe8ne-physique}}

\hypertarget{quelques-duxe9finitions}{%
\subsection{Quelques définitions}\label{quelques-duxe9finitions}}

Le son est une vibration mécanique d'un fluide. Dans le cadre de ce cours, nous ne considérerons que l'air comme médium de propagation. Cette onde cause une variation de la pression dans l'espace. Nous, les êtres humains, le percevons grâce à notre ouïe. Il s'agit donc, par définition, d'un phénomène ondulatoire et peut être caractérisé par un nombre d'oscillations par seconde, aussi appelé fréquence. On estime que notre espèce est sensible aux fréquences allant de 20 Hz (très grave) jusqu'à 20 000 Hz (très aigu).

On parlera d'\textbf{évènement sonore} pour parler généralement de phénomènes physiques produisant une onde sonore.

Les sons composés d'une seule fréquence se nomment \textbf{sons purs}. Cependant, de tels signaux n'existent pas dans la nature, et sont souvent utilisés afin de réaliser des mesures ou des tests psychoacoustiques.

\begin{center}\includegraphics{_main_files/figure-latex/unnamed-chunk-2-1} \end{center}

Dans notre environnement, les sons sont donc composés de plusieurs fréquences. La fréquence la plus grave d'un son est sa \textbf{fréquence fondamentale}. Les autres sont alors appelées \textbf{partiels}. Si ces partielles ont pour fréquence un multiple de la fréquence fondamentale, alors on les nomme \textbf{harmoniques}.

\begin{quote}
Plus généralement, on admettra que la composition fréquentielle, ou spectrale, de tout son peut être décomposée par une somme de sinusoïde. L'outil permettant de passer de la représentation temporelle d'un signal à sa représentation fréquentiel s'appelle la \textbf{transformée de Fourrier.}
\end{quote}

\begin{figure}

{\centering \includegraphics{_main_files/figure-latex/unnamed-chunk-3-3} 

}

\caption{Signal carré et visualisation de son spectre}\label{fig:unnamed-chunk-3}
\end{figure}

La fréquence fondamentale donne la \textbf{hauteur} du son (sa note en musique par exemple). Les partiels enrichissent cette fréquence fondamentale et créés le \textbf{timbre} d'un son. C'est en partie grâce au timbre que l'on peut reconnaître différents instruments de musiques jouant la même note.

Un son se caractérise également par l'évolution de son amplitude au cours du temps. On parle alors de son \textbf{enveloppe}. Un modèle courant d'enveloppe est l'ADSR : \emph{Attack}, \emph{Decay}, \emph{Sustain}, \emph{Release}, soit \emph{Attaque}, \emph{Décroissance}, \emph{Maintient} et \emph{Relâchement}.

\begin{figure}

{\centering \includegraphics[width=0.65\linewidth]{_resources/drawings/adsr} 

}

\caption{Exemple d'enveloppe ADSR}\label{fig:unnamed-chunk-4}
\end{figure}

Lorsque son temps et très bref, l'ensemble \emph{attaque} et \emph{décroissance} forme les \textbf{transitoires}. Cette partie du signal est responsable de la sensation percussive du son.

\hypertarget{relation-entre-temps-distance-et-fruxe9quence}{%
\subsection{Relation entre temps, distance et fréquence}\label{relation-entre-temps-distance-et-fruxe9quence}}

Il est important de garder à l'esprit que les notions de temps, de fréquence et de distance sont étroitement liées. Nous avons vu ci-dessus que tous les sons peuvent être décrits par une somme de sinusoïde. Leur fréquence la plus grave, dite fondamentale, permet de définir la \textbf{période}. La période est le temps que met un signal à répéter son motif oscillatoire (voir schémas 3.1 et 3.2). Le lien mathématique entre fréquence et période est très simple, car l'un est l'inverse de l'autre :

\[ f = \frac 1 T \]

Si nous étudions les fréquences extrêmes, audibles par notre ouïe, nous trouvons que pour \(f_{min} = 20 \,Hz\), sa période \(T_{f_{min}} = 50 \,ms\). Pour \(f_{max} = 20\,000 \,Hz\), \(T_{f_{max}} = 0.5 \,ms\).

Une onde sonore est également caractérisée par sa \textbf{célérité}. Celle-ci est constante dans un milieu donné. Dans l'air, à une température de \(15 \,°C\) et au niveau de la mer, sa célérité \(c\) est de \(340\,m.s^{-1}\). On admettra cette valeur pour réaliser l'ensemble de nos différents calculs.

Comme son unité l'indique, la célérité du son est homogène à une distance divisée par un temps, soit :

\[ c =\frac d t \]

Suivant cette formule, nous pouvons alors calculer la \textbf{longueur d'onde} correspondant à une fréquence. La longueur d'onde se note \(\lambda\).

\[ \lambda = cT \; \iff \; \lambda = \frac c f\]

Si nous étudions à nouveau les bornes minimale et maximale de notre audition, nous trouvons que \(\lambda_{f_{min}} = 17 \,m\) et \(\lambda_{f_{max}} = 17 \,mm\).

Nous pouvons également calculer le temps de propagation du son. En pratique, nous serons souvent intéressés par le temps de propagation séparant deux points dans l'espace (par exemple, le temps séparant deux microphones par rapport à un instrument).

\begin{figure}

{\centering \includegraphics[width=0.25\linewidth]{_resources/drawings/mic_dist} 

}

\caption{Distance entre deux microphones.}\label{fig:unnamed-chunk-5}
\end{figure}

\[ t = \frac {d_2-d_1}{c}\]

\hypertarget{perception-du-son}{%
\section{Perception du son}\label{perception-du-son}}

Nous avons abordé quelques notions de physique permettant de mieux caractériser le phénomène sonore. Comme indiqué au début de ce chapitre, le son peut également être discuté sous l'angle de notre ouïe, et donc, de notre perception. Cette branche de la science se nomme la psychoacoustique et cherche à étudier la façon dont nous percevons le son.

Notre corps, et a fortiori notre cerveau, sont des machines extrêmement complexes. Nous sommes équipés d'une multitude de capteurs permettant de sentir le contact d'une matière, des odeurs, d'entendre, de goûter, de voir, de positionner nos membres dans l'espace, de ressentir la douleur, etc. Pris indépendamment, chacun de ces sens est déjà un phénomène complexe à décrire, mais il existe en plus une grande interdépendance entre ceux-ci. Par exemple, l'interdépendance entre la vision et l'audition est à l'origine d'un certain nombre de mécanismes biaisant notre écoute.

Nous nous bornerons au fil de ce cours à quelques notions liées à l'ouïe et à son interdépendance à d'autre sens quand cela sera pertinent.

\hypertarget{spectre-timbre-et-vocabulaire}{%
\subsection{Spectre, timbre et vocabulaire}\label{spectre-timbre-et-vocabulaire}}

D'un point de vue perceptif, le spectre d'un évènement sonore est facilement remarquable. Il est, par contre, beaucoup plus difficile à qualifier. Il n'est pas rare de rencontrer les adjectifs ``chaud'', ``brillant'', ``rond'', ``aéré'', ``ouvert'', ``sombre'', voir d'autres encore plus ésotérique, pour tenter de communiquer la sensation ressentie à l'écoute de tel ou tel son.

Cette difficulté liée à l'absence de vocabulaire commun quant à la qualification le son emmène systématiquement la redéfinition de ce vocable en fonction de son interlocuteur. En effet, le mot ``rond'' ne signifiera pas forcément la même chose selon à qui on s'adresse. Une stratégie possible consiste à questionner son interlocuteur sur l'utilisation de ses adjectifs tout en cherchant à y associer des exemples sonores.

Nous pouvons tout de même nous essayer à cet exercice pour nous permettre d'avoir un vocabulaire commun au fil de ce cours. Vous aurez sans doute compris qu'il n'y aura, dans les termes employés, aucun critère absolu.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{_resources/drawings/spectre} 

}

\caption{Distance entre deux microphones.}\label{fig:unnamed-chunk-6}
\end{figure}

\textbf{Proposition d'association entre bandes de fréquences et sensation}.

\begin{itemize}
\tightlist
\item
  \textbf{20~Hz --- 80~Hz} : Subharmonique, sensation tripale
\item
  \textbf{80~Hz --- 160~Hz} : Grave, sensation d'assise
\item
  \textbf{160~Hz --- 380~Hz} : bas-médium, sensation de «~chaleur~», voir «~boueux~»
\item
  \textbf{380~Hz --- 1400~Hz} : Medium, sensation de «~boîte~» quand trop présent, sonne «~creux~» quand trop absent
\item
  \textbf{1400~Hz --- 3200~Hz} : Haut-medium : zone de sensibilité maximale de l'oreille.
\item
  \textbf{3200~Hz --- 8000~Hz} : Aigu, apporte de la précision voir de l'agressivité
\item
  \textbf{8000~Hz --- 20~000~Hz} : Air, apporte une sensation d'ouverture voir de finesse
\end{itemize}

Il est intéressant de former son oreille à reconnaître une plage de fréquence, ainsi que d'y associer son propre vocabulaire et une sensation. Les appellations proposées ci-dessus ne sont à prendre que comme guides et n'ont pas valeur de référence. Cela favorise une écoute critique et analytique.

\begin{quote}
Aussi, les fréquences graves ont un effet masquant sur les fréquences plus aiguës. Ce phénomène est dû au fonctionnement de notre oreille, et plus particulièrement de la cochlée.
\end{quote}

\hypertarget{pression-acoustique-niveau-sonore}{%
\subsection{Pression acoustique \& niveau sonore}\label{pression-acoustique-niveau-sonore}}

Nous l'avons abordé plus haut, lorsqu'une onde sonore se déplace dans l'air, on constate la variation de la pression atmosphérique en ce point. Dès lors, il est facile de corréler l'amplitude de la variation de la pression avec le niveau sonore entendu (ou mesuré).

L'unité du système international de la pression est le \textbf{pascal} (\textbf{Pa}). Or, il est très rare de parler de la pression acoustique en pascal, car la variation de cette pression exprimée en pascal ne correspond pas à ce que nous percevons. En d'autres termes, si la pression acoustique exprimée en pascal double, nous ne percevons pas un son deux fois plus fort.

Notre oreille fonctionne de façon logarithmique, et non linéairement, face à une variation de pression acoustique. C'est pour cela que l'on parle généralement de \textbf{niveau de pression acoustique}, où \textbf{SPL} (pour Sound Pressure Level en anglais), qui s'exprimera en \textbf{décibel}. La relation entre la variation de pression et le niveau de pression acoustique se fait grâce à la relation :

\[L_p = 20\,\log_{10}\Big(\frac{p_{eff}}{p_{ref}}\Big) \qquad p_{ref} = 20\mu Pa\]

\begin{quote}
Si la pression acoustique double, on observe une augmentation du niveau sonore de 6 dB SPL. Lorsqu'on ressent un doublement du niveau sonore, on observe une augmentation de 20 dB.

La pression acoustique est divisée par deux à chaque doublement de distance.
\end{quote}

La question se complexifie lorsque l'on rajoute la dimension fréquentielle à la question de la perception du niveau sonore. En effet, nous percevons des niveaux sonores différents pour différentes fréquences pourtant émises au même niveau de pression acoustique. Pour inclure cette dépendance fréquentielle, nous avons mis en place une unité de mesure : la \textbf{sonie} ou \textbf{bruyance} (\textbf{loudness} en anglais). Il est donc possible ensuite de définir des courbes d'\textbf{isosonie}, c'est-à-dire des courbes indiquant un niveau sonore de perception égale en fonction de la fréquence et du niveau de pression acoustique.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{_resources/diagrams/Courbes_isosonie} 

}

\caption{Courbes d'isosonie, aussi dites de Fletcher-Munson}\label{fig:unnamed-chunk-7}
\end{figure}

Que conclure de cet abaque ?

\begin{itemize}
\tightlist
\item
  Notre oreille ne perçoit pas les fréquences de manière égale.
\item
  Notre zone de sensibilité maximale se situe dans l'aigu (3k-4k Hz).
\item
  Notre perception d'un matériau sonore en fonction du niveau auquel nous l'écoutons !
\end{itemize}

\hypertarget{positionnement-dans-lespace}{%
\subsection{Positionnement dans l'espace}\label{positionnement-dans-lespace}}

Notre système auditif nous permet de situer l'émission d'un son dans l'espace. Cette capacité de localisation repose sur un ensemble de facteurs étroitement liés entre eux.

On qualifie notre écoute de \textbf{binaurale}, littéralement, écouter avec deux oreilles. La présence de deux ``capteurs de pression'' (oserait-on parler de microphones ?) sur les faces latérales de notre crâne et un premier élément expliquant notre capacité de localisation du son.

En effet, l'espacement de nos oreilles (en moyenne 15 cm), créer un décalage temporel entre nos deux canaux d'écoutes. Ce léger retard entendu d'un côté ou de l'autre nous permettra de placer un son plutôt à gauche ou plutôt à notre droite. On appelle cet écart de temps \textbf{différence de temps interaural}, ou \textbf{ITD} (interaural time difference en anglais) et se note \(\Delta t\).

On pourrait d'ailleurs, grâce aux formules de ce début de chapitre, calculer le retard maximal moyen entre nos deux oreilles.

\[\Delta t_{max} = \frac d c = \frac {0,15}{340} = 0.4 \> ms\]

\begin{figure}

{\centering \includegraphics{_resources/drawings/delta_t} 

}

\caption{Illustration de l'ITD}\label{fig:unnamed-chunk-8}
\end{figure}

Si nos oreilles sont espacées de quelques centimètres, notre tête les séparant représente un obstacle acoustique non négligeable. De plus, les pavillons des oreilles imposent également une certaine directivité à notre écoute. En première approximation, on pourra donc considérer que l'ensemble formé par la tête et les pavillons implique une atténuation linéaire des ondes sonores, elle-même fonction de l'angle d'incidence. On appelle cette différence de niveau \textbf{différence d'intensité interaural}, ou \textbf{ILD} (interaural level difference) et se note \(\Delta i\). On considère que si la différence de niveau de pression acoustique entre les deux oreilles est supérieure à 20 dB, on entendra l'évènement sonore complètement latéralisé.

\begin{quote}
L'ombre acoustique que représentent la tête et le pavillon n'est en réalité pas du tout linéaire en fréquence. La modification du timbre induite par ce système n'est pas perçue par notre cerveau comme une information de couleur, mais bien comme une information de spatialisation. Ainsi, selon l'angle d'incidence de l'évènement sonore, son spectre sera filtré d'une certaine manière qui permettra à notre cerveau de le positionner dans l'espace. La réponse en fréquence d'une tête se nomme \textbf{HRTF} (\textbf{Head Related Transfer Function}).
\end{quote}

Enfin, nous sommes également capables de déterminer la distance d'un évènement sonore. La plupart des paramètres permettant d'évaluer cette distance sont relatifs. Cela signifie que l'évènement doit être comparé à un autre pour pouvoir le repositionner dans l'espace. On pourra alors comparer :

\begin{itemize}
\tightlist
\item
  Leurs niveaux sonores : un évènement sonore plus fort paraît plus proche
\item
  Leurs timbres : l'absorption de l'air aura pour effet de diminuer les fréquences aiguës
\item
  La sensation de réverbération associée : plus le signal de l'évènement sonore semblera solliciter la réponse acoustique du lieu, plus celui-ci semblera fort.
\item
  Le temps d'arrivée des premières réflexions : le son direct d'un évènement sonore lointain arrivera quasi simultanément avec ses premières réflexions. Le son direct d'un évènement sonore proche arrivera avant ses premières réflexions.
\end{itemize}

Le chapitre suivant traitera des notions d'acoustique élémentaire ainsi que de la réverbération.

\hypertarget{acoustique-des-salles}{%
\chapter{Acoustique des salles}\label{acoustique-des-salles}}

Tout environnement, sollicité par un évènement sonore, produit une réponse acoustique. Cette réponse acoustique est appelée réverbération. Elle est caractéristique d'un lieu et peut, dans certains cas, être une alliée précieuse dans notre travail. Dans d'autres, elle est source de problèmes et complexifie grandement notre travail d'écoute analytique.

\hypertarget{guxe9nuxe9ralituxe9s}{%
\section{Généralités}\label{guxe9nuxe9ralituxe9s}}

\hypertarget{la-ruxe9verbuxe9ration}{%
\subsection{La réverbération}\label{la-ruxe9verbuxe9ration}}

L'acoustique d'une salle est généralement décrite en deux temps : le temps des premières réflexions et le temps du champ diffus.

\begin{figure}

{\centering \includegraphics{_resources/drawings/reverb} 

}

\caption{Schéma d'une réponse impulsionnelle de réverbération.}\label{fig:unnamed-chunk-9}
\end{figure}

Les premières réflexions sont les premiers rebonds d'une onde sonore sur les parois d'une salle et sont caractéristiques de la signature acoustique du lieu. Ces rebonds reviennent à l'auditeur avec un certain temps. Ce retard se nomme souvent «~pré-délai~» dans les moteurs de réverbération artificiels. Ce prédélai est fonction de deux paramètres~:

\begin{itemize}
\tightlist
\item
  la taille de la pièce~; plus la pièce est petite, plus les premières réflexions reviendront à l'auditeur rapidement.
\item
  les positions de la source sonore et de l'auditeur~; plus l'auditeur est proche de la source, plus les premières réflexions arriveront après le son direct, plus l'auditeur est loin de la source, plus les premières réflexions arriveront en même temps que le son direct.
\end{itemize}

Lorsque les premières réflexions elles-mêmes auront rebondi plusieurs fois sur les parois du lieu, le phénomène d'écho des premières réflexions va se muer en champs diffus, par nature plus dense. La longueur du champ diffus se mesure grâce au RT60. Cette méthode de mesure propose de regarder le temps que met la réverbération à perdre 60~dB. Ce temps permettra ensuite de donner une longueur de réverbération.

\hypertarget{calcul-du-temps-de-ruxe9verbuxe9ration}{%
\subsection{Calcul du temps de réverbération}\label{calcul-du-temps-de-ruxe9verbuxe9ration}}

L'équation de Sabine permet de calculer le temps de réverbération d'une salle à partir de son volume et du coefficient d'absorption de ses matériaux.

\[RT_{60} = 0.1611 \times \frac{V}{\sum_{i=0}^{k} S_i.\alpha_i}\]

\(V\) s'exprime en \(m^3\) et \(S\) en \(m^2\). \(\alpha\) est le coefficient d'absorption du matériau, en sabins. Ce coefficient est compris entre 0 et 1, plus il est important plus le matériau est absorbant.

En guise d'exemple sur l'utilisation de la formule ci-dessus, prenons le cas d'une pièce de \(25\,m^2\) (\(5\,m\) par \(5\,m\)) et de \(2.40\,m\) de hauteur. Nous considérons que le sol est en parquet et les murs en plâtre. Nous avons donc \(25\,m^2\) de parquet et \(4\times(5\times2.4)=48\,m^2\). On trouve sur les sites de fabricant de matériaux que le plâtre peint a un coefficient d'absorption de 0.05 sabins et le bois un coefficient de 0.15 sabins. Notre calcul final.

\[RT_{60} = 0.1611 \times \frac{25 \times 2.4}{25\times0.15+48\times0.05} \approx 1.57\,s\]

On peut dès lors calculer la \textbf{distance critique}, distance à partir de laquelle on entendra autant un évènement sonore que la réponse acoustique de la salle à son stimulus.

\[d_c \approx 0.057 \times \sqrt{\frac{V}{RT60}}\]

Dans notre exemple \(d_c \approx 0.35\,m\).

Il est souvent considéré que la taille de la pièce joue un rôle déterminant sur la longueur de réverbération. L'équation de Sabine indique bien que le coefficient d'absorption des matériaux y joue un rôle beaucoup plus important. Le modèle de réverbération de l'IRCAM va jusqu'à complètement décorréler la taille de la pièce simulée du temps de réverbération. Au final, la taille de l'espace joue davantage sur la structure temporelle des échos, et donc, principalement sur les premières réflexions.

\hypertarget{limite-de-luxe9quation-de-sabine}{%
\subsection{Limite de l'équation de Sabine}\label{limite-de-luxe9quation-de-sabine}}

Il convient d'observer plusieurs réserves quant à l'utilisation de l'équation de Sabine. Premièrement, elle ne tient pas compte de l'aspect fréquentiel lié à l'absorption des matériaux. En effet, le temps de réverbération des graves est presque toujours plus long que celui des aigus. Afin de contourner ce problème, on pourra chercher des coefficients d'absorption tenant compte de la fréquence et ainsi résoudre l'équation de Sabine pour certaines plages fréquentielles.

L'équation de Sabine pose également problème pour de petits espaces (régie d'écoute par exemple) en prédisant un temps de réverbération trop long. Dans ce cas, l'équation d'Eyring est plus adaptée.

\[RT_{60} = -0.1611 \times \frac{V}{\sum_{i=0}^{k} S_i.\ln(1-\alpha_i)}\]

\begin{quote}
L'équation d'Eyring n'améliore pas non plus la problématique fréquentielle.
\end{quote}

\hypertarget{le-phuxe9nomuxe8ne-donde-stationnaire}{%
\subsection{Le phénomène d'onde stationnaire}\label{le-phuxe9nomuxe8ne-donde-stationnaire}}

La plupart des pièces de vie sont des salles rectangulaires. Dans ce cas, les surfaces sont toutes parallèles. Ce type de salle est particulièrement propice à l'apparition d'ondes stationnaires. Une onde stationnaire est un phénomène acoustique provoquant l'augmentation de volume de certaines fréquences (ventre) et la disparition d'autres (nœuds).

Nous aborderons ici ce phénomène sous l'angle de l'acoustique des salles, mais il est applicable dans d'autres situations, comme la vibration d'une corde par exemple.

\url{_resources/gif/Standing_wave_2.gif}

Il est possible de calculer les fréquences d'un mode grâce aux formules vues au chapitre précédent :

\[f(n) = \frac{c}{2L}.n\]
où \(c=340\,m.s^{-1}\), \(L\) est la longueur considérée de la pièce. Pour \(n=1\) on trouve le \textbf{mode propre}. Pour \(n>1\) on trouvera tous les \textbf{modes harmoniques}.

Étudions la fréquence du mode propre pour deux cas théoriques : une salle de 16 m² (4x4) et une autre de 49 m² (7x7). On trouvera donc :

\[f(1)_{L=4m} = 42.5 \,Hz \>\>\>\> f(1)_{L=7m} = 24 \,Hz\]

On en déduit donc que, plus la pièce est grande, plus la fréquence des modes propres sera grave. Il convient également de considérer la distance de chaque surface parallèle, car les pièces sont rarement cubiques. Cela implique donc la présence de trois modes propres, plus leurs modes harmoniques, pour une seule et même salle.

\hypertarget{premiuxe8res-ruxe9flexions-et-filtre-en-peigne}{%
\section{Premières réflexions et filtre en peigne}\label{premiuxe8res-ruxe9flexions-et-filtre-en-peigne}}

Nous avons vu que la réponse acoustique, ou réverbération, d'une salle se décompose généralement en deux parties, la première étant les premières réflexions. Ces premières réflexions sont donc, comme leur nom l'indique, les premiers rebonds que nous entendons suite à un évènement sonore.

Dans de petites pièces, les premières réflexions peuvent être entendues si proche du son direct que cela génère un type de filtrage bien particulier appelé \textbf{filtre en peigne}.

\begin{center}\includegraphics{_main_files/figure-latex/unnamed-chunk-11-1} \end{center}

Toujours en utilisant les formules définies au premier chapitre, on établit la relation suivante :

\[ fc = \frac 1{2t} = \frac c{2d} \]

Où \(fc\) correspond à la fréquence d'annulation la plus grave du filtre en peigne. Les autres fréquences se calculent grâce à la relation \(f(n) = fc*n\). Le phénomène de filtre en peigne est donc également harmonique.

Ainsi, on peut calculer les filtres en peignes présents au point d'écoute d'une régie de mixage ou de prise de son grâce à la mesure du chemin des premières réflexions.

\begin{figure}

{\centering \includegraphics{_resources/drawings/roomPr} 

}

\caption{Ensemble des premières reflexions entendues par une oreille pour une enceinte (hors plafond et plancher/bureau).}\label{fig:unnamed-chunk-12}
\end{figure}

\begin{quote}
La réflexion du son sur une paroi est tout à fait comparable à de l'optique géométrique. Une onde sonore arrivant avec un angle d'incidence \(\alpha\) sur une surface sera réfléchie avec le même angle. Ainsi, il est souvent conseillé d'utiliser un miroir lorsque l'on positionne des traitements acoustiques. Lorsque la personne assise au point d'écoute voit une enceinte dans un miroir placé sur un mur, on sait alors qu'il faudra placer le panneau à la place du miroir.
\end{quote}

On se rend donc compte que l'influence des filtres en peigne générés par les premières réflexions est très importante. Ce phénomène à lui seul explique l'intérêt d'une grande régie d'écoute. En effet, plus une pièce est grande, plus l'écart de temps entre le son direct et les premières réflexions est important. Cela implique deux choses :

\begin{itemize}
\tightlist
\item
  Notre cerveau favorisera le son direct plus facilement (effet de précédence)
\item
  À partir d'une certaine taille, l'effet du filtre en peigne se mue en information d'acoustique pour notre cerveau. Au-delà de 40 ms (trajet d'une première réflexion d'environ 14 m), l'écart entre le son direct et les premières réflexions est tel que nous entendons un écho (effet Haas).
\end{itemize}

Afin de réduire au maximum les effets des filtres en peignes, il est recommandé de placer des traitements aux points de réflexion critique par rapport à la position d'écoute (voir schéma ci-dessus).

\begin{center}\includegraphics{_main_files/figure-latex/unnamed-chunk-13-1} \end{center}

\hypertarget{traitement-acoustique}{%
\section{Traitement acoustique}\label{traitement-acoustique}}

Grâce aux différents points abordés ci-dessus, nous avons maintenant bien l'idée que l'acoustique d'un lieu est un des facteurs les plus déterminants sur le rendu sonore. Mais c'est aussi celui sur lequel il est plus difficile et technique d'intervenir.

On favorisera au maximum une architecture optimisée pour l'acoustique. Dans ce but, il convient de n'avoir aucune surface parallèle, cela permettant de grandement limiter l'apparition d'ondes stationnaires. On choisira également des matériaux avec des propriétés acoustiques intéressantes (plâtre et carrelage sont à proscrire, au profit du bois par exemple).

On se posera ensuite la question des endroits de la pièce les plus propices pour y positionner un évènement sonore (enceinte, musicien, etc.). On cherchera donc un point où la contribution des différents modes semble équilibrée. Pour cela, il suffit de se munir d'une enceinte et d'y diffuser une musique ou un signal test qui nous est familier. En déplaçant l'enceinte, on pourra évaluer la contribution acoustique de la pièce en différents points.

Une fois ces considérations prises en compte, on pourra alors aborder le traitement de l'acoustique.

\begin{quote}
Il ne faut pas confondre isolation acoustique et traitement acoustique. Dans le premier cas, on chercher a limiter la contribution sonore d'un lieu sur son environnement, dans l'autre on cherche à améliorer la propagation du son dans un espace donné. Une isolation acoustique satisfaisante nécessite de lourds travaux, voire l'aménagement d'une ``boîte dans une boîte''. Ces notions d'acoustiques dépassent le cadre de ce cours.
\end{quote}

\hypertarget{les-types-de-traitements}{%
\subsection{Les types de traitements}\label{les-types-de-traitements}}

On trouve, en général, deux types de traitements~:

\begin{itemize}
\tightlist
\item
  Les absorbeurs, qui réduisent l'énergie d'une onde sonore à son impact.
\item
  Les diffuseurs, qui répartissent l'énergie d'une onde sonore dans l'espace.
\end{itemize}

Dans un lieu où la quantité de réverbération est jugée trop importante, on utilisera des absorbeurs. À l'inverse, dans un lieu où l'on souhaite préserver la quantité de réverbération, mais en évitant les phénomènes de modes ou de filtre en peignes, on utilisera des diffuseurs.

Dans de petits lieux, l'usage de diffuseur semble contre-productif, la priorité étant d'absorber au maximum les premières réflexions, celle-ci arrivant très rapidement après l'émission du son direct.

\hypertarget{considuxe9ration-dacoustique-pour-le-travail-de-son}{%
\subsection{Considération d'acoustique pour le travail de son}\label{considuxe9ration-dacoustique-pour-le-travail-de-son}}

Il est vivement recommandé d'installer un studio, de prise de son ou de monitoring, dans un lieu plutôt grand. En effet, plus le lieu est grand, plus il sera facile de positionner un point de prise de son ou d'écoute suffisamment éloigné des parois afin de minimiser l'influence des premières réflexions. Aussi, plus le lieu est grand, plus l'espace y sera suffisant pour installer des traitements acoustiques. Certains types de traitements, comme les basstraps, peuvent prendre une place bien trop importante pour être installée dans des pièces de dimension habituelle (chambres, bureau, etc.). On se rappellera aussi de choisir une pièce de travail avec le minimum de surface parallèle, afin de limiter les ondes stationnaires.

En ce qui concerne les traitements en eux-mêmes, il est vivement recommandé de traiter en priorité le bas du spectre. L'ajout de basstrap est donc prioritaire sur le reste des traitements. Plus la longueur d'onde à traiter est grande (donc la fréquence grave), plus la taille des matériaux devra être importante. On retrouve donc le point abordé précédemment~: traiter une pièce correctement, demande un certain espace. Par ailleurs, il est important que les traitements appliqués à un lieu soient linéaires en fréquence, c'est-à-dire qu'il ne se concentre pas sur une seule zone du spectre. Cela arrive souvent avec les kits de mousses peu onéreux, mais n'ayant une réelle efficacité que dans les médiums et hautes fréquences.

Pour une régie d'écoute, on sera tenté de privilégier des traitements d'absorption. En effet, une réverbération trop longue dans une régie de monitoring risque fort de fausser certaines prises de décisions (distance des microphones à la source, quantité de réverbération, etc.). À l'inverse, une pièce avec un temps de réverbération trop court pourra créer un sentiment d'inconfort, voire de malaise.

Pour une salle de prise de son, l'idéal est de disposer d'un grand espace avec un traitement acoustique principalement basé sur de la diffusion, pour ensuite disposer de traitements absorbants amovibles permettant de sculpter le rendu acoustique en fonction de la prise de son à réaliser. Pour des petits lieux (- de 25 m²), on cherchera à absorber au maximum afin de limiter les effets de filtre en peigne.

\hypertarget{notions-uxe9luxe9mentaires-duxe9lectronique}{%
\chapter{Notions élémentaires d'électronique}\label{notions-uxe9luxe9mentaires-duxe9lectronique}}

Les chapitres précédents nous ont permis d'aborder un certain nombre de notions fondamentales sur le son ainsi que sur l'acoustique des salles. Nous allons maintenant aborder quelques notions d'électricité et d'électronique. Le but n'est pas de savoir lire un schéma électronique, ou de comprendre comment réaliser tel ou tel circuit, mais bien d'aborder les quelques notions indispensables pour le travail du son.

Durant tout son trajet dans le milieu analogique, le signal sonore est représenté par un courant électrique. Il est donc régi par les mêmes règles que n'importe quel autre courant, même s'il possède une certaine spécificité, comme son oscillation. Un courant électrique se caractérise par le déplacement d'électrons dans un matériau conducteur (le métal par exemple). Un matériau, comme le plastique, qui ne permet pas aux électrons de se déplacer, est qualifié d'\textbf{isolant}.

\begin{quote}
Les électrons font partie des composants de l'atome. Ils sont chargés négativement et se déplacent donc dans le sens inverse du courant.
\end{quote}

\hypertarget{les-grandeurs-physiques}{%
\section{Les grandeurs physiques}\label{les-grandeurs-physiques}}

Commençons par aborder les grandeurs physiques liées à l'électricité.

\hypertarget{lintensituxe9}{%
\subsection{L'intensité}\label{lintensituxe9}}

L'intensité électrique, notée \textbf{I} et exprimée en \textbf{Ampère (A)}, est une grandeur permettant de mesurer le débit du courant électrique. Ceci est parfaitement analogue à un débit d'eau. Si un robinet est faiblement ouvert, l'écoulement de l'eau sera faible, s'il est complètement ouvert, le débit sera fort.

\hypertarget{la-tension}{%
\subsection{La tension}\label{la-tension}}

La tension, généralement notée \textbf{U} et exprimée en \textbf{Volt (V)}, désigne une différence de potentiel entre deux points d'un circuit. Imaginons deux réservoirs d'eau, remplis d'un volume différent et connectés par une valve. Dans ce cas, la différence de potentiel serait la différence du volume d'eau entre les deux réservoirs. En d'autres termes, s'il n'y a pas de tension, il n'y a pas de débit.

\begin{quote}
On choisit, en général, la masse, valant zéro volt, comme point de référence.
\end{quote}

Dans le cas de l'audio, la tension électrique du signal sonore est homologue à la variation de pression.

Tout comme la pression acoustique, il est possible de rendre compte d'une variation de tension électrique à un niveau sonore en décibel. Le relation liant la tension et le niveau est :

\[ L_{dB} = 20 \, log (\frac{U}{U_{ref}}) \]

Il existe plusieurs valeurs pour U\_\{ref\}, donnant lieu à différentes unités de mesures :

\begin{itemize}
\tightlist
\item
  \textbf{dBm}, définie à l'apparition du téléphone, propose \(U_{ref} = 0.775 V\) pour une impédance de \(600 \omega\). Cette impédance correspond à celle des lignes téléphoniques.
\item
  \textbf{dBu} / \textbf{dBv}, qui ne tient plus compte de la charge d'impédance, \(U_{ref} = 0.775 V\).
\item
  \textbf{dBV}, où \(U_{ref} = 1 V\)
\end{itemize}

\begin{quote}
Lorsque la tension double, le niveau augmente de six décibels. Lorsque la tension est multiplié par dix, le niveau augmente de vingt décibels.
\end{quote}

On peut également définir l'augmentation du niveau sonore par rapport à la puissance du signal. On admet que :

\[ P = \frac{U^2}{Z} \, U = \sqrt{P \times Z} \]

Où \(P\) est la puissance. En remplaçant dans l'équation précédente, on trouve :

\[ L_{dB} = 20 \, log (\frac{\sqrt{P}}{\sqrt{P_{ref}}}) \> = 10 \, log (\frac{P}{P_{ref}}) \]

\begin{quote}
Lorsque la puissance double, le niveau augmente de trois décibels. Lorsque la puissance est multiplié par dix, le niveau augmente de dix décibels.
\end{quote}

On utilisant la loi d'ohm (voir ci-dessous) et la relation entre la puissance, la tension et l'impédance, on trouve également que :

\[ P = U \times I \]

\hypertarget{limpuxe9dance}{%
\subsection{L'impédance}\label{limpuxe9dance}}

Nous connaissons, en général, la \textbf{loi d'Ohm}. Celle-ci permet de donner une relation entre l'intensité du courant et sa tension, aux bornes d'un composant d'un circuit (aussi appelé dipôle).

\[ U = R \times I \]

Où \(R\) est la résistance du dipôle. Elle traduit la facilité d'un courant à se déplacer dans le dipôle. Pour reprendre les analogies ci-dessus, la résistance correspondrait à une valve. À tension constante, si la résistance tend vers zéro, le débit est très important. Si la résistance tend vers l'infini, le débit sera très faible. Si elle est nulle, alors nous sommes dans le cas d'un court-circuit (interrupteur fermé). Si elle est infinie, cela traduit une absence de connexion entre deux points d'un circuit (interrupteur ouvert). L'unité de cette résistance est l'\textbf{ohm}.

L'impédance traduit elle aussi l'opposition d'un circuit au passage d'un courant électrique, mais dans le cas d'une \textbf{tension oscillante}. Dès lors, l'impédance englobe les effets de résistance, de capacitance et d'inductance (voir ci-dessus).

\hypertarget{les-composants-uxe9lectroniques}{%
\section{Les composants électroniques}\label{les-composants-uxe9lectroniques}}

\hypertarget{les-composants-passifs}{%
\subsection{Les composants passifs}\label{les-composants-passifs}}

\includegraphics[width=0.25\linewidth]{_resources/diagrams/resistor} \includegraphics[width=0.25\linewidth]{_resources/diagrams/resistor_sym}

Étudions maintenant les composants électroniques les plus communs. Nous avons en premier les \textbf{résistances}. Ce sont des dipôles purement résistifs. Leur valeur s'exprime en \textbf{ohm}. Une résistance s'oppose donc au passage du courant. Pour rappel, la tension a ses bornes est \(U = R \times i\).

\begin{figure}

{\centering \includegraphics[width=0.25\linewidth]{_resources/diagrams/capa} \includegraphics[width=0.25\linewidth]{_resources/diagrams/capa_sym} 

}

\caption{Représentation d'un condensateur et de son symbole}\label{fig:unnamed-chunk-15}
\end{figure}

Viennent ensuite les \textbf{condensateurs}. Ils sont constitués de matériaux conducteurs séparés par une couche isolante. La relation entre tension et intensité à ses bornes en régime oscillant est :

\[ U = Z_c \times I \]

Où \(Z_c\) est l'impédance d'un condensateur idéal. Nous pouvons ici la même analyse que plus haut, quand \(Z_c\) tend vers l'infini le courant ne passe plus, quand \(Z_c\) tend vers 0, le débit est important. L'impédance d'un condensateur est fonction de sa \textbf{capacité} (noté \textbf{C}, et s'exprime en \textbf{farads}).

\[ Z_c = \frac{1}{jC\omega} \> = 2 \pi \, f\]

Si la fréquence \(f\) tend vers l'infini, \(Z_c\) tend vers zéro, si la fréquence tend vers zéro, \(Z_c\) tend vers l'infini. On constate donc que l'impédance d'un condensateur varie en fonction de sa fréquence. On peut assimiler un condensateur à un interrupteur ouvert en basse fréquence et à un interrupteur fermé en haute fréquence.

\begin{figure}

{\centering \includegraphics[width=0.25\linewidth]{_resources/diagrams/inductor_sym} 

}

\caption{Symbole d'une bobine}\label{fig:unnamed-chunk-16}
\end{figure}

Terminons sur les bobines. Ces composants sont constitués d'un enroulement de câble en cuivre et possède une \textbf{inductance} notée \textbf{L} et s'exprimant en \textbf{henrys}. Étudions à nouveau la relation entre tension et intensité, aux bornes d'une bobine :

\[ U = Z_L \times I \]

Où \(Z_L\) est l'impédance d'une bobine idéale. Cette impédance se calcule grâce à la relation suivante :

\[ Z_L = j\omega L = 2 \pi \, f \]

Si la fréquence \(f\) tend vers l'infini, \(Z_L\) tend vers l'infini. Si \(f\) tend vers zéro, alors \(Z_L\) tend vers zéro. On observe donc le comportement inverse du condensateur. Une bobine se comporte comme un court-circuit en basse fréquence et comme un interrupteur ouvert en haut fréquence.

\begin{quote}
On admet j comme un outil mathématique permettant de simplifier certaines écritures et certains calculs. On l'appelle le nombre complexe, tel que \(j^2 = -1\). Dans nos applications, sa présence dans les relations des impédances de condensateur et de bobine implique un déphasage de \(-\frac{\pi}{2}\) pour un condensateur, et, de \(\frac{\pi}{2}\) pour une bobine.
\end{quote}

L'association de résistances, de condensateurs et de bobines donne des circuits RL, RC où RLC, permettant de réaliser des \textbf{opérations de filtrage} sur le signal.

\hypertarget{tubes-semi-conducteurs}{%
\subsection{Tubes \& semi-conducteurs}\label{tubes-semi-conducteurs}}

\begin{figure}

{\centering \includegraphics[width=0.25\linewidth]{_resources/bitmap/elec/tube} \includegraphics[width=0.25\linewidth]{_resources/bitmap/elec/transistor} \includegraphics[width=0.25\linewidth]{_resources/bitmap/elec/ic} 

}

\caption{Tubes, transistor et circuits intégrés}\label{fig:unnamed-chunk-17}
\end{figure}

Les \textbf{tubes}, tubes à vide, ou parfois, lampes, sont historiquement les premiers composants permettant d'amplifier le signal, contre une certaine tension d'alimentation. On les retrouve donc dans les préamplificateurs, égaliseurs, compresseurs, et autres amplificateurs jusque dans les années soixante. Ils sont alors progressivement remplacés par les \textbf{transistors}, composants appelés \textbf{semi-conducteurs}. Ces transistors permettent de réaliser la même amplification du signal qu'une lampe, mais sont beaucoup plus petits et demandent aussi moins de puissance électrique pour réaliser le même facteur d'amplification (aussi appelé \textbf{gain}). Peu de temps après la mise au point des transistors, les \textbf{circuits intégrés} sont inventés. Ces petites boîtes renferment plusieurs transistors, et peuvent également servir à l'amplification de signaux.

Il est très important de savoir que l'invention du transistor et des circuits intégrés est sans doute l'avancée technologique la plus importante du siècle dernier. Elle a permis le développement exponentiel de l'industrie informatique grâce à la miniaturisation des composants.

L'utilisation de tubes, de transistors ou de circuits intégrés au sein des machines audio, est souvent associée à une certaine «~couleur~». Il y aurait donc un son des tubes, un son des transistors et un son des circuits intégrés. Les différences entre ces dipôles apparaissent principalement dans les zones de \textbf{non-linéarité} des composants, typiquement dans leur zone de saturation. La saturation apparaît lorsque la tension du signal amplifiée dépasse la tension d'alimentation du composant responsable de cette amplification. On observe alors l'apparition de certaines harmoniques. La distribution des harmoniques générés est différente en fonction du dipôle utilisé.

Il est compliqué d'attribuer une couleur sonore particulière à un composant. En effet, le comportement d'un composant est fondamentalement conditionné par la topologie du circuit dans lequel il est utilisé ainsi que par les autres composants qui l'entourent. Il convient donc, à l'humble avis de l'auteur, d'être relativement prudent sur des expressions telles que «~son des tubes~» ou «~son des transistors~», particulièrement quand il s'agit de dire que l'une des technologies «~sonnerait mieux~» que l'autre. L'histoire de l'électronique musicale regorge d'exemples et de contre-exemples pour chacune de ces affirmations.

\hypertarget{linfluence-de-limpuxe9dance-entre-diffuxe9rents-appareils.}{%
\section{L'influence de l'impédance entre différents appareils.}\label{linfluence-de-limpuxe9dance-entre-diffuxe9rents-appareils.}}

Sur la fiche technique des appareils, on trouve des valeurs pour son impédance d'entrée et son impédance de sortie. Imaginons que nous connections un appareil A dans un appareil B. En pratique, nous faisons en sorte que l'impédance de sortie de l'appareil A soit dix fois inférieure à l'impédance d'entrée de l'appareil B. À partir du moment où ces impédances sont proches, voire que l'impédance de sortie de A soit plus grande que celle d'entrer de B, nous allons atténuer le signal transitant entre les deux appareils. Étudions de plus près ce phénomène.

Soit le schéma électronique ci-dessous. On appelle \(U_{out}\) la tension de sortie de l'appareil A et \(Z_{out}\) son impédance de sortie. De façon similaire, on appelle \(U_{in}\) la tension d'entré de l'appareil B et \(Z_{in}\) son impédance d'entré.

\begin{center}\includegraphics{_resources/diagrams/impedance} \end{center}

Dans ce circuit, \(Z_{eq} = Z_{in} + Z_{out}\) et \(U_{out} = Z_{eq} \times i\). Alors, \(i = \frac{U_{out}}{Z_{eq}} = \frac{U_{out}}{Z_{in} + Z_{out}}\). Toujours grâce au circuit ci-dessus, on peut dire que \(U_{in} = Z_{in} \times I\). En remplaçant dans l'expression précédente on trouve : \(\frac{U_{in}}{Z_{in}} = \frac{U_{out}}{Z_{in} + Z_{out}}\)

\[ \frac{U_{in}}{U_{out}} = \frac{Z_{in}}{Z_{in} + Z_{out}} = \frac{1}{1+\frac{Z_{out}}{Z_{in}}} \]

Dès lors, si \(Z_{in}\) est très grand devant \(Z_{out}\), alors \(U_{in}\) tend vers \(U_{out}\). Si \(Z_{out}\) est très grand devant \(Z_{in}\), alors \(U_{in}\) tend vers \(0\).

Cela nous amène à démontrer l'affirmation ci-dessus. Maintenant, nous savons que dans un circuit, l'impédance varie en fonction de la fréquence. Dès lors, une mauvaise adaptation d'impédance ne fera pas que diminuer l'amplitude du signal, mais filtrera aussi une partie de spectre, généralement les hautes fréquences.

\begin{quote}
On considère aussi l'adaptation d'\textbf{impédance en tension}. Lorsque que nous considérons la \textbf{puissance} les relations sont différentes (cf section sur les hautparleurs).
\end{quote}

\hypertarget{description-dune-production-musicale-type}{%
\chapter{Description d'une production musicale type}\label{description-dune-production-musicale-type}}

Afin de comprendre quels vont être les enjeux du preneur de son, il convient de comprendre dans quel contexte il intervient. Certes, il est le premier métier du son à rentrer en scène, mais l'œuvre à enregistrer a déjà très probablement eu une longue vie. Elle a été composée, arrangée, peut-être même déjà interprétée au cours de concerts.

À ce stade, le preneur de son aura un regard neuf sur la matière. Il aura donc le potentiel de permettre aux créateurs de prendre du recul sur leur travail. Il convient d'ailleurs de rappeler qu'un preneur de son, aussi talentueux et créatif soit il, est un \textbf{assistant de création}. Cela signifie qu'il met à disposition une compétence technique à un d'artiste pour lui permettre d'avancer sur son projet. Cela implique également que celui ou celle qui a le mot final sur le choix des orientations esthétiques est l'artiste en question. Il convient donc, en tant que preneur de son, d'être force de proposition, tout en sachant respecter le choix (qu'ils soient bons ou mauvais) des artistes.

D'un point de vue sonore, le travail de prise de son est absolument critique. Ce sera à ce moment que va se jouer la majorité des choix esthétiques. Il convient donc de réunir les conditions optimales pour~:

\begin{itemize}
\tightlist
\item
  offrir aux musiciens et musiciennes la chance de donner leur meilleure interprétation possible
\item
  réaliser une prise de son en adéquation avec l'orientation esthétique du projet
\end{itemize}

La plupart des choix faits à la prise de son ne pourront pas être renégociés a posteriori. Il convient donc de mettre d'accord les artistes, le directeur artistique et le preneur de son sur les moyens à mettre en œuvre.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{_resources/diagrams/productionSonore} 

}

\caption{Entonnoir de la production musicale}\label{fig:unnamed-chunk-19}
\end{figure}

\hypertarget{les-acteurs-de-la-ruxe9alisation-dune-ux153uvre-enregistruxe9e}{%
\section{les acteurs de la réalisation d'une œuvre enregistrée}\label{les-acteurs-de-la-ruxe9alisation-dune-ux153uvre-enregistruxe9e}}

Nous allons ici rapidement discuter des différents rôles apparaissant dans la production d'une œuvre musicale enregistrée. Ceux-ci sont volontairement très séparés, bien que dans les cas pratiques, une personne puisse en incarner plusieurs.

\textbf{Le compositeur} est la personne qui a composé la mélodie et l'harmonie de l'œuvre.

\textbf{L'arrangeur} est chargé de l'orchestration (choix des instruments) et l'écriture des différentes partitions.

\textbf{L'interprète} a la responsabilité de retranscrire une partition le plus justement possible, à la fois dans sa dimension technique et sensible.

\textbf{Le directeur artistique} (ou DA) supervise l'ensemble de l'enregistrement. Il aura, par exemple, à choisir le preneur de son, le mixeur ou dans quel studio enregistrer. Lors de la session d'enregistrement, il aura à diriger les musiciens (comme un réalisateur dirige ses acteurs au cinéma) afin de leur faire jouer la meilleure interprétation possible pour l'œuvre. Lors du mixage, il sera le principal interlocuteur du mixeur. Pour faire court~: il est le garant de l'orientation esthétique du projet.

\textbf{Le producteur} finance l'ensemble de projets. C'est donc un investisseur qui attend un retour sur investissement.

\begin{quote}
L'appellation abusive de «~producteur~» pour parler du directeur artistique vient d'un anglicisme du mot «~producer~». Le producteur est donc bien l'équivalent du directeur artistique dans les pays anglo-saxons. Si le DA a besoin d'un certain talent, le producteur a surtout besoin d'argent.
\end{quote}

\textbf{Le preneur de son} est chargé d'enregistrer les musiciens et musiciennes. Il a donc un rôle premier très technique~: il doit inscrire sur un support les ondes sonores produites par ces musiciens. Il a également un rôle esthétique très important, d'un point de vue sonore, car le choix du dispositif de prise de son aura un fort effet sur la suite de la vie de l'œuvre.

\textbf{Le mixeur} intervient après la prise de son et doit réaliser une sommation de l'ensemble des points de captations (microphone) vers un format écoutable par le grand public (mono, stéréo, 5.1, Ambisonique, Dolby Atmos, etc.). Son rôle esthétique est fortement contraint par le travail de prise de son. Si celle-ci est réussie, il pourra amplifier et bonifier les choix de production. Dans le cas contraire, il devra lutter pour essayer de faire sortir le meilleur d'une matière imparfaite.

\textbf{Le technicien de mastering} est le dernier maillon de la chaîne. Son rôle premier sera de préparer le travail de mixage à aux supports de diffusion. Il se devra également d'offrir une oreille nouvelle sur le travail réalisé au mixage.

\hypertarget{la-pruxe9production}{%
\section{La préproduction}\label{la-pruxe9production}}

La préproduction concerne toutes les étapes d'une œuvre enregistrée qui ont lieu avant ledit enregistrement. On parlera donc en premier lieu de la composition et particulièrement de l'arrangement.

La qualité d'un arrangement aura une influence énorme sur la facilité à mixer une œuvre. Si les instruments sont astucieusement répartis sur l'ensemble du spectre sonore, cela sera une difficulté de moins à gérer au mixage par exemple.

Il est aussi courant pour des artistes de réaliser des «~démos~». Celles-ci sont souvent des enregistrements réalisés en home studio afin de définir un cap esthétique pour la suite de la production sonore. C'est un atout extrêmement précieux pour un preneur de son, cela permet de rapidement identifier quel est le projet esthétique de l'œuvre.

\hypertarget{la-production}{%
\section{La production}\label{la-production}}

C'est ici que le travail du preneur de son commence. L'étape de production consiste à fixer les interprétations définitives. Le premier objectif est donc de s'assurer du bon enregistrement de tous les canaux prévus. Bien sûr, l'enjeu n'est pas seulement technique, mais aussi esthétique. Et il n'est pas moindre, les choix pris lors de la prise de son seront des carcans impossibles à outrepasser lors de la phase de mixage. Enfin, l'élément le plus déterminant de cette étape est d'obtenir des musiciens leurs meilleures interprétations. La présence d'un directeur artistique est d'une aide précieuse afin de diriger et d'orienter les musiciens. Il permet aussi de faire le lien entre les artistes et l'équipe technique, en exprimant les besoins des uns aux autres.

Sur les projets les plus modestes, le poste de directeur artistique est souvent sacrifié. Il en va donc à l'ingénieur du son de, parfois, remplir ce rôle.

\hypertarget{la-postproduction}{%
\section{La postproduction}\label{la-postproduction}}

Arrivé à ce stade, la majorité du travail est déjà accompli, il ne reste que le mixage et le mastering. Classiquement, chacune de ces tâches incombe à un technicien différent. Le travail du mixeur consistera à réaliser la sommation, généralement en stéréo, de l'ensemble des canaux enregistrés lors de la prise de son. Afin de faire cohabiter tous ces signaux, il est commun d'utiliser des traitements pour les répartir sur l'ensemble du spectre et de gérer leur dynamique. Parfois, ces traitements remplissent un rôle esthétique, en déformant le signal d'origine pour aboutir à une nouvelle matière.

Une fois le travail du mixeur terminé, le mastering commence. Le but et d'homogénéiser l'ensemble des titres d'un disque, en volume, en dynamique et en couleur. Ensuite, il convient aussi de définir le niveau de sortie général du disque. La dernière étape consistera à monter l'ordre des morceaux pour le disque, d'y inscrire les métadonnées (nom de l'artiste, des titres, genre musical, etc.) et de générer le fichier final, dédier à l'exploitation.

\hypertarget{part-uxe9quipement-et-usage}{%
\part{Équipement et usage}\label{part-uxe9quipement-et-usage}}

\hypertarget{le-chemin-du-signal}{%
\chapter{Le chemin du signal}\label{le-chemin-du-signal}}

La première mission d'un preneur de son est d'assurer l'arrivée à bon port des signaux dans l'enregistreur. En effet, toute notion de mise en scène sonore et d'esthétique devient très secondaire si le contenu n'a pas été enregistré.

Le diagramme ci-dessous reprend les principaux étages rencontrés par un signal audio dans un contexte de production numérique. Il est essentiel d'être le plus familier possible avec ces différents composants.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{_resources/diagrams/cheminSignal} 

}

\caption{Le chemin du signal. Elle peut-être agrandie en ouvrant l'image dans un nouvel onglet.}\label{fig:unnamed-chunk-20}
\end{figure}

Nous pourrions catégoriser à partir de ce schéma différents «~milieux~». Tout d'abord, nous avons le \textbf{milieu acoustique}, où nous trouverons toutes sortes d'instruments de musique, les différents lieux dans lesquels ils pourront s'y trouver. C'est donc le domaine de l'onde sonore mécanique.

On trouve ensuite le \textbf{milieu analogique}, où l'onde sonore est représentée, de façon analogue, par des grandeurs électriques. Celles d'un signal sonore dans un circuit analogique sont fonction, par exemple, de la variation de la pression atmosphérique provoquée en un point par une onde sonore. Les éléments clefs du milieu analogique sont les préamplificateurs et les amplificateurs, mais on trouve aussi certains traitements, comme les égaliseurs et les compresseurs. On définira «~analogique~» comme une représentation dans laquelle les grandeurs (tension, courant, etc.) qui entrent dans les calculs sont représentées par des grandeurs analogues et qui varient de manière identique (définition du \href{https://www.cnrtl.fr/definition/analogique}{CNRTL}).

Pour passer du milieu acoustique au milieu analogique, et vice-versa, on utilise des microphones et des haut-parleurs. Tous deux sont des \textbf{transducteurs}, permettant de transformer une énergie en une autre. Le microphone transforme une énergie mécanique en énergie électrique. Le haut-parleur réalise l'opération inverse.

On en vient ensuite au \textbf{milieu numérique}. Fondamentalement, le signal est toujours de nature électrique, mais il a subi une opération très importante nommée \textbf{échantillonnage}. On a donc mesuré à intervalle régulier la tension électrique générée par l'onde sonore. Le passage par le numérique permet une myriade de traitements sur le signal, beaucoup plus complexes que ceux permis par l'électronique analogique. L'audio numérique permet aussi un stockage de l'information à moindre coût et l'acheminement d'un grand nombre de voies (canaux) grâce à un faible nombre de modulations (câble).

L'appareil permettant de passer du milieu analogique au milieu numérique est le \textbf{convertisseur analogique/numérique}. Il ne s'agit pas d'un transducteur, car les signaux d'entrées et de sorties sont de même nature électrique. Pour opérer l'opération inverse, on utilise un \textbf{convertisseur numérique/analogique.}

Le \textbf{milieu informatique} nous permet d'utiliser des applications relatives aux traitements du son par le biais d'ordinateurs. Il s'agit aujourd'hui indubitablement de notre outil de travail principal. Nous y réalisons la grande majorité des traitements audio, ainsi que l'enregistrement et le routage des sources.

Le lien entre un ordinateur et un convertisseur A/N/A se fait grâce à un \textbf{bus de sérialisation} associé à un \textbf{pilote} (ou \textbf{driver}). L'ensemble des deux permet de mettre en forme la donnée numérique et de la rendre compréhensible à l'ordinateur.

Chaque élément évoqué ci-dessus sera abordé dans des sections dédiées dans la suite de ce livre.

\hypertarget{les-microphones}{%
\chapter{Les microphones}\label{les-microphones}}

Un microphone est un \textbf{transducteur} permettant de transformer une onde acoustique en signal électrique. Cette opération est réalisée par une membrane. Selon la nature du microphone, cette membrane pourra être constituée d'une feuille métallique d'un condensateur ou encore être rattachée à une bobine.

Le microphone est l'outil principal du preneur de son. Le choix du modèle et sa position dans l'espace est déterminants sur le rendu sonore d'une captation. Ces deux paramètres ont par ailleurs une certaine interdépendance~: une position souhaitée du microphone pouvant influencer le choix du modèle et vice-versa.

\hypertarget{petit-historique-des-microphones}{%
\section{Petit historique des microphones}\label{petit-historique-des-microphones}}

Sans vouloir rentrer dans un récit exhaustif sur l'invention et l'évolution des microphones, relater les moments clefs de cette technologie permet d'avoir une vision globale du marché d'aujourd'hui.

La nécessité de capter un évènement sonore grâce à un microphone provient de trois besoins~:

\begin{itemize}
\tightlist
\item
  le transmettre (télécommunication)
\item
  l'amplifier (concert, spectacle vivant)
\item
  l'enregistrer (industrie du disque)
\end{itemize}

En 1876, Alexandre Graham Bell propose un système à base liquide, permettant de transformer une onde sonore en tension électrique. Le système ne fut jamais réellement exploité, car le rendu sonore était jugé trop peu satisfaisant.

Le premier type de microphone utilisé industriellement est le \textbf{microphone à charbon} (au UK, par David Edward Hugues, aux US par Emile Berliner et Thomas Edison. Le brevet sera d'ailleurs disputé, avec un gain de cause pour Edison malgré des démonstrations publiques de Hugues antérieur aux publications d'Edison). En raison de sa faible bande passante et de son niveau de bruit élevé, il se révèle de piètres qualités pour l'enregistrement et la transmission de la musique. Il aura, par contre, une place de choix dans les téléphones durant de longues décennies.

Viennent ensuite les \textbf{microphones à condensateur}, dont les premiers modèles remontent à 1916, par le chercheur Edward Wente. Ces microphones sont tout d'abord réputés assez capricieux, leurs réponses en fréquences pouvant varier significativement en fonction de l'humidité de l'air et de la température.

À cause de ces variations sonores présentes dans les premiers microphones à condensateur, on leur préférera un temps les \textbf{microphones à ruban}. Ils sont inventés en 1923 par Harry Olson. Ils sont par contre d'une grande fragilité mécanique.

George Neumann est un des noms à connaître dans cette histoire des microphones. On lui doit, entre autres, la stabilisation des microphones statiques. Il sera aussi le premier à produire un microphone (U87) utilisant un transistor en lieu et place des traditionnels tubes.

À partir des années 1970, les microphones dynamiques arrivent sur le marché, notamment porté par la marque Shure. Ces microphones ont la grande qualité d'être très robustes, et remplaceront leurs homologues à ruban dans bien des cas.

Depuis, les principales améliorations ont concerné la robustesse d'une part, et la miniaturisation des dispositifs d'autre part, menant ainsi au développement des capsules MEMS.

\hypertarget{les-types-et-technologies-de-microphones}{%
\section{Les types et technologies de microphones}\label{les-types-et-technologies-de-microphones}}

Avant d'aborder en détail certaines constructions de microphones, il convient de faire attention à certains raccourcis associant des méthodes de fabrications à un niveau présumé de qualité. Par exemple, il est commun d'associer les microphones à électret à une construction «~bas de gamme~». Or, c'est oublier que la série 4000 de chez DPA, considérée par beaucoup comme une référence indétrônable de la prise de son, ne contient que des microphones à électret. Les MEMS souffrent du même biais, ceux-ci se retrouvent pourtant de plus en plus souvent sur des microphones ambisoniques, comme le Zyla ou le SPC mic.

Nous allons maintenant aborder les types de microphones suivants~:

\begin{itemize}
\tightlist
\item
  Les microphones électrostatiques/à condensateur
\item
  Les microphones à ruban
\item
  Les microphones dynamiques
\end{itemize}

\hypertarget{les-microphones-uxe9lectrostatiquesuxe0-condensateur}{%
\subsection{Les microphones électrostatiques/à condensateur}\label{les-microphones-uxe9lectrostatiquesuxe0-condensateur}}

\begin{figure}

{\centering \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/u87} \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/cmc64} \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/cm4} 

}

\caption{Neumann U87, Schoeps CMC64, Line Audio CM4}\label{fig:unnamed-chunk-21}
\end{figure}

Ce sont, historiquement, les premiers microphones à permettre une captation du spectre audible satisfaisante. Ils sont cependant très sensibles aux conditions de température et d'humidité et il fallut attendre les années trente pour que ce problème cesse. Ils nécessitent une alimentation externe, appelée alimentation fantôme, normalisée à +48V. Il existe deux familles de microphones électrostatiques, les \textbf{condensateurs à hautes fréquences} et \textbf{condensateur polarisés en courant continu}.

Les microphones à condensateur polarisés en courant continu ont le fonctionnement le plus commun. Un courant continu vient polariser la capsule/condensateur. Lorsqu'une onde sonore rencontre la capsule, une de ses armatures se déforme et génère une variation de tension analogue à la variation de pression.

Les microphones à condensateur à haute fréquence proposent une approche différente. Un oscillateur est intégré dans le microphone et la variation de pression enregistrée par le condensateur vient moduler la fréquence de cet oscillateur. Le signal est ensuite démodulé dans la plage audible. Cette méthode de construction offre une impédance de sortie plus faible et une plus grande résistance aux variations de conditions climatiques.

Concernant leurs caractéristiques, ces microphones possèdent des réponses en fréquence souvent très linéaire et une excellente réponse en transitoire. Leur niveau de sortie (sensibilité) est élevé. Leur impédance de sortie est basse.

Exemples~: Neumann~U87/AKG C414/Shoeps CMC4/Série 4000 DPA/Série MKH Sennheiser

\hypertarget{les-microphones-uxe0-ruban}{%
\subsection{Les microphones à ruban}\label{les-microphones-uxe0-ruban}}

\begin{figure}

{\centering \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/r121} \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/vinjet} \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/coles} 

}

\caption{Royer R121, Cascade Vinjet, Coles 4038}\label{fig:unnamed-chunk-22}
\end{figure}

Les microphones à ruban souvent préférés à leurs homologues statiques dans les débuts de la musique enregistrée. Leur fonctionnement repose sur l'utilisation d'une feuille métallique placée entre deux aimants. Lorsqu'une onde sonore rencontre cette feuille (le ruban), celle-ci vibre et perturbe le champ électromagnétique créé par les aimants et génère une tension analogue à la variation de pression.

D'un point de vue sonore, les microphones à ruban ont souvent un bas du spectre assez généreux et une réponse plutôt douce pour les hautes fréquences. Ils sont aussi connus pour avoir une impédance de sortie assez élevée et un niveau de sortie faible. Attention à l'alimentation fantôme (+48V), elle peut endommager le microphone.

Exemples~: Royer R121/Cohles/Beyerdynamic M160

\hypertarget{les-microphones-dynamiques}{%
\subsection{Les microphones dynamiques}\label{les-microphones-dynamiques}}

\begin{figure}

{\centering \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/sm57} \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/re20} \includegraphics[width=0.33\linewidth]{_resources/bitmap/mic/md441} 

}

\caption{Shure SM57, Electro-Voice RE20, Sennheiser MD441}\label{fig:unnamed-chunk-23}
\end{figure}

Les microphones dynamiques sont conçus pour des conditions d'utilisation rudes, où les niveaux sonores sont élevés et où le risque de chute est important. Ils sont donc monnaie courante en sonorisation. Leur membrane est attachée à une bobine entourant un aimant. Lorsqu'une onde sonore la met en vibration, la bobine se déplace autour de l'aimant, et, par perturbation du champ électromagnétique, génère une tension de sortie analogue à la variation de pression.

Leur réponse en fréquence est souvent accidentée, particulièrement dans le haut du spectre. Cela peut être vu comme un inconvénient ou comme un outil de «~coloration~» du son. Comme leurs homologues à ruban, ils possèdent un niveau de sortie faible et une impédance de sortie élevée.

Exemples~: Shure~SM57/Electrovoice~RE20/Sennheiser~MD441

\hypertarget{la-taille-des-membranes}{%
\subsection{La taille des membranes}\label{la-taille-des-membranes}}

La taille des membranes influe sur la captation du son. Plus la capsule est grande, plus les fréquences aiguës seront diffractées et donc atténuées dans la prise de son. Un microphone à petite membrane est donc techniquement un microphone plus «~juste~». Cependant, l'emploi de large membrane permet aussi d'adoucir un surplus d'énergie dans le haut du spectre.

\hypertarget{microphones-uxe0-tubes-ou-transistors}{%
\subsection{Microphones à tubes ou transistors?}\label{microphones-uxe0-tubes-ou-transistors}}

Historiquement, les tubes ont été les premiers composants électroniques à permettre l'amplification du signal. Le transistor est apparu à la fin des années 40 et a permis de remplir les mêmes fonctions qu'un tube, par une consommation moindre et avec un encombrement beaucoup plus faible.

Certains microphones continuent à être fabriqués avec des tubes, préférant leur comportement vis-à-vis du son. Une écrasante majorité est cependant fabriquée avec des transistors.

Le choix entre un microphone à tube et un microphone à transistor semble cependant anecdotique par rapport à son type, à son placement et à sa directivité.

\hypertarget{timbre-et-directivituxe9}{%
\section{Timbre et directivité}\label{timbre-et-directivituxe9}}

La directivité d'un microphone permet de décrire sa capacité à réaliser une «~écoute~» sélective de son environnement. On rencontre les directivités suivantes~:

\begin{itemize}
\tightlist
\item
  Omnidirectionnel~: capte l'ensemble du champ sonore de façon indifférenciée.
\item
  Hypercardioïde~: compromis entre Omnidirectionnel et cardioïde.
\item
  Cardioïde~: capte à l'avant, mais rejette à l'arrière du microphone.
\item
  Supercardioïde~: ressers la zone d'écoute avant au prix de l'apparition d'une résurgence arrière.
\item
  Hypercardioïde~: ressers davantage la zone d'écoute et augmente d'autant plus la résurgence arrière.
\item
  Bidirectionnel : capte à l'avant et à l'arrière, mais selon un lobe plus resserré qu'en cardioïde.
\end{itemize}

\begin{center}\includegraphics{_resources/plotly/test} \end{center}

Plus la directivité d'un microphone est large, plus la contribution de l'acoustique est apparente. Le timbre est également aussi linéaire que possible. À l'inverse, plus la directivité tant à être étroite, plus le microphone aura une capacité à échantillonner seulement une zone de l'espace. Le timbre est, par contre, amoindri dans le bas du spectre. Les microphones omnidirectionnels sont donc les plus larges et les plus «~neutres~», tandis que les microphones bidirectionnels sont les plus focalisés et ont la plus importante perte dans le bas du spectre.

Le preneur de son choisit donc une directivité en fonction de la tâche à accomplir. Les microphones directifs ont l'avantage de limiter la contribution d'évènements sonores que l'on ne souhaite pas capter. Les microphones omnidirectionnels ont la faculté d'être un dispositif de prise de son plus transparent, mais seront beaucoup plus sensibles à une acoustique moins optimale, ainsi qu'au bruit environnant.

Nous allons par la suite nous intéresser au cœur du microphone : sa capsule. Il existe deux familles de capsules, celles dites «~à pression~», et celles dites à «~gradient de pression~».

\hypertarget{capsules-uxe0-pression}{%
\subsection{Capsules à pression}\label{capsules-uxe0-pression}}

Une capsule sensible à la pression est omnidirectionnelle : elle capte les fluctuations de pressions en un point. Mathématiquement, cette relation s'exprime, en coordonnées polaires, par :

\[ \theta = 1 \]

L'angle d'incidence de l'onde sonore par rapport au microphone importe donc peu.

Pour réaliser une capsule à pression, on enferme une partie de la membrane dans un milieu acoustique à pression constante.

\hypertarget{capsules-uxe0-gradient-de-pression}{%
\subsection{Capsules à gradient de pression}\label{capsules-uxe0-gradient-de-pression}}

Une capsule à gradient de pression est sensible à la \textbf{variation} du champ de pression. Ces capsules ne sont plus omnidirectionnelles, mais bidirectionnelles : elles captent devant et derrière elles. Mathématiquement, une telle directivité s'exprime par la relation (en coordonnées polaires) :

\[ \theta = cos(\alpha) \]

Où \(\alpha\) est l'angle d'incidence d'un son par rapport à la capsule.

Pour réaliser une capsule à gradient de pression, il suffit de laisser exposer les deux faces de la membrane aux variations de pressions.

\hypertarget{et-les-autres-directivituxe9s}{%
\subsection{Et les autres directivités~?}\label{et-les-autres-directivituxe9s}}

Il est possible, à partir des deux équations ci-dessus, de retrouver toutes les autres directivités. Par exemple, un microphone cardioïde a une équation de directivité polaire tel que :

\[ \theta(\alpha) = \frac{1}{2}(1 + cos[\alpha]) \]

Elles découlent donc des deux directivités primaires : omnidirectionnelle et bidirectionnelle. Pour obtenir une directivité particulière, il suffit de «~doser~» l'influence de ces deux directivités. Par exemple, un microphone cardioïde possède une contribution égale de chacune d'elles. Plus on augmente la proportion de la directive bidirectionnelle, plus on tend vers un microphone supercardioïde, voire hypercardioïde. À l'inverse, augmenter la proportion de la directivité omnidirectionnelle fait tendre le microphone vers une directivité hypocardioïde.

Il existe deux solutions pour agir sur la contribution des directivités primaires. La première consiste à utiliser un labyrinthe acoustique pour changer le milieu acoustique d'une des faces de la membrane. L'autre consiste à avoir une capsule omnidirectionnelle et une seconde bidirectionnelle et de sommer leur tension de sortie.

Les microphones à multidirectivité permettent à l'utilisateur d'influer, soit sur le labyrinthe acoustique, soit sur la sommation des deux capsules. Il n'est pas rare que ces microphones soient moins performants qu'un microphone spécifiquement dédié à une seule directivité.

On retiendra donc :

\[ \theta(\alpha) = A + B \cos (\alpha) \> où \> A + B = 1\]

\begin{figure}

{\centering \includegraphics[width=0.33\linewidth]{_resources/diagrams/Polar-pattern-U-87-Ai-omni} \includegraphics[width=0.33\linewidth]{_resources/diagrams/Polar-pattern-U-87-Ai-cardioid} \includegraphics[width=0.33\linewidth]{_resources/diagrams/Polar-pattern-U-87-Ai-figure8} 

}

\caption{Directivités réelles du microphone (U 87)}\label{fig:unnamed-chunk-25}
\end{figure}

\hypertarget{directivituxe9s-ruxe9elles-duxe9timbrage}{%
\subsection{Directivités réelles \& détimbrage}\label{directivituxe9s-ruxe9elles-duxe9timbrage}}

Nous avons jusque là considéré que la directivité d'un microphone était un phénomène indépendant de la fréquence. Or, cela n'est pas vrai. En d'autres termes, la directivité d'un microphone n'est pas la même en fonction de la fréquence de l'onde sonore lui arrivant. Typiquement, un microphone tendra vers une directivité plus resserrée dans le haut du spectre, et vers une directivité plus large dans le bas du spectre.

\begin{figure}

{\centering \includegraphics[width=0.66\linewidth]{_resources/diagrams/Frequency-diagram-U-87-Ai-omni} 

}

\caption{Réponse en fréquence du microphone  Neumann U87 (omnidirectionnel)}\label{fig:unnamed-chunk-26}
\end{figure}
\begin{figure}

{\centering \includegraphics[width=0.66\linewidth]{_resources/diagrams/Frequency-diagram-U-87-Ai-cardioid} 

}

\caption{Réponse en fréquence du microphone Neumann U87 (cardioïde)}\label{fig:unnamed-chunk-27}
\end{figure}
\begin{figure}

{\centering \includegraphics[width=0.66\linewidth]{_resources/diagrams/Frequency-diagram-U-87-Ai-figure8} 

}

\caption{Réponse en fréquence du microphone Neumann U87 (figure en huit)}\label{fig:unnamed-chunk-28}
\end{figure}

Cela signifie donc que positionner un microphone hors axe face à un évènement sonore n'aura pas seulement un effet sur le niveau du signal en sortie du microphone, mais également sur le timbre. On appelle alors «~\textbf{timbré}~», un évènement sonore capté plein axe par un microphone, et \textbf{détimbré} un évènement sonore capté hors axe.

Ce phénomène est un outil précieux pour les preneurs de son. Par exemple, lorsqu'on enregistre une voix, certains sons sont exagérés par le microphone, particulièrement les «~s~». En tournant légèrement le microphone pour placer la voix hors axe, on peut déjà grandement améliorer les problèmes de sifflante avant même de penser à un éventuel traitement ultérieur.

\hypertarget{les-modulations-de-signaux-analogiques}{%
\chapter{Les modulations de signaux analogiques}\label{les-modulations-de-signaux-analogiques}}

Les câbles assurent le transport de signaux électriques. Ces signaux peuvent représenter une onde sonore (précédemment captée par un microphone), une valeur de contrôle pour piloter un appareil (pédale d'expression) ou encore une information numérique (câble USB, ethernet, etc.). Nous aborderons ici les câbles dédiés aux modulations analogiques, et tout particulièrement à l'audio.

Le principe de transport d'un signal analogique est assez simple. Pour une modulation, il faudra au moins un conducteur pour véhiculer le signal, et un conducteur pour la référence de tension, la masse. Pour transporter un signal supplémentaire, on conservera le même conducteur pour la référence et l'on en ajoutera un pour véhiculer le signal supplémentaire, faisant ainsi un total de trois conducteurs.

\hypertarget{anatomie-dun-cuxe2ble}{%
\section{Anatomie d'un câble}\label{anatomie-dun-cuxe2ble}}

Les câbles véhiculant un seul signal sont généralement constitués de quatre à cinq composants~:

\begin{itemize}
\tightlist
\item
  d'un cœur composé d'un filament (souvent multibrin) en un métal conducteur, véhiculant le signal électrique.
\item
  d'une gaine isolante (plastique) protégeant le cœur
\item
  d'une tresse en cuivre connectée à la masse
\item
  Parfois, d'une feuille de cuivre, enrobant la tresse, permettant de réaliser une cage de faraday et de protéger le cœur des ondes électromagnétiques.
\item
  Enfin, d'une dernière gaine isolante, permettant de protéger l'ensemble du câble.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{_resources/drawings/cable} 

}

\caption{Section d'un câble}\label{fig:unnamed-chunk-29}
\end{figure}

Ceux permettant de transporter plus de signaux rajouteront des cœurs multibrins entourés de leur gaine isolante. La plupart du temps, les câbles véhiculent un ou deux signaux à la fois, mais certains permettent d'en acheminer beaucoup plus (multipaire, Sub-D). On appelle un câble en fonction de ses connecteurs (ou fiches).

\hypertarget{longueur-du-cuxe2ble-son-et-impuxe9dance}{%
\subsection{Longueur du câble, son et impédance}\label{longueur-du-cuxe2ble-son-et-impuxe9dance}}

Étudions la section d'un câble à modulation unique. Nous pouvons faire plusieurs observations. Le fil conducteur du signal, généralement en cuivre, est d'une longueur non négligeable. Plus cette longueur est importante, plus ce fil aura une \textbf{résistance} importante. De plus, ce fil est séparé de la tresse de masse (élément également conducteur) par un isolant. Il existe donc un effet de \textbf{capacitance} entre le point chaud et la masse. Enfin, la tresse de masse peut être comparée à une bobine, et possède donc une \textbf{inductance}. Nous pouvons donc assimiler un câble à un circuit \textbf{RLC} filtrant le haut du spectre audio.

Physiquement, notre description précédente est valide, mais elle est à corréler à \textbf{l'impédance de sortie} de la source. Typiquement, lors de l'utilisation d'un microphone statique, son impédance est suffisamment faible pour que la longueur du câble soit totalement transparente. Certains microphones dynamiques ou à ruban, possédant une impédance plus élevée, peuvent très légèrement souffrir de la longueur du câble.

Ce phénomène d'altération du timbre à cause de la longueur d'un câble a surtout lieu avec les instruments électriques \textbf{passifs} (guitares et basses). L'impédance de sorte de ces instruments est tellement grande que l'on peut aisément entendre la différence de son entre deux câbles.

\begin{quote}
Il est amusant de constater que certains musiciens utilisent ce phénomène, et jouent avec des câbles volontairement trop longs, pour atténuer le haut du spectre. Brian May et Eric Johnson en sont deux exemples.
\end{quote}

\hypertarget{les-connexions-asymuxe9triques}{%
\subsection{Les connexions asymétriques}\label{les-connexions-asymuxe9triques}}

Les connexions asymétriques permettent de transporter un signal entre une source et un récepteur. Il s'agit de la façon la plus simple de connecter deux appareils devant échanger des signaux. Cependant, sur de longue distance, le câble peut se comporter comme une antenne et induire sur le signal certaines ondes électromagnétiques (comme la radio). Ces connexions ne nécessitent qu'un fil conducteur par modulation.

\hypertarget{les-connexions-symuxe9triques}{%
\subsection{Les connexions symétriques}\label{les-connexions-symuxe9triques}}

Le but de ces connexions est de palier au problème des connexions asymétrique. Dans l'appareil émetteur, le signal à transporter est dupliqué, et ce duplicata est inversé en phase. Cette étape s'appelle la \textbf{symétrisation}.

C'est deux signaux qui sont appelés point chaud (signal d'origine) et point froid (signal opposé en phase). Sur le trajet du câble, lorsqu'une perturbation électromagnétique est induite sur le signal, celle-ci s'inscrit en phase sur les deux conducteurs (point chaud et point froid). À l'arrivée, l'appareil récepteur inverse la phase du point froid et le somme avec le point chaud. Cette étape se nomme la \textbf{dé-symétrisation}. Ainsi le signal d'origine est sommé en phase, tandis que les interférences sont sommées hors phase et s'annulent.

Les connexions symétriques nécessitent deux fils conducteurs pour chaque modulation.

\hypertarget{les-fiches-connecteurs}{%
\section{Les fiches \& connecteurs}\label{les-fiches-connecteurs}}

\begin{figure}

{\centering \includegraphics[width=0.2\linewidth]{_resources/bitmap/plug/jackTs} \includegraphics[width=0.2\linewidth]{_resources/bitmap/plug/jackTrs} \includegraphics[width=0.2\linewidth]{_resources/bitmap/plug/jackBantam} \includegraphics[width=0.2\linewidth]{_resources/bitmap/plug/xlr} \includegraphics[width=0.2\linewidth]{_resources/bitmap/plug/subd25} 

}

\caption{Jack TS, Jack TRS, Jack Bantam, XLR, Sub-D 25}\label{fig:unnamed-chunk-30}
\end{figure}

On appelle «~fiche~» les éléments mécaniques situés aux extrémités d'un câble et permettant sa connexion à un équipement. Celle-ci nous permet de facilement identifier le type de câble que nous avons entre les mains.

\begin{quote}
Contrairement aux dires de certains mythes, majoritairement reliée à l'audiophilie, la différence de matériau utilisé pour le contact de la fiche n'a pas d'incidence sur le son.
\end{quote}

On rencontre principalement les connectiques jack TS, jack TRS, jack bantam, XLR et Sub-D. Les fiches jack TS ont deux points de connexion. Les fiches jack TRS, XLR et bantam en ont deux. Les Sub-D~25 en possèdent vingt-cinq.

Les fiches jack TS sont souvent utilisées sur les instruments électriques et électroniques (guitare, basse, synthétiseurs, etc.). Ces connexions sont nécessairement symétriques. Les jack TRS sont un peu plus rare et se trouvent généralement sur des instruments avec des sorties stéréophoniques, ou sur des équipements audio possédant des entrés/sorties symétriques. La connectique XLR remplit fondamentalement le même usage qu'un jack TRS, mais offre un verrouillage mécanique, permettant de sécuriser la connexion. On la trouve principalement sur les microphones et sur préamplificateurs. L'avantage du jack TRS est son plus faible encombrement mécanique. On le préfère donc sur les appareils possédant un grand nombre d'entrées/sorties. Le jack bantam se trouve sur les boîtiers de patch. Leur petite taille permet une grande densité de point de connexion. Les patchbay prennent ainsi moins de place. On trouve aussi les connectiques Sub-D~25, principalement pour remplacer des connexions XLR. En effet, une seule connectique Sub-D~25 permet de remplacer huit câbles XLR.

\hypertarget{exemples-pratiques}{%
\section{Exemples pratiques}\label{exemples-pratiques}}

\hypertarget{cuxe2ble-jack-mono}{%
\subsection{Câble jack «~mono~»}\label{cuxe2ble-jack-mono}}

Ce type de câble est souvent utilisé sur les instruments électriques. On l'appelle «~mono~» car il ne véhicule qu'un seul signal.

\hypertarget{cuxe2ble-jack-stuxe9ruxe9o}{%
\subsection{Câble jack «~stéréo~»}\label{cuxe2ble-jack-stuxe9ruxe9o}}

L'appellation de ce câble est ambiguë. Le terme stéréo fait référence à ses deux voies de connexion, cependant, le nom «~stéréo~» impliquerait qu'une des voies est destinée à alimenter l'enceinte gauche, et l'autre, le canal droit. Or, ce type de câble peut également convenir pour des connexions symétriques.

\begin{quote}
On notera qu'il est possible de brancher un câble jack TS dans une fiche TRS. Un seul des canaux sera alors acheminé.
\end{quote}

\hypertarget{cuxe2ble-y}{%
\subsection{Câble «~Y~»}\label{cuxe2ble-y}}

Ces câbles possèdent trois connecteurs, et sont le plus souvent équipés de jack TS. Ils permettent de récupérer un signal pour le transmettre sur deux appareils. Attention, la duplication du signal étant passive, on risque un problème d'impédance si l'impédance d'entrée des deux appareils est trop différente. Le cas d'école est souvent rencontré lorsqu'on branche deux casques sur le même amplificateur. Si l'impédance des deux casques est trop différente, un des deux aura presque l'intégralité du niveau du signal alors que l'autre sous-modulera.

\hypertarget{les-connexions-dinsert}{%
\subsection{Les connexions d'insert}\label{les-connexions-dinsert}}

Ces câbles ont la particularité d'avoir une fiche jack TRS et deux fiches jack TS. En studio, on les rencontre très souvent pour insérer un périphérique de traitement dans la chaîne audio. Le «~tip~» du jack TRS est connecté au «~tip~» d'un des jack TS qui est connectés sur l'entré du périphérique. Le deuxième jack TS est raccordé à la sortie de l'appareil et son «~tip~» est connecté au «~ring~» du jack TRS.

Ces câbles sont aussi utilisés pour séparer une sortie dite «~stéréo~» en deux voies «~mono~».

\hypertarget{routage-des-signaux}{%
\section{Routage des signaux}\label{routage-des-signaux}}

En studio d'enregistrement, il n'est pas rare de rencontrer plusieurs cabines de prise de son, chacune équipée de boîtier de patch. Ces boîtiers sont constitués d'un certain nombre d'entrées XLR. On achemine ensuite les sorties de ces boîtiers via des multipaires jusqu'à une «~patchbay~». Le rôle de la «~patchbay~» est de permettre de connecter n'importe quelle entrée (signal provenant d'un microphone) vers n'importe quel préamplificateur.

On trouve évidemment beaucoup d'usage à ces «~patchbay~». Elles sont à considérer comme la matrice de routage d'un studio d'enregistrement.

\hypertarget{les-pruxe9amplificateurs}{%
\chapter{Les préamplificateurs}\label{les-pruxe9amplificateurs}}

Le rôle d'un préampli est de réaliser une amplification en tension du signal ainsi que de diminuer son impédance. Cette opération est indispensable pour permettre à notre signal de traverser le reste de la chaîne du traitement audio.

Il n'est pas rare que les préamplificateurs soient souvent choisis pour leur «~couleur~» sur le signal. Nous commencerons par aborder ces outils d'un point de vue pratique pour enfin déboucher sur cette question.

\hypertarget{crituxe8res-de-choix-dun-pruxe9amplificateur}{%
\section{Critères de choix d'un préamplificateur}\label{crituxe8res-de-choix-dun-pruxe9amplificateur}}

Le critère de première importance dans le choix d'un préamplificateur est son gain maximal. Plus l'amplification disponible est grande, plus le préampli sera capable de répondre à des situations exigeantes, telles que l'enregistrement d'un évènement sonore à faible niveau, ou l'emploi d'un microphone à faible sensibilité.

Le second critère important dans le choix d'un préampli est sa réponse en fréquence. Théoriquement, celle-ci doit être la plus neutre possible. Une certaine coloration peut être acceptée (voire souhaitée), mais celle-ci doit rester raisonnable pour répondre à des critères d'utilisations professionnelles.

La réponse en transitoire est un autre élément important. Certains préamplis auront tendance à adoucir la sensation d'attaque des sources. Cet effet n'est pas souhaitable.

Enfin le rapport signal sur bruit doit être le plus grand possible. Nous cherchons toujours à rajouter le moins de bruit possible sur le chemin de notre signal.

\hypertarget{les-technologies-de-pruxe9ampli}{%
\section{Les technologies de préampli}\label{les-technologies-de-pruxe9ampli}}

Nous avons vu dans le chapitre trois qu'il existe trois familles de composants électroniques permettant d'amplifier le signal : les tubes, les transistors et les circuits intégrés. On retrouve donc des topologies de circuit de préamplificateurs utilisant chacun de ces composants.

Chacune de ces topologies offre de très légère variation de son lorsque les préamplis sont poussés dans leur retranchement (seuil de saturation). Comme pour les microphones, il est délicat de parler de son «~à tube~» ou «~à transistor~». De plus, l'influence sur le son d'un préamplificateur apparaît en pratique comme très marginale par rapport au positionnement du microphone.

\hypertarget{les-ruxe9glages-dun-pruxe9ampli}{%
\section{Les réglages d'un préampli}\label{les-ruxe9glages-dun-pruxe9ampli}}

Un préampli propose souvent les réglages suivants~:

\begin{itemize}
\tightlist
\item
  Un potentiomètre de gain (qui est souvent remplacé par un sélecteur cranté, plus précis, pour les modèles haut de gamme).
\item
  Un bouton activant l'alimentation fantôme. En effet, c'est bien le préampli qui génère cette tension d'alimentation pour les microphones statiques.
\item
  Un bouton d'inversion de phase.
\item
  Un coupe-bas.
\end{itemize}

\hypertarget{la-conversion-analogique-numuxe9rique}{%
\chapter{La conversion analogique numérique}\label{la-conversion-analogique-numuxe9rique}}

\hypertarget{la-nuxe9cessituxe9-de-la-conversion-analogique-numuxe9rique}{%
\section{La nécessité de la conversion analogique numérique}\label{la-nuxe9cessituxe9-de-la-conversion-analogique-numuxe9rique}}

Durant toute la période de l'audio analogique, le support de stockage de prédilection fut la bande magnétique. Cependant, celle-ci n'offre pas un rapport signal sur bruit très satisfaisant, limitant alors la dynamique musicale enregistrable. De plus, la bande a également un coût non négligeable. On a donc cherché à remplacer ce support afin de résoudre ces deux problèmes. Le stockage numérique offre, sous certaines conditions, une dynamique bien supérieure à celle des supports analogiques.

Une représentation numérique de l'audio permet aussi la réalisation de traitement délicat, voire impossible, en analogique. On pense, par exemple, aux algorithmes de réverbération, d'écho et de «~pitch shifting~» (modification de la hauteur d'un son).

Enfin, nos principaux outils de manipulation du son sont aujourd'hui informatiques. Dès lors, une représentation numérique des signaux est toute indiquée pour les manipuler grâce à nos ordinateurs. Il en découle donc une nécessité de bien maîtriser les principes entourant la numérisation des signaux.

\begin{quote}
En français, le «~digital~» est un anglicisme. Le mot correct est donc bien «~numérique~», et non «~digital~», qui qualifie ce qui a rapport au doigt.
\end{quote}

\hypertarget{thuxe9orie-de-luxe9chantillonnage}{%
\section{Théorie de l'échantillonnage}\label{thuxe9orie-de-luxe9chantillonnage}}

\hypertarget{dun-signal-continu-vers-un-signal-uxe9chantillonnuxe9}{%
\subsection{D'un signal continu vers un signal échantillonné}\label{dun-signal-continu-vers-un-signal-uxe9chantillonnuxe9}}

Une des caractéristiques principales d'un signal analogique est qu'il est continu. Une fonction, en mathématique, est dite continue si elle est définie en n'importe quel instant. Afin d'être numérisé, un signal doit donc être dénombré. En effet, la notion d'infini imposé par la continuité du signal n'a pas d'existence en numérique.

La numérisation du signal est comparable à l'utilisation d'un multimètre pour mesurer une tension. Un convertisseur va prélever la valeur du signal, de façon régulière, au cours du temps.

Afin de correctement numériser un signal, il convient de définir deux paramètres~:

\begin{itemize}
\tightlist
\item
  la vitesse de prélèvement, ou \textbf{fréquence d'échantillonnage}
\item
  la plage de valeur permise pour le signal, ou \textbf{résolution de quantification}
\end{itemize}

\hypertarget{la-fruxe9quence-duxe9chantillonnage}{%
\subsection{La fréquence d'échantillonnage}\label{la-fruxe9quence-duxe9chantillonnage}}

Cette fréquence définit le nombre de prélèvements par seconde. Par exemple, un morceau édité sur un CD audio a une fréquence d'échantillonnage de 44~100~Hz (44,1~kHz), cela signifie que le signal est mesuré 44~100~fois par seconde.

La fréquence de travail la plus courante est 48~kHz, mais l'on rencontre parfois des valeurs supérieures, multiple de celle-ci~: 96~kHz, 192~kHz, etc. Cette augmentation proportionnelle de la fréquence d'échantillonnage s'appelle \textbf{suréchantillonnage}. Certains techniciens espèrent ainsi améliorer la qualité de l'enregistrement. Ce suréchantillonnage à un coût en ressource CPU et en espace de stockage. Un flux audio échantillonné à 96~kHz demande deux fois plus de ressource et d'espace qu'un flux échantillonné à 48~kHz. Cette valeur initiale de 44~100~Hz (ou 48~kHz) n'a pas été choisie au hasard. Pour la comprendre, il faut revenir au phénomène physique que nous cherchons à numériser.

Rappelons que le son est une onde mécanique, et nous l'entendons lorsqu'elle oscille dans une plage de fréquence comprise entre 20~Hz (très grave) et 20~000~Hz (très aigu). Il faut donc que notre système de numérisation soit capable de reproduire une fréquence maximale allant jusqu'à 20~000~Hz. Pour cela, nous utilisons les résultats des travaux des chercheurs Harry Nyquist et Claude Shannon (tous deux ayant travaillé aux laboratoires Bell).

Le \textbf{théorème de Shannon-Nyquist} stipule que, pour être capable d'échantillonner un signal de fréquence \(f\), la fréquence d'échantillonnage doit au moins être de \(2f\). Ainsi, un ensemble de points généré par une fréquence inférieure à \(f\) ne peut correspondre qu'à cette seule et unique fréquence. Notre plage d'écoute étant limitée à 20~kHz, la fréquence d'échantillonnage minimale dont nous avons besoin est de 40~kHz.

Que se passe-t-il si la fréquence du signal dépasse la moitié de la fréquence d'échantillonnage~? Dans ce cas, la vitesse de prélèvement n'est plus suffisante et nous observons l'apparition de nouvelles fréquences ne provenant pas du signal original. Ce phénomène se nomme \textbf{repliement spectral}.

\hypertarget{la-ruxe9solution-de-quantification}{%
\subsection{La résolution de quantification}\label{la-ruxe9solution-de-quantification}}

La résolution de quantification permet de définir la plage de valeur dynamique permise dans le système numérique. Celle-ci s'exprime en bit. Par exemple, si nous prenons un convertisseur travaillant en 8~bit. Le nombre de valeurs que peut prendre un signal numérisé par un tel convertisseur est de \(2^8-1 = 255\) en base 10. Admettons que ce convertisseur accepte des signaux ayant une tension en entrée variant entre +15V et -15~V, celles-ci seront \textbf{échelonnées} sur 255~valeurs. Si maintenant, ce convertisseur travaille en 16~bit, il y aura 65~535~échelons. La précision de mesure de la dynamique du signal n'est donc pas du tout la même.

En pratique, augmenter la résolution de quantification permet principalement de définir le niveau de bruit du convertisseur. Plus la résolution est élevée, plus le bruit se retrouvera faible. En 8~bit, l'écart entre le niveau maximal d'un signal et le bruit est de 48~dB, en 16~bit cet écart est de 96~dB, en 24~bit, 144~dB. On peut approximativement calculer cette dynamique par la relation suivante :

\[ \Delta_L \approx 6 \times N_{bits} \]

La résolution de quantification standard en enregistrement est 24~bit. La plage dynamique est telle qu'elle rend le travail d'enregistrement beaucoup plus souple sur les niveaux d'acquisition des différentes sources.

\hypertarget{quelle-influence-sur-le-signal}{%
\section{Quelle influence sur le signal ?}\label{quelle-influence-sur-le-signal}}

Le son numérique a longtemps eu la réputation d'être «~dur~», particulièrement dans le haut du spectre. Cela s'explique assez facilement par le fonctionnement des premiers convertisseurs.

En effet, toute la difficulté de fabrication d'un convertisseur réside dans la réalisation d'un filtre anti-repliement, pour prévenir le repliement spectral. Ce filtre doit enlever toutes les fréquences au-dessus de la moitié de la fréquence d'échantillonnage, sans pour autant affecter le spectre audible. Ce type de filtre est extrêmement délicat à réaliser en analogique. Cependant, ce problème est résolu grâce à une méthode d'échantillonnage appelée «~sigma-delta~» (voir ci-dessous).

Le repliement spectral n'apparaît pas seulement lors de la conversion. Il peut également survenir lors de l'utilisation de certains traitements (saturation, simulation analogique, compresseurs). Lorsqu'il devient audible, le repliement spectral se caractérise par l'apparition de fréquences \textbf{non harmoniques} souvent qualifiées de «~dures~» et désagréables. Il est cependant bon de rappeler que ce phénomène, certes bien réel, apparaît dans des conditions de saturation du signal importante et sur des sources sonores riches en hautes fréquences.

Malgré la dure vie que mène parfois la réputation du son numérique, il est important de rappeler qu'il a apporté un grand nombre d'avantages sur le son analogique, \textbf{y compris sur des questions de rendus sonores}. Par exemple, la dynamique est bien plus importante, la distorsion involontaire du signal infime et l'ajout de bruit inexistant.

\hypertarget{la-conversion-sigma-delta}{%
\section{La conversion sigma-delta}\label{la-conversion-sigma-delta}}

Aujourd'hui, les convertisseurs ne travaillent pas directement à 44,1~kHz/16~bit ou 48~kHz/24~bit. Ils utilisent à la place un procédé appelé échantillonnage sigma-delta. Le principe est d'utiliser une fréquence d'échantillonnage très rapide (384~kHz) et de coder la dynamique du signal, en relatif, sur un seul bit (ce bit prend une valeur de 1 si le nouvel échantillon est plus fort que l'ancien, 0 pour le cas inverse). Les formats de travail que nous utilisons sont générés après cette première étape.

L'intérêt de cette méthode est double~:

\begin{itemize}
\tightlist
\item
  Le signal est suréchantillonné dès l'enregistrement
\item
  Les filtres permettant d'éviter le repliement spectral sont donc très simples à réaliser
\end{itemize}

\hypertarget{les-modulations-de-signaux-numuxe9riques}{%
\chapter{Les modulations de signaux numériques}\label{les-modulations-de-signaux-numuxe9riques}}

Après être passé au travers d'un convertisseur, l'audio est représenté par un ensemble d'échantillons. En raison de cette représentation particulière, on trouve un certain nombre de protocoles de communication de signaux numériques entre appareils. Il ne s'agit plus ici de faire transiter une tension analogue à celle de la variation de pression d'une onde sonore, mais plutôt une tension représentant des mots binaires (bits).

La variation de tension de ces signaux s'apparente à une onde carrée. Ces signaux périodiques possèdent un état «~haut~» et un état «~bas~», très pratique pour communiquer des nombres binaires.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{_main_files/figure-latex/unnamed-chunk-31-1} 

}

\caption{Exemples de signaux carrés (Non Return to Zero à gauche, Return to Zero à droite)}\label{fig:unnamed-chunk-31}
\end{figure}

\hypertarget{les-liaisons-point-uxe0-point}{%
\section{Les liaisons point à point}\label{les-liaisons-point-uxe0-point}}

Les protocoles ci-dessous permettent de transmettre un ou plusieurs signaux numériques entre deux appareils.

\hypertarget{aes3-aesebu}{%
\subsection{AES3~; AES/EBU}\label{aes3-aesebu}}

L'AES3 est un protocole défini par l'\emph{Audio Engineering Society} et par l'\emph{European Union Broadcast}. Il est principalement destiné aux appareils audio dits «~professionnels~». Il permet de véhiculer deux canaux audio, à une fréquence d'échantillonnage maximal de 48~kHz, via une fiche XLR ou BNC (coaxial).

La S/PDIF est relativement proche de l'AES3, plutôt utilisé dans les équipements grand public, utilisant des câbles coaxiaux (sur fiches RCA) ou optiques (fiche toslink).

\hypertarget{adat}{%
\subsection{ADAT}\label{adat}}

L'\emph{ADAT lightpipe}, souvent abrégé ADAT, est un autre protocole de transmission de signaux numériques. Il a été développé par Alesis pour fonctionner avec les magnétophones à bandes numériques de la même marque. ADAT signifie enfaîte «~Alesis Digital Audio Tape~». On retrouve ce protocole sur un grand nombre d'appareils, notamment les interfaces audio, afin d'augmenter le nombre d'entrées/sorties accessibles.

L'ADAT peut transporter jusqu'à huit canaux à 44.1/48~kHz, quatre canaux à 88.2/96~kHz et deux canaux à 176.4/192~kHz. Le débit d'information est donc constant, doubler la fréquence d'échantillonnage divise par deux le nombre de canaux.

La connectique la plus courante pour l'ADAT est la fibre optique avec fiches toslink.

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{_resources/bitmap/plug/toslink} 

}

\caption{Câble Toslink}\label{fig:unnamed-chunk-32}
\end{figure}

\hypertarget{madi}{%
\subsection{MADI}\label{madi}}

Le MADI, ou AES10, est un protocole permettant d'acheminer un grand nombre de canaux. On peut donc récupérer soixante-quatre canaux audio à une fréquence de 44.1/48~kHz. Comme pour l'ADAT, le nombre de canaux est divisé par deux à chaque doublement de la fréquence d'échantillonnage.

Ce protocole se retrouve fréquemment dans le monde de l'audio professionnel. Les connexions entre appareils supportant le MADI peuvent se faire soit avec des fibres optiques, soit sur câble coaxial (fiches BNC). Certains constructeurs, comme DIGICO, ont choisi les câbles~RJ45 comme support d'acheminement.

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{_resources/bitmap/plug/fibre} \includegraphics[width=0.3\linewidth]{_resources/bitmap/plug/bnc} 

}

\caption{Fibre optique et câble BNC}\label{fig:unnamed-chunk-33}
\end{figure}

\hypertarget{les-ruxe9seaux-audio-numuxe9riques}{%
\section{Les réseaux audio numériques}\label{les-ruxe9seaux-audio-numuxe9riques}}

Aujourd'hui, dans le monde du spectacle vivant, la plupart des salles de spectacle sont équipées avec des solutions de transmission des signaux audio sur réseau. Ces solutions se retrouvent aussi de plus en plus dans les studios d'enregistrement et de production audiovisuelle.

Il existe plusieurs protocoles permettant le déploiement de tels dispositifs, mais leur logique fondamentale reste identique. Chaque appareil capable de se connecter au réseau audio peut recevoir et envoyer un flux audio a n'importe quels autres appareils appartenant au même réseau.

Les réseaux audio sont régis par les mêmes règles que les réseaux informatiques. Chaque appareil pouvant être connecté à un réseau est identifiable par une adresse matérielle unique, appelée \textbf{adresse MAC}. Lorsqu'un appareil est connecté sur un réseau, il faut lui attribuer une adresse logique appelée \textbf{adresse IP}. Il y a ici deux façons de faire. Soit l'utilisateur attribue manuellement une adresse différente à chaque machine (solution préférée en audio, mais fastidieuse lorsque le réseau comprend un grand nombre d'appareils), soit le réseau possède un \textbf{serveur DHCP} qui se chargera d'attribuer une adresse IP unique à chacun des appareils connectés. Cet outil est généralement intégré dans un appareil nommé \textbf{routeur}, permettant d'interconnecter plusieurs appareils ainsi que de gérer le routage des flux d'information. Une fois les appareils interconnectés, chaque constructeur de solutions audio sur IP fournit un logiciel de routage de l'audio entre les appareils.

Les principaux acteurs industriels des réseaux audionumériques sont Audinet avec DANTE, ALC NetworX (appartenant à Lawo) avec Ravenna, et les protocoles open source~AES67 et AVB.

\hypertarget{introduction-uxe0-linformatique-musicale}{%
\chapter{Introduction à l'informatique musicale}\label{introduction-uxe0-linformatique-musicale}}

(En cours d'écriture)

\hypertarget{fonctionnement-dun-ordinateur}{%
\section{Fonctionnement d'un ordinateur}\label{fonctionnement-dun-ordinateur}}

\hypertarget{les-systuxe8mes-dexploitation}{%
\section{Les systèmes d'exploitation}\label{les-systuxe8mes-dexploitation}}

\hypertarget{linux}{%
\subsection{Linux}\label{linux}}

\hypertarget{microsoft-windows}{%
\subsection{Microsoft Windows}\label{microsoft-windows}}

\hypertarget{apple-macos}{%
\subsection{Apple MacOS}\label{apple-macos}}

\hypertarget{les-pilotes-audio}{%
\section{Les pilotes audio}\label{les-pilotes-audio}}

\hypertarget{asio}{%
\subsection{ASIO}\label{asio}}

\hypertarget{coreaudio}{%
\subsection{CoreAudio}\label{coreaudio}}

\hypertarget{alsa}{%
\subsection{ALSA}\label{alsa}}

\hypertarget{jack-audio}{%
\subsection{Jack Audio}\label{jack-audio}}

\hypertarget{les-stations-de-travail-audio-numuxe9rique-daw}{%
\section{Les Stations de Travail Audio-Numérique (DAW)}\label{les-stations-de-travail-audio-numuxe9rique-daw}}

\hypertarget{le-moteur-audio}{%
\subsection{Le moteur audio}\label{le-moteur-audio}}

\hypertarget{les-fonctionnalituxe9s}{%
\subsection{Les fonctionnalités}\label{les-fonctionnalituxe9s}}

\hypertarget{les-protocoles-de-transmission-dinformations}{%
\section{Les protocoles de transmission d'informations}\label{les-protocoles-de-transmission-dinformations}}

\hypertarget{midi}{%
\subsection{MIDI}\label{midi}}

\hypertarget{osc}{%
\subsection{OSC}\label{osc}}

\hypertarget{enceintes-et-amplificateurs}{%
\chapter{Enceintes et amplificateurs}\label{enceintes-et-amplificateurs}}

Un haut-parleur est un appareil permettant de transformer une énergie électrique en énergie mécanique. On l'appelle, plus spécifiquement, un transducteur électroacoustique. Fondamentalement, il s'agit d'un appareil extrêmement proche d'un microphone. D'ailleurs, il est possible d'utiliser un haut-parleur comme microphone, et vice-versa. Les haut-parleurs ont de faibles rendements, il est donc nécessaire d'amplifier les signaux grâce à des amplificateurs de puissance en amont.

De tous les équipements audio nécessaires pour réaliser une prise de son, les enceintes (et les casques) sont certainement les plus importants. En effet, c'est à travers leur prisme que nous pourrons écouter et contrôler notre travail. Il est donc crucial d'utiliser des écoutes regroupant un certain nombre de critères et, surtout, de les connaître sur le bout des doigts.

\hypertarget{anatomie-dun-haut-parleur}{%
\section{Anatomie d'un haut-parleur}\label{anatomie-dun-haut-parleur}}

\begin{figure}

{\centering \includegraphics[width=0.25\linewidth]{_resources/bitmap/speaker/woofer} \includegraphics[width=0.25\linewidth]{_resources/bitmap/speaker/midrange} \includegraphics[width=0.25\linewidth]{_resources/bitmap/speaker/tweeter} 

}

\caption{Coupe de hautparleur (dans l'ordre, woofer, mid-range, tweeter). Infographie par Svjo, CC BY-SA 3.0}\label{fig:unnamed-chunk-34}
\end{figure}

Sur les schémas ci-dessus, nous trouvons les éléments suivants~:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  L'aimant
\item
  La bobine
\item
  La suspension
\item
  La membrane
\end{enumerate}

La plupart des haut-parleurs sont qualifiés de \textbf{dynamiques}. La membrane du haut-parleur est reliée à une bobine, elle-même entourée par un système d'aimants. Lorsqu'un courant est appliqué aux bornes de cette bobine, sa position change dût à la modification du champ électromagnétique. Si le courant oscille, la bobine oscille de façon analogue, entraînant la membrane et permet donc la reproduction du son.

On appelle généralement «~subwoofer~» les haut-parleurs conçus pour retranscrire les fréquences très graves (20-200~Hz), «~woofer~» les haut-parleurs dédiés aux fréquences graves (50~Hz à 1000~kHz), «~mid-range~» les haut-parleurs du médium (1~kHz à 6~kHz), et «~tweeter~», ceux de l'aigu (au-delà de 5~kHz).

Le haut-parleur est sans doute l'appareil audio le plus imparfait qui soit. Il est sujet à de nombreuses sources de distorsion du signal.

Nous ne savons pas fabriquer des haut-parleurs capables de reproduire uniformément toutes les fréquences. Ces derniers sont souvent spécialisés dans une certaine plage de fréquence. La plupart des enceintes de monitoring utilisent 3~voies~: deux actives (utilisant des haut-parleurs) pour l'aigu et le médium, et une passive (évent avant ou arrière) pour le grave. L'utilisation du plusieurs voies imposent donc l'utilisation de filtres induisant un déphasage de certaines fréquences.

Également, un haut-parleur peut être approché par un modèle «~masse-ressort~». Cela signifie qu'il y a une certaine inertie à sa mise en action et une certaine inertie à sa mise en arrêt. L'enceinte idéale devrait posséder une inertie nulle. Cette inertie est potentiellement responsable d'un adoucissement des transitoires et d'une sensation de flou.

\hypertarget{amplification-et-impuxe9dance}{%
\section{Amplification et impédance}\label{amplification-et-impuxe9dance}}

Nous avons précédemment abordé le préamplificateur, qui permet d'amplifier la tension d'un signal audio analogique et d'en baisser son impédance. On appelle alors «~amplificateur~» un amplificateur de \textbf{puissance}. On rappel que la puissance d'un signal s'exprime par la relation ci-dessous. On cherche donc à augmenter la tension \textbf{et} l'intensité du signal.

\[ P = U \times I \]

Nous pouvons rapidement aborder la notion de classe d'amplification. En audio, nous n'utilisons que les classes A, AB et D. La classe A utilise un transistor (ou tube) pour amplifier l'ensemble du signal. Elle possède un très mauvais rendement. Cela signifie qu'il faut fournir beaucoup d'énergie au transistor pour un faible gain sur la puissance du signal. La classe AB utilise deux transistors, un pour les alternances négatives et un pour les alternances positives. Le rendement est meilleur que pour la classe A. Cependant, le point de raccordement entre les deux transistors est assez sensible et peu généré de la distorsion sur le signal (distorsion de croisement). La classe D, aussi appelée à tort «~numérique~», utilise un transistor afin d'indiquer l'état du signal. On retrouve donc la même idée que dans l'échantillonnage du signal. Ces amplificateurs offrent un \textbf{excellent rendement}.

Nous avons également abordé précédemment la notion d'adaptation d'impédance en tension, sans aborder l'adaptation d'impédance en puissance. Pour rappel, afin de préserver la tension entre deux appareils A et B, nous faisons en sorte d'avoir une faible impédance à la sortie de l'appareil A et une grande impédance à l'entré de l'appareil B. Pour préserver la puissance du signal, ce paradigme ne fonctionne plus. On cherche alors à avoir la même impédance entre la sortie d'un appareil et l'entrée d'un autre. En pratique, on raccordera, sur la sortie «~8~ohms~» d'un amplificateur, un haut-parleur ayant une impédance de «~8~ohms~».

\begin{quote}
On remarque qu'ici, les impédances sont extrêmement faibles. Les impédances typiques des haut-parleurs (et donc des sorties d'amplificateurs en puissance) sont 4, 8 et 16~ohms.
\end{quote}

La plupart des enceintes de monitoring ont aujourd'hui une amplification de classe D directement intégré.

\hypertarget{puissance-et-sensibilituxe9}{%
\section{Puissance et sensibilité}\label{puissance-et-sensibilituxe9}}

On trouve généralement deux mesures de la puissance pour les enceintes. La puissance \textbf{crête à crête} (peak) et la \textbf{puissance moyenne} (\textbf{RMS}, ou \textbf{Root Mean Square}). La puissance se calcule grâce à la formule suivante~:

\[ P =\frac {U^2}{Z} \]

\(P\) est la puissance, \(U\) la tension et \(Z\) l'impédance. Pour réaliser la mesure de puissance d'un haut-parleur, on le soumet à un signal test, en général un bruit rose, pendant plusieurs heures. La puissance crête à crête se calcul grâce à la tension crête à crête (aussi dite maximale). Par exemple, pour une tension maximale de 100~V, sous une impédance de 8~ohms, on trouve une \textbf{puissance crête à crête} d'environ 1200~watts (abbrégé W). On considère généralement que la tension moyenne d'un signal est six décibels plus petite que sa tension maximale. En reprenant notre exemple, pour une tension maximale de 100~V, on a une tension moyenne de 50~V, sous une impédance de 8~ohms, on trouve une \textbf{puissance moyenne} d'environ 300~W.

Alors, il faut donc faire très attention sur les spécifications données par les constructeurs, parfois volontairement floues. À défaut, si on lit que la puissance admissible d'un haut-parleur est de 1000~W, on supposera par défaut qu'il s'agit d'une puissance crête à crête. On ne dépassera donc pas une puissance moyenne d'amplification de 250 W.

La \textbf{sensibilité} est une mesure du niveau sonore à un mètre de l'enceinte pour une puissance RMS d'entrée d'un watt. Grâce à cette valeur, on peut calculer le niveau sonore produit par le haut-parleur à diverses distances et en fonction de différentes puissances d'entrées. On comprend aussi que la puissance électrique admissible dans l'enceinte ne donne que peu d'information sur son niveau sonore de sortie.

\hypertarget{conseils-pratiques}{%
\section{Conseils pratiques}\label{conseils-pratiques}}

\hypertarget{choisir-une-paire-duxe9coutes}{%
\subsection{Choisir une paire d'écoutes}\label{choisir-une-paire-duxe9coutes}}

Choisir une paire d'enceintes peut sembler être un exercice difficile. Il existe énormément de modèles, coûtant de quelques dizaines d'euros à plusieurs dizaines de milliers.

Il y a cependant plusieurs critères assez objectifs pour évaluer la qualité d'une enceinte~:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La réponse en fréquence~: l'enceinte flatte-t-elle particulièrement une zone du spectre~? En délaisse-t-elle une autre~?
\item
  La réponse en transitoires~: les attaques sont-elles respectées~? Retrouve-t-on l'énergie initiale du signal~?
\item
  La linéarité en fonction du volume~: a-t-on une sensation de compression du signal lorsque l'on augmente le niveau envoyé dans l'enceinte~?
\item
  Le centre fantôme~: le centre du système stéréophonique paraît-il stable~? Paraît-il précis~?
\item
  La couleur sonore de l'enceinte~: a-t-on plaisir à écouter du son et de la musique sur ce système~?
\end{enumerate}

\hypertarget{placer-correctement-son-uxe9coute}{%
\subsection{Placer correctement son écoute}\label{placer-correctement-son-uxe9coute}}

Afin de satisfaire les critères de la stéréophonie, il convient de respecter les règles suivantes~:

\begin{itemize}
\tightlist
\item
  Les deux enceintes doivent être de même marque, de même modèle et appairée. Si une des membranes a dû être changée sur l'une d'elle, l'autre aurait dû recevoir la même opération.
\item
  Les deux enceintes doivent être séparées par un angle de 60°
\item
  L'auditeur doit être placé à équidistance des deux haut-parleurs, et regarder vers le milieu du segment formé par les deux enceintes.
\end{itemize}

Une fois ces critères respectés, voici quelques conseils sur le placement des enceintes dans une pièce~:

On préférera des pièces de grandes tailles, afin de repousser au maximum le temps d'arrivée des premières réflexions. Le système stéréophonique devrait être positionné dans un souci de symétrie~: l'enceinte de gauche ne devrait pas être plus proche d'un mur que l'enceinte de droite, par exemple. Dans le cas de petit espace, on préféra coller les enceintes contre un mur. Cela permettra de supprimer l'influence d'une des premières réflexions au prix de l'augmentation du niveau de grave. Il est vivement recommandé de procédé au traitement, même minimal, acoustique de la pièce de travail, à commencer par les zones de réflexions premières et par les angles (ou le grave va s'accumuler). Si le traitement acoustique n'est pas envisageable, il convient de privilégier une écoute à faible niveau et une proximité maximale avec les enceintes.

\hypertarget{luxe9coute-au-casque}{%
\section{L'écoute au casque}\label{luxe9coute-au-casque}}

Le casque est un outil permettant d'écouter un signal tout en s'extrayant de son environnement (acoustique et/ou bruit). Cependant, de par son mode de fonctionnement, à savoir deux haut-parleurs placés dans une enceinte en contact direct avec les oreilles, il génère un certain nombre de déformations.

Premièrement, la stéréophonie écoutée au casque est hypertrophiée. En effet, dans ces conditions d'écoutes, l'oreille gauche n'entend que le haut-parleur gauche et l'oreille droite n'entend que le haut-parleur droit.

Deuxièmement, il est très difficile de trouver des casques avec une réponse en transitoire satisfaisante. Il convient donc d'être excessivement prudent lorsque l'on mix du contenu percussif sur un casque.

Troisièmement, les casques sont encore moins linéaires en fréquence que les haut-parleurs, il convient là aussi d'être très prudent lors de la réalisation d'un mixage.

Ces défauts peuvent être compensés par l'habitude et la connaissance du système d'écoute, mais la transportabilité d'un mixage (à savoir, sa compatibilité avec d'autres systèmes d'écoute) réalisé au casque est souvent discutable.

\hypertarget{casque-fermuxe9-ou-casque-ouvert}{%
\subsection{Casque fermé ou casque ouvert~?}\label{casque-fermuxe9-ou-casque-ouvert}}

Le casque fermé, comme son nom l'indique, propose une fabrication enfermant le haut-parleur dans une enceinte close. Cette méthode de fabrication offre l'avantage d'isoler celui qui écoute de l'environnement, mais aussi d'isoler l'environnement de ce qui est diffusé dans le casque. Par contre, ces casques ont souvent une réponse en fréquence très accidentée, et ne sont pas recommandés pour le mixage. Il est par contre vivement recommandé pour les musiciens en session de prise de son.

Le casque ouvert, à l'inverse de son homologue fermé, n'offre aucune isolation acoustique, au prix d'une meilleure réponse en fréquence du casque. Ces casques sont tout indiqués pour le mixage, mais beaucoup moins pour des situations de prise de son.

\hypertarget{part-muxe9thodologie-de-prise-de-son}{%
\part{Méthodologie de prise de son}\label{part-muxe9thodologie-de-prise-de-son}}

\hypertarget{mono-et-multimicrophonie}{%
\chapter{Mono et multimicrophonie}\label{mono-et-multimicrophonie}}

(En cours d'écriture)

\hypertarget{la-prise-de-son-au-couple}{%
\chapter{La prise de son au couple}\label{la-prise-de-son-au-couple}}

La prise de son au couple stéréophonique regroupe l'ensemble des techniques de prise de son dédié au système d'écoute stéréophonique (deux enceintes séparées de 60° et orientées vers un auditeur placé à équidistance des deux transducteurs).

Ces techniques permettent une bien meilleure représentation des espaces des prises de son ainsi qu'une localisation des différents éléments enregistrés dans cet espace.

\hypertarget{guxe9nuxe9ralituxe9s-sur-les-muxe9canismes-de-la-localisation-du-son-par-loreille-humaine}{%
\section{Généralités sur les mécanismes de la localisation du son par l'oreille humaine}\label{guxe9nuxe9ralituxe9s-sur-les-muxe9canismes-de-la-localisation-du-son-par-loreille-humaine}}

Afin de mieux comprendre comment fonctionne un couple de prise de son, il convient d'étudier rapidement les principes fondamentaux de notre écoute.

Notre capacité à localiser les sons dans l'espace repose principalement sur deux mécanismes~:
+ La différence de temps
+ La différence de niveau

\hypertarget{la-localisation-par-diffuxe9rence-de-temps}{%
\subsection{La localisation par différence de temps}\label{la-localisation-par-diffuxe9rence-de-temps}}

Nos oreilles sont espacées, d'environ 15 à 25 cm. Cette distance implique qu'un son émis plus proche de l'oreille droite arrivera également plus tôt qu'à l'oreille gauche. Cet écart de temps, de quelques millisecondes, est suffisant pour donner à notre cerveau un indice sur la localisation du son.

Afin de sentir l'ordre de grandeur en jeu, calculons la différence de temps (\(\Delta t\)) maximale pour un individu possédant un écart d'oreille de 20 cm.

On sait que la célérité du son dans l'air vaut \(c = 340 m.s^{-1}\), et est invariant en fonction de la fréquence. On sait également que \(c = \frac{d}{t}\).

Dès lors, si on pose \(d = 20 cm\) soit \(d = 0.2 m\), on peut en déduire que~:

\(t = \frac{d}{c} \iff t= \frac{0.2}{340} \approx 0.0006 s \approx 0.6 ms\)

Afin de mettre en relief ce résultat, il est communément admis que l'oreille humaine commence à faire la différence entre deux répétitions d'un même son à partir de \(20 ms\).

\hypertarget{la-localisation-par-diffuxe9rence-dintensituxe9}{%
\subsection{La localisation par différence d'intensité}\label{la-localisation-par-diffuxe9rence-dintensituxe9}}

A priori, l'espace entre nos deux oreilles n'est pas creux. La densité de notre crâne et de son contenu va réfléchir et absorber une partie des fréquences rencontrées.

Également, la partie externe de nos oreilles, appelées pavillon, permet, grâce à sa forme, de donner une directivité à notre écoute.

En d'autres termes, notre tête et le pavillon de nos oreilles se comportent comme un filtre, variant en fonction de l'angle d'incidence de la source. Cette altération du timbre n'est pas perçue comme une coloration, mais bien comme une information de localisation. La modélisation mathématique de ces filtres se retrouve dans la littérature scientifique sous le nom \textbf{HRTF}.

Cette atténuation séquentiellement dépendante est décisive dans notre capacité à localiser les sons. On la retrouve communément sous le nom \(\Delta i\).

\hypertarget{pruxe9valence-fruxe9quentielle-de-ces-deux-phuxe9nomuxe8nes}{%
\subsection{Prévalence fréquentielle de ces deux phénomènes}\label{pruxe9valence-fruxe9quentielle-de-ces-deux-phuxe9nomuxe8nes}}

Il est communément admis que le \(\Delta t\) aura une efficacité maximale dans les basses fréquences, et le \(\Delta i\) dans les hautes fréquences.

\hypertarget{principes-de-la-prise-de-son-au-couple}{%
\section{Principes de la prise de son au couple}\label{principes-de-la-prise-de-son-au-couple}}

Pour créer son effet stéréophonique, les couples de prise de son utilisent les mêmes mécanismes que notre écoute naturelle~:

\begin{itemize}
\tightlist
\item
  La différence de temps
\item
  La différence d'intensité
\end{itemize}

Il va de soi que, pour fonctionner de façon optimale, les microphones utilisés pour réaliser une prise de son stéréophonique doivent être de même marque, de même modèle et appairée.

\begin{quote}
L'appairage garantit que les microphones aient des caractéristiques techniques suffisamment proches pour être considérés comme identiques.
\end{quote}

Afin de manipuler ces mécanismes, le preneur de son peut jouer sur les paramètres suivant~:

\begin{itemize}
\tightlist
\item
  La directivité des microphones
\item
  L'angle entre les capsules
\item
  La distance entre les capsules
\end{itemize}

Modifier chacun de ses paramètres influe sur l'\textbf{angle de prise de son}. Plus l'ange de prise de son est faible, plus l'impression de stéréophonie sera grande. Plus l'angle de prise de son est grand, plus l'impression de stéréophonie sera faible, jusqu'à tendre vers la monophonie.

\begin{quote}
Attention de ne pas confondre l'angle de prise de son avec l'angle entre les capsules.
\end{quote}

\hypertarget{comment-choisir-un-angle-de-prise-de-son.}{%
\subsection{Comment choisir un angle de prise de son.}\label{comment-choisir-un-angle-de-prise-de-son.}}

L'angle de prise de son est étroitement lié à la distance du couple par rapport à l'évènement sonore à enregistrer. En règle générale, plus le couple est loin des objets sonores à enregistrer, plus son angle de prise de son sera faible. À l'inverse, plus le couple sera proche, plus son angle de prise de son sera grand.

Ensuite, lors de la réalisation d'un couple de prise de son, il est commun d'enregistrer un ensemble d'éléments~: plusieurs instruments (batterie), voire plusieurs musiciens (quatuor à corde, orchestre). L'objectif est bien souvent de retrouver une sensation de disposition des éléments dans l'espace proche de la situation réelle. On cherche donc un angle de prise de son suffisamment petit pour que les sources occupent l'intégralité de l'espace stéréophonique, mais également suffisamment grand pour ne pas créer une sensation de trou au centre.

\hypertarget{comment-ruxe9aliser-un-angle-de-prise-de-son.}{%
\subsection{Comment réaliser un angle de prise de son.}\label{comment-ruxe9aliser-un-angle-de-prise-de-son.}}

Plusieurs outils existent pour aider le preneur de son à configurer son angle de prise de son correctement.

Il est important de commencer par évoquer les abaques de Michael Williams, ayant cherché à étudier l'angle de prise de son et ses qualités en fonction des paramètres vues précédemment. Les résultats de ses travaux se trouvent sur le site \href{https://www.mmad.info/MAD/2\%20Ch/2ch.htm}{mmad.info}.

On trouve également beaucoup d'application mobile, comme celle du constructeur du microphone Neumann, s'appuyant sur les travaux de Michael Williams pour aider leurs utilisateurs à correctement positionner leurs microphones. Évidemment, et heureusement, rien n'est spécifique à un fabricant de microphones en particulier, l'application d'un constructeur A peut servir pour placer des microphones d'un constructeur B.

Plus récemment, des chercheurs britanniques ont développé une application, nommée \href{https://marrsweb.hud.ac.uk/}{MARRS}, permettant de positionner son couple de prise de son par rapport aux sources via une interface graphique très simple à utiliser. Cette application est disponible sur mobile et sur navigateur internet.

\hypertarget{priviluxe9gier-le-delta-i-ou-le-delta-t}{%
\subsection{\texorpdfstring{Privilégier le \(\Delta i\) ou le \(\Delta t\)~?}{Privilégier le \textbackslash Delta i ou le \textbackslash Delta t~?}}\label{priviluxe9gier-le-delta-i-ou-le-delta-t}}

La différence de perception du champ stéréophonique est très différente entre celui produit par le \(\Delta i\) ou par le \(\Delta t\).

\begin{itemize}
\tightlist
\item
  Un couple reposant sur le \(\Delta i\) aura une sensation de localisation des sources précise. De plus si un tel couple enregistre une source ce déplaçant a vitesse constante, la sensation de déplacement retranscrite par le couple sera, elle aussi, linéaire. Il est également possible de sommer les deux microphones ensemble afin d'obtenir un signal monophonique. Un tel couple est appelé compatible mono.
\item
  Un couple reposant sur le \(\Delta t\) aura une sensation de localisation plus floue, mais apportera un sens de l'espace plus grand et une dimension spacieuse. À l'inverse d'un couple \(\Delta i\), la sensation d'un déplacement linéaire d'une source n'est pas linéaire. Il n'est pas possible de sommer les deux capsules pour en obtenir une réduction mono sans générer des altérations de timbre sévères.
\end{itemize}

Chaque couple possède ses avantages et ses inconvénients. Heureusement, nous ne sommes pas limités à l'un où l'autre et nous pouvons à loisir réaliser une combinaison des deux mécanismes.

\hypertarget{les-topologies-classiques-de-prise-de-son-au-couple}{%
\section{Les topologies classiques de prise de son au couple}\label{les-topologies-classiques-de-prise-de-son-au-couple}}

Le premier ingénieur à se poser la question du son stéréophonique est l'anglais Alan Blumlein en 1929. Il imagine l'entièreté de la chaîne d'enregistrement et de diffusion nécessaire à la stéréophonie. Cependant, la BBC lui impose comme contrainte que toutes ses propositions soient compatibles avec des systèmes monophoniques. Il inventera donc le couple XY et MS.

Plus tard, la plupart des radios européennes développeront des couples de prises de son mêlant \(\Delta i\) et \(\Delta t\), tel que l'ORTF.

\hypertarget{le-couple-blumlein-xy}{%
\subsection{Le couple Blumlein / XY}\label{le-couple-blumlein-xy}}

Les deux microphones sont ici directifs, placés au même point de l'espace et ongulé d'une certaine valeur entre eux.

De par les contraintes technologiques de son époque, Blumlein a décrit ce couple pour une utilisation de deux microphones bidirectionnels. Il est aujourd'hui plus commun de le rencontrer avec deux cardioïdes.

Dans sa version originale, le couple Blumlein comprend donc deux microphones bidirectionnels avec un angle de 90°.

La formulation du couple XY comprend deux microphones cardioïdes avec un angle compris entre 90° et 135°.

\hypertarget{le-couple-ms}{%
\subsection{Le couple MS}\label{le-couple-ms}}

Le couple MS, également inventé par Alan Blumlein, permet de doser la quantité de stéréophonie après l'enregistrement.

Pour se faire, ce couple utilise deux microphones~:

\begin{itemize}
\tightlist
\item
  Un omnidirectionnel, historiquement, mais aujourd'hui fréquemment remplacé par un microphone cardioïde.
\item
  Un bidirectionnel
\end{itemize}

Le microphone omnidirectionnel, ou cardioïde, va rendre compte du centre de la stéréophonie, tandis que le microphone bidirectionnel rendra compte de la latéralité.

Une fois enregistrés, ces deux canaux ont besoin d'être convertis, plus exactement dématricés, vers une paire de canaux stéréophonique. L'opération est très simple~:

\[L = M+S\]
\[R = M-S\]

Cette opération peut être réalisée sur une console de mixage, telle que décrite ci-dessous.

\begin{figure}
\includegraphics[width=0.4\linewidth]{_resources/171f157be4749ac8446dd9bdfff0625b} \caption{Dématriçage MS}\label{fig:chunk-label}
\end{figure}

\hypertarget{le-couple-ortf}{%
\subsection{Le couple ORTF}\label{le-couple-ortf}}

Le couple ORTF, inventé par la radio française du même nom, combine l'effet du \(\Delta i\) et du \(\Delta t\) afin de s'approcher de l'écoute humaine.

Sa topologie est précisément définie. Elle propose l'utilisation d'une paire de microphones cardioïde, ongulé du 110° et avec un écart de 17 cm.

\hypertarget{les-couples-ab}{%
\subsection{Les couples AB}\label{les-couples-ab}}

Les couples AB peuvent avoir une définition ambiguë. Une partie de la littérature scientifique considère comme couple AB tout couple non coïncident. À cet égard l'ORTF est considéré comme un couple AB. Pour d'autre, les couples AB ne concernent que des couples constitués de microphones omnidirectionnels.

Ces derniers ont la particularité de n'utiliser que le \(\Delta t\) afin de placer les sources dans l'espace. Le rendu est donc souvent spacieux, au prix d'une certaine instabilité et d'un certain manque de précision de l'image stéréophonique.

\hypertarget{compluxe9ter-une-prise-de-son-au-couple-par-des-appoints}{%
\section{Compléter une prise de son au couple par des appoints}\label{compluxe9ter-une-prise-de-son-au-couple-par-des-appoints}}

Il est commun, lors d'une prise de son au couple, de chercher à obtenir une entière satisfaction sonore à la seule aide du couple. Cependant, cela n'est parfois pas possible, souvent pour des contraintes physiques et acoustiques (un instrument de l'ensemble jouant moins fort que les autres). Dans ces cas, l'utilisation d'appoint, donc de microphone supplémentaire, placé en proximité de la source, va permettre de venir récupérer une précision supplémentaire de l'instrument.

Lors de l'étape de mixage, le couple servira de base principale et l'on viendra ajouter la quantité nécessaire d'appoints pour préciser le propos. Il sera parfois nécessaire de remettre en phase l'appoint et le couple pour améliorer la sommation de l'ensemble.

\hypertarget{considuxe9rations-pratiques}{%
\chapter{Considérations pratiques}\label{considuxe9rations-pratiques}}

Le bon déroulement de l'enregistrement d'instruments acoustiques dépend de multiple facteur. Trié par ordre d'importance décroissante, nous trouvons~:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Le confort du musicien
\item
  La qualité de l'instrument enregistré
\item
  La qualité de l'acoustique de la pièce où a lieu l'enregistrement
\item
  Le placement du microphone
\item
  Le choix du microphone (technologie et directivité)
\item
  Le choix du préampli
\end{enumerate}

\hypertarget{le-confort-du-musicien}{%
\section{Le confort du musicien}\label{le-confort-du-musicien}}

Même si elle peut sembler triviale, cette «~étape~» de la chaîne de prise de son est de loin la plus importante.
La qualité de l'interprétation donnée par le musicien dépendra grandement de son état moral et psychologique~:

\begin{itemize}
\tightlist
\item
  Est-il stressé
\item
  Est-il confiant
\item
  Se sent-il accueilli
\item
  etc.
\end{itemize}

Nous pourrions considérer qu'un ou une musicienne arrivant dans un studio d'enregistrement se présente avec un taux de confiance maximal envers l'équipe technique. Dès lors l'objectif des différents techniciens est de conserver cette jauge au maximum.

Les premières minutes sont particulièrement importantes et va poser un ressenti fort sur la journée de travail. Il y a donc un équilibre à trouver entre un accueil chaleureux et décontracté et un rapport productiviste et sérieux.

Le système permettant aux musiciens de communiquer entre eux et avec les techniciens est primordial. En pratique, il n'est pas rare de dédier certains microphones du plateau à cette tâche. Du côté régi, le «~talkback~» est l'outil de communication premier des techniciens présents sur la session. Il convient de l'utiliser avec soin et prudence. Un musicien peut rapidement se sentir isolé, s'il enregistre seul. Il convient de maintenir un contact régulier et précis afin de ne pas l'abandonner dans le seul dans sa cabine. Qui plus est, un quiproquo peut être vite arrivé avec les systèmes de talkback. Prudence quant à l'état d'ouverture ou de fermeture du microphone.

\hypertarget{le-choix-de-linstrument}{%
\section{Le choix de l'instrument}\label{le-choix-de-linstrument}}

La plupart des musiciens se présenteront avec leurs instruments. La marge de manœuvre est donc ici quasi nulle.

Cependant il n'est pas rare que le studio possède du «~backline~», souvent composé de batteries, d'amplificateur guitare et basse, voire de guitares et de basses. Si l'instrument utilisé par le musicien pose problème pour la prise de son, proposer une alternative peut s'avérer être un bon pari. Il convient évidemment de sonder l'ouverture du musicien par rapport à cette proposition, afin de ne pas le braquer.

Il peut également être intéressant de «~préparer~» les instruments. Cette technique est très courante sur les pianos et les batteries, afin de changer les propriétés acoustiques de l'instrument grâce a l'utilisation de draps, coussins, couvertures disposées dans ou sur l'instrument.

\hypertarget{le-choix-de-lacoustique}{%
\section{Le choix de l'acoustique}\label{le-choix-de-lacoustique}}

L'acoustique de la salle d'enregistrement est-elle aussi plus souvent une contrainte qu'une variable d'ajustement.

On préférera souvent de grandes salles afin de limiter l'apparition prématurée de premières réflexions. Plus la salle sera petite, plus celle-ci apportera une forte coloration sur le contenu enregistré. Il convient donc d'être attentif aux petites cabines de studio, celles-ci sont souvent très mates, mais leur apport sur le timbre des instruments qui y sont enregistrés est souvent très important.

Lorsque l'on a la possibilité d'enregistrer dans de grandes salles, il est souvent intéressant de disposer des quelques panneaux acoustiques mobiles, afin de modeler la pièce à sa convenance.

Si l'acoustique imposée est défavorable, on préférera dans ce cas des prises d'hyper proximité, afin de minimiser son effet au maximum.

\hypertarget{placer-et-choisir-son-microphone}{%
\section{Placer et choisir son microphone}\label{placer-et-choisir-son-microphone}}

En pratique, il est bien difficile de dissocier le choix du microphone de son placement, les deux étant très interdépendants. Cependant, il convient de garder à l'esprit que le positionnement du microphone est, parmi les deux, sans doute le plus déterminant.

La première étape, avant même de choisir un microphone, consiste à écouter l'instrument dans l'acoustique d'enregistrement. Il s'agit ici d'une écoute active. On se déplace autour de l'instrument, on s'en approche, on s'en éloigne, afin de sentir l'interaction entre la source et l'acoustique du lieu. Aussi, il est important de trouver deux zones d'émission particulière de l'instrument~: la zone de projection maximale et la zone au timbre le plus favorable. La première peut nous servir à positionner l'instrumentiste par rapport aux autres instruments afin de minimiser les reprises entre microphones. La deuxième zone nous indique l'axe de prise de son.

Cette zone au timbre le plus favorable est relative. Elle dépend de l'instrument, bien sûr, mais aussi du modèle. Elle dépend également du mode de jeu, de l'articulation du joueur et évidemment, de l'esthétique de la musique.

\hypertarget{le-rapport-a-la-distance-du-microphone}{%
\subsection{Le rapport a la distance du microphone}\label{le-rapport-a-la-distance-du-microphone}}

La distance de positionnement du microphone est un élément excessivement important sur le rendu esthétique de la prise de son.

En règle générale, plus on prend de distance, plus on approche une prise de son naturaliste, cherchant à reproduire un évènement sonore dans son environnement, tel qu'il aurait été entendu dans la pièce. Plus on se rapproche, plus on fragmente l'événement sonore et plus on l'arrache aussi a son contexte de diffusion.

Afin de déterminer efficacement le placement d'un microphone, il convient d'abord d'en connaître sa distance critique. Celle-ci correspond au point, dans une pièce, où le son provenant directement d'une source est perçu au même niveau sonore que la réponse acoustique à cette source. Cela signifie que si nous plaçons notre microphone au-delà de ce point, nous obtiendrons plus d'acoustique que de son direct de l'instrument.

Il est important aussi de considérer que la directivité du microphone influe sur la distance critique. En effet, plus la directivité du microphone est large (tends vers l'omnidirectionnalité), plus le microphone paraîtra éloigné de la source. À l'inverse, plus la directivité d'un microphone est étroite (tends vers la bidirectionnalité), plus le microphone paraîtra proche.

Dans le cas de l'utilisation de microphone directif, le placement en proximité et hyperproximité va créer une accentuation du contenu basse-fréquence de la source. Cela devient parfois un élément esthétique, comme sur les voix radiophoniques. Cela aussi peut être un défaut, une exagération qu'il conviendra de corriger en postproduction.

\hypertarget{quand-choisir-une-prise-de-son-stuxe9ruxe9ophonique}{%
\subsection{Quand choisir une prise de son stéréophonique}\label{quand-choisir-une-prise-de-son-stuxe9ruxe9ophonique}}

La prise de son stéréophonique, comme son nom l'indique, regroupe l'ensemble des techniques de prise de son dédié au système de diffusion stéréophonique (deux enceintes séparées de 60° et orientées vers un auditeur placé à équidistance des deux transducteurs).

L'avantage de tels dispositifs de prises de son est de peupler dès la prise l'espace stéréophonique qui est donné à l'auditeur lors de la diffusion. Ils permettent également de rendre compte de la position de plusieurs évènements sonores ayant lieu dans la même acoustique. Cette dernière est d'ailleurs bien mieux retranscrite par de tels systèmes de prise de son.

Il s'agit à nouveau d'un choix esthétique. Faire le choix d'une prise de son monophonique permet de renforcer la sensation de frontalité et de densité d'une source. À l'inverse, une prise de son stéréophonique donnera une définition spatiale accrue.

\hypertarget{quand-choisir-la-multi-microphonie}{%
\subsection{Quand choisir la multi-microphonie}\label{quand-choisir-la-multi-microphonie}}

La multi-microphonie consiste à enregistrer un instrument via l'utilisation de microphones (principalement) directifs, placés à différents endroits jugés pertinents et en hyperproximité.

Cette approche esthétique de la prise de son est devenue indissociable des «~musiques actuelles~». Elle offre l'avantage d'une grande flexibilité de traitement lors de la phase de mixage. Voir, elle implique une certaine partie des traitements.

En effet, une prise d'hyperproximité va systématiquement relever deux défauts~:

\begin{itemize}
\tightlist
\item
  un effet de proximité~: le grave/bas médium de la source paraît hypertrophié lors de l'emploi de microphones directifs.
\item
  Les dynamiques de jeux sont également hypertrophiées.
\end{itemize}

L'effet de proximité implique donc bien souvent l'utilisation d'un égaliseur, permettant de corriger cette augmentation artificielle du grave. De même, l'hypertrophie de la dynamique de jeu implique l'usage d'un compresseur afin de corriger ces variations artificielles.

Afin de recréer une sensation de spatialisation, on utilisera principalement deux outils. En premier lieu, le potentiomètre de panoramique afin de diriger ces sons mono dans l'espace stéréophonique, puis les réverbérations artificielles permettra de reconstituer un champ acoustique et de réintégrer ces sources dans une scène sonore.

Si l'approche de la prise au couple pouvait être qualifiée de naturaliste, alors la prise de son en multimicrophone sera son pendant spectaculaire. Évidemment, il convient de ne pas aussi franchement opposer ces deux approches et il existe tout un monde de système de prise de son entre ces deux extrêmes.

\hypertarget{le-choix-du-pruxe9amplificateur}{%
\section{Le choix du préamplificateur}\label{le-choix-du-pruxe9amplificateur}}

Le rôle du préamplificateur est d'amplifier le signal, le tout en ramenant le minimum de bruit. Un premier élément de choix de préampli va se faire sur le niveau de pression acoustique produit par les sources à enregistrer.

Enregistrer une batterie impose peut de contrainte sur le préampli quand a sa capacité à amplifier sans rajouter beaucoup de bruit sur le signal. À l'inverse, enregistrer des instruments peux sonores, possiblement avec des microphones peux sensibles, implique l'utilisation de préampli avec une excellente réserve de gain et un excellent rapport signal bruit.

\hypertarget{linfluence-du-pruxe9ampli-sur-la-couleur-du-son}{%
\subsection{L'influence du préampli sur la «~couleur~» du son}\label{linfluence-du-pruxe9ampli-sur-la-couleur-du-son}}

Il est assez connu que le préampli peut également devenir un choix esthétique pour influencer la couleur d'une prise de son. Cette question semble assez complexe. Voici quelques éléments de réponse~:

\begin{itemize}
\tightlist
\item
  Le choix du préampli est d'une influence minime par rapport à \textbf{tous} les autres choix précédemment fait.
\item
  Les préamplis sont souvent catégorisés, en termes de couleur, via les composants utilisés pour réaliser l'amplification. Attention, un composant électronique dépend toujours du contexte dans lequel il est placé (ici, du circuit électronique). Il est donc difficile de précisément qualifier le son d'un préampli à lampe ou à transistor de façon générique.
\item
  Les impédances d'entrée des préamplis ne sont souvent pas évoquées dans ces discussions. Hors, pour la plus parts des microphones (hors statiques), leur impédance de sortie peut être suffisamment élevée pour engendrer une déperdition en aigu et en transitoire. Cette déperdition peut être heureuse, ou malheureuse, mais surtout bien réelle. Une manière de s'en prémunir peut-être d'utiliser des «~booster~» de microphones (parfois également appelés préamplis), permettant d'augmenter le niveau de sortie des microphones et aussi d'adapter leur impédance.
\end{itemize}

\hypertarget{duxe9phasage-et-remise-en-phase}{%
\chapter{Déphasage et remise en phase}\label{duxe9phasage-et-remise-en-phase}}

\hypertarget{les-effets-sonores-de-duxe9phasage}{%
\section{Les effets sonores de déphasage}\label{les-effets-sonores-de-duxe9phasage}}

Tous les signaux sont caractérisés par une certaine phase. Celle-ci est moins tangible que celles de niveau sonore ou de fréquence. En effet, lorsqu'un signal est écouté seul, celle-ci ne s'entend pas. C'est au moment où plusieurs signaux corrélés (comprendre, enregistrés au même moment, par plusieurs microphones) sont sommés que les différences de phase peuvent s'entendre.

\hypertarget{approche-mathuxe9matique}{%
\section{Approche mathématique}\label{approche-mathuxe9matique}}

Prenons l'exemple d'un son pur~:
\(sin (\omega t + \phi)\) où \(\omega = 2\pi f\)

La phase de ce signal est décrite par \(\omega t +\phi\)

Les deux paramètres responsables de déphasages audibles sont~:

\begin{itemize}
\tightlist
\item
  \(t\), le temps
\item
  \(\phi\), la phase à l'origine
\end{itemize}

Attention, pour un son pur, l'effet de la modification de \(t\) ou de \(\phi\) semble très similaire. Ce n'est pas le cas pour des signaux pseudo-périodiques, atténués dans le temps.

\hypertarget{les-sources-de-duxe9phasage}{%
\section{Les sources de déphasage}\label{les-sources-de-duxe9phasage}}

Les causes les plus classiques de déphasages sont~:

\begin{itemize}
\tightlist
\item
  Un câble XLR avec une inversion sur le point chaud et le point froid
\item
  Une prise de son avec une différence de distance entre deux microphones
\item
  Une prise de son utilisant deux microphones positionnés de part et d'autre d'une membrane
\item
  Un retard de certaines fréquences lié aux objets rencontrés par les signaux
\end{itemize}

\end{document}
